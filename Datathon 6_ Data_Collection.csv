Year,Title,Abstract,Discussion
2017,A machine learning-based framework to identify type 2 diabetes through electronic health records,"Objective To discover diverse genotype-phenotype associations affiliated with Type 2 Diabetes Mellitus (T2DM) via genome-wide association study (GWAS) and phenome-wide association study (PheWAS), more cases (T2DM subjects) and controls (subjects without T2DM) are required to be identified (e.g., via Electronic Health Records (EHR)). However, existing expert based identification algorithms often suffer in a low recall rate and could miss a large number of valuable samples under conservative filtering standards. The goal of this work is to develop a semi-automated framework based on machine learning as a pilot study to liberalize filtering criteria to improve recall rate with a keeping of low false positive rate. Materials and methods We propose a data informed framework for identifying subjects with and without T2DM from EHR via feature engineering and machine learning. We evaluate and contrast the identification performance of widely-used machine learning models within our framework, including k-Nearest-Neighbors, Na√Øve Bayes, Decision Tree, Random Forest, Support Vector Machine and Logistic Regression. Our framework was conducted on 300 patient samples (161 cases, 60 controls and 79 unconfirmed subjects), randomly selected from 23,281 diabetes related cohort retrieved from a regional distributed EHR repository ranging from 2012 to 2014. Results We apply top-performing machine learning algorithms on the engineered features. We benchmark and contrast the accuracy, precision, AUC, sensitivity and specificity of classification models against the state-of-the-art expert algorithm for identification of T2DM subjects. Our results indicate that the framework achieved high identification performances (‚àº0.98 in average AUC), which are much higher than the state-of-the-art algorithm (0.71 in AUC). Discussion Expert algorithm-based identification of T2DM subjects from EHR is often hampered by the high missing rates due to their conservative selection criteria. Our framework leverages machine learning and feature engineering to loosen such selection criteria to achieve a high identification rate of cases and controls. Conclusions Our proposed framework demonstrates a more accurate and efficient approach for identifying subjects with and without T2DM from EHR.",Expert algorithm-based identification of T2DM subjects from EHR is often hampered by the high missing rates due to their conservative selection criteria. Our framework leverages machine learning and feature engineering to loosen such selection criteria to achieve a high identification rate of cases and controls.
2017,Machine learning techniques for diabetic macular edema (DME) classification on SD-OCT images,"Background Spectral domain optical coherence tomography (OCT) (SD-OCT) is most widely imaging equipment used in ophthalmology to detect diabetic macular edema (DME). Indeed, it offers an accurate visualization of the morphology of the retina as well as the retina layers. Methods The dataset used in this study has been acquired by the Singapore Eye Research Institute (SERI), using CIRRUS TM (Carl Zeiss Meditec, Inc., Dublin, CA, USA) SD-OCT device. The dataset consists of 32 OCT volumes (16 DME and 16 normal cases). Each volume contains 128 B-scans with resolution of 1024 px √ó 512 px, resulting in more than 3800 images being processed. All SD-OCT volumes are read and assessed by trained graders and identified as normal or DME cases based on evaluation of retinal thickening, hard exudates, intraretinal cystoid space formation, and subretinal fluid. Within the DME sub-set, a large number of lesions has been selected to create a rather complete and diverse DME dataset. This paper presents an automatic classification framework for SD-OCT volumes in order to identify DME versus normal volumes. In this regard, a generic pipeline including pre-processing, feature detection, feature representation, and classification was investigated. More precisely, extraction of histogram of oriented gradients and local binary pattern (LBP) features within a multiresolution approach is used as well as principal component analysis (PCA) and bag of words (BoW) representations. Results and conclusion Besides comparing individual and combined features, different representation approaches and different classifiers are evaluated. The best results are obtained for LBP16-ri vectors while represented and classified using PCA and a linear-support vector machine (SVM), leading to a sensitivity(SE) and specificity (SP) of 87.5 and 87.5%, respectively.","Evaluations of individual features (see Table 8) show that the dimensionality reduction of the features and the use of Histogram + PCA representation improved the results of B-scan classification. The reason for that, we have only 30 (no. of volumes, two left out for testing) multiply by 128 (no. of B-scan per volume) points in the space to be classified, while the dimension space is huge as shown in Tables 5 and ‚Äãand6.6. Using only Histogram representation, RF classifier led to the best performance followed by linear-SVM. RBF-SVM classifier had the lowest performance for all the individual features due to overfitting. The performance was improved when the number of dimensions were reduced using PCA. Using the second representation the gap between the classifiers were reduced and the classification performances obtained were similar. Comparing individual features, LBP proved to be more discriminative than HoG features. This could be due to the rotation invariant property of LBP in comparison to non-invariant HoG descriptors. Based on Table 9, the combination of LBP and HoG features did not improve the results but decreased the performance of individual features, the reason could be due to the higher dimensionality of the LBPPCA + HoGPCA. In this test, RF and linear-SVM had similar performance while RBF-SVM was overfitting. As shown in Table 2, various methods were tested using the same dataset. The pipeline applied by these methods vary in terms of each step, denoising, features extraction and classifying, which appear in disparate results (refer to state-of-the-art section) To conclude with Exp1, the highest classification performance was achieved using: LBPPCA8-ri and linear-SVM, LBPPCA16-ri and RBF-SVM, LBP16-ri and RF, and finally LBPPCA16-ri and RF classifier. These configurations were later tested in Exp2 using BoW representation. The results obtained from Exp2 showed that Histogram + PCA + BoW representation led to lower the performance results. In fact, this approach represented each volume in terms of visual-B-scans rather than visual-patches or visual-sub-volumes, which could be a reason why BoW failed."
2018,Machine Learning Methods to Predict Diabetes Complications,"One of the areas where Artificial Intelligence is having more impact is machine learning, which develops algorithms able to learn patterns and decision rules from data. Machine learning algorithms have been embedded into data mining pipelines, which can combine them with classical statistical strategies, to extract knowledge from data. Within the EU-funded MOSAIC project, a data mining pipeline has been used to derive a set of predictive models of type 2 diabetes mellitus (T2DM) complications based on electronic health record data of nearly one thousand patients. Such pipeline comprises clinical center profiling, predictive model targeting, predictive model construction and model validation. After having dealt with missing data by means of random forest (RF) and having applied suitable strategies to handle class imbalance, we have used Logistic Regression with stepwise feature selection to predict the onset of retinopathy, neuropathy, or nephropathy, at different time scenarios, at 3, 5, and 7 years from the first visit at the Hospital Center for Diabetes (not from the diagnosis). Considered variables are gender, age, time from diagnosis, body mass index (BMI), glycated hemoglobin (HbA1c), hypertension, and smoking habit. Final models, tailored in accordance with the complications, provided an accuracy up to 0.838. Different variables were selected for each complication and time scenario, leading to specialized models easy to translate to the clinical practice.","This work describes the application of a modern data mining pipeline, combining a variety of approaches to exploit clinical data to extract a risk calculator of microvascular T2DM complication. It provides a multivariate index of the patients‚Äô conditions. AI-based strategies were used to handle missing data and to address class imbalance. Models were created considering different prediction horizons and validated by state-of-art data science principles. Finally, LR and nomograms was selected as the instrument to deliver the predictive models to the users. The developed pipeline allowed developing models tailored on the population characteristics, which are specific of the T2DM patients treated by the ICSM hospital. The LR model on the entire dataset, after RF imputation, identified individual risk factors for the onset of the three microvascular complications and their relative odds ratios. Hba1c, as the standard measure for blood glucose monitoring in diabetic patients, was found to be a risk factor for all complications. As the developed models take into account measurements at the first visit near the hospital, HbA1c might be affected by some bias due to poor metabolic control at the referral. However, this bias is mitigated by the very nature of the measure, which takes into account a 3-month period before the visit. In fact, HbA1c values mean (SD) of 62.42 (21.05) mmol/mol are comparable to the average values of the Italian T2DM patients.21,22 Duration of diabetes (T2DM) and BMI were found to be important risk factors for both retinopathy and neuropathy, while hypertension was found as a risk factor for both retinopathy and nephropathy. As regards of retinopathy, these results can be supported by other studies and literature reviews,23 where is shown that the main risk factors for retinopathy prevalence increasing are HbA1c and diabetes duration. Regarding nephropathy, a recent study24 applied a data mining framework to predict renal failure in T2DM on a time horizon of 5 years. The described models are based on a larger cohort and include albuminuria and creatinine values, which were not available in our analysis. The results in terms of metabolic control are comparable. Although AUC values are higher for nephropathy on a 5-year horizon, they are not significantly different from the 3-year ones, which we choose to deliver for clinical practice (as shown in table 3). the missed opportunity to include albumin-creatinine ratio indicators, which have been demonstrated to be cardiovascular risk factors,25-27 is one of the main limitations of the presented work. Models performances were evaluated in terms of MCC, which is instead dependent on the decisional threshold, which relates to how close the predicted outcome is to the actual outcome. MCC values were more informative when evaluating the impact of strategies to address the class imbalance problem: if no such strategy was adopted, the models assigned almost all examples to the majority class, leading to poor MCC results. While small differences are noticeable among resampling approaches, in general none of the proposed strategies contributed to significantly improve the AUC performances with respect to the baseline model nor achieved better MCC."
2019,Machine-learning to stratify diabetic patients using novel cardiac biomarkers and integrative genomics,"Background Diabetes mellitus is a chronic disease that impacts an increasing percentage of people each year. Among its comorbidities, diabetics are two to four times more likely to develop cardiovascular diseases. While HbA1c remains the primary diagnostic for diabetics, its ability to predict long-term, health outcomes across diverse demographics, ethnic groups, and at a personalized level are limited. The purpose of this study was to provide a model for precision medicine through the implementation of machine-learning algorithms using multiple cardiac biomarkers as a means for predicting diabetes mellitus development. Methods Right atrial appendages from 50 patients, 30 non-diabetic and 20 type 2 diabetic, were procured from the WVU Ruby Memorial Hospital. Machine-learning was applied to physiological, biochemical, and sequencing data for each patient. Supervised learning implementing SHapley Additive exPlanations (SHAP) allowed binary (no diabetes or type 2 diabetes) and multiple classification (no diabetes, prediabetes, and type 2 diabetes) of the patient cohort with and without the inclusion of HbA1c levels. Findings were validated through Logistic Regression (LR), Linear Discriminant Analysis (LDA), Gaussian Na√Øve Bayes (NB), Support Vector Machine (SVM), and Classification and Regression Tree (CART) models with tenfold cross validation. Results Total nuclear methylation and hydroxymethylation were highly correlated to diabetic status, with nuclear methylation and mitochondrial electron transport chain (ETC) activities achieving superior testing accuracies in the predictive model (~‚Äâ84% testing, binary). Mitochondrial DNA SNPs found in the D-Loop region (SNP-73G, -16126C, and -16362C) were highly associated with diabetes mellitus. The CpG island of transcription factor A, mitochondrial (TFAM) revealed CpG24 (chr10:58385262, P‚Äâ=‚Äâ0.003) and CpG29 (chr10:58385324, P‚Äâ=‚Äâ0.001) as markers correlating with diabetic progression. When combining the most predictive factors from each set, total nuclear methylation and CpG24 methylation were the best diagnostic measures in both binary and multiple classification sets. Conclusions Using machine-learning, we were able to identify novel as well as the most relevant biomarkers associated with type 2 diabetes mellitus by integrating physiological, biochemical, and sequencing datasets. Ultimately, this approach may be used as a guideline for future investigations into disease pathogenesis and novel biomarker discovery.","Machine-learning can be applied as a systems biology approach, integrating multiple classes of biometric data to assess the importance of specific factors, while also predicting future outcomes. Whereas conventional assessments of disease identification exist, more detailed genomic and epigenomic testing is likely to reveal a comprehensive, systemic valuation of an etiology. To-date, studies have applied machine-learning algorithms in examining the physiological, biochemical, and/or genetic components of disease onset or progression [51]. The advantage of our current study is through the assimilation of patient-matched data across a variety of critically impacted systems, providing an archetype for developing novel, descriptive, diagnostic measures through machine-learning algorithms that are specific for each disease type. By individually representing our datasets in Figs. 2, ‚Äã,33 and ‚Äãand4,4, we were able to reach more conclusive data in Fig. 5 by choosing the most predictive features for our final model. For the first time, a multi-omics, machine-learning approach was used to assess the progression and development of type 2 diabetes mellitus in a patient population, identifying potential biomarkers for cardiovascular risk and revealing the fundamental role of genetics in the pathology. Molecular pathogenesis and machine-learning While clinical practice has recently experienced a surge in deep learning applications used for non-invasive imaging [52], implementing machine-learning algorithms to the fundamental biochemistry and cellular and molecular processes of the body is now only blossoming. Onset and progression of type 2 diabetes has been traditionally measured through blood glucose levels, but, the multifaceted aspects of the disease could create variability in prognosis between vastly different demographic and ethnic groups. Owusu Adjah et al. [14] recently identified BMI as a risk factor for determining ethnic group disposition to type 2 diabetes mellitus. Specifically, the relationship between BMI and increased incidence of diabetes mellitus is non-linear; some groups, such as South Asian populations, were more disposed to developing the disease even at lower BMIs. While the current manuscript examines cardiovascular tissue, other less invasive approaches have been used to apply machine-learning algorithms. By retrieving blood from the basilica vein, circulating biomarkers were examined for their role in predicting early recurrence of atrial fibrillation following cryoballoon ablation [53]. Support vector machines confirmed that decreased levels of creatine-kinase (CK-MB) and Troponin T (TnT) were associated with increased early recurrence of atrial fibrillation following cryoballoon ablation. Additionally, a unique, non-invasive approach for potentially diagnosing type 2 diabetes in patients was performed through the examination of toenails. Carter et al. [54], through a variety of machine learning algorithms, focused on 22 elements, including aluminum, cesium, nickel, vanadium, and zinc, and was able to get an AUC of 0.90 when predicting diabetic status using a random forest model. Similar to parts of the aims of this study, other groups have attempted to use machine learning to separate diabetic and non-diabetic patients without the inclusion of blood glucose or HbA1c [55]. In a testing set of 13,700 patients from the Luzhou, China region, random forest machine-learning algorithms provided a 0.7225 accuracy when predicting diabetic status from physical examination data in the absence of blood glucose [55]. Also using a random forest model, Tang et al. [56] revealed how CpG island methylation data, combined with microRNA expression profiles, can be instrumental in cancer pathogenesis; implementing this two-feature selection process, they were able to identify the best tissue specific features, ultimately allowing for the identification of the originating tissue where tumor progression began. In a similar fashion, the machine-learning algorithm HeteSim [57], which examines heterogeneous datasets and calculates their relatedness, was employed in ascribing how gene profiles can be related to phenotypic outcomes, specifically in the validation and prediction of genes classified within major diseases [58]. While understanding how to better form prognoses and treat cardiac dysfunction in patients with type 2 diabetes mellitus remains a critical mission, more than 80 million American adults, most of which are undiagnosed, are prediabetic [59]. In the current work, we have implemented predictive algorithms to assess biomarkers likely involved in the onset, as well as prediabetic progression, of type 2 diabetes mellitus. Although multiple classification categories further reduce the predictive power of the model, separation into distinct groupings revealed a unique phenotype for prediabetics (Fig. 4h). The effects of diabetes mellitus on the body is a high glucose stressed condition, altering substrate metabolism and causing systemic inflammation [60]. Due to this environmental change, researchers have shown how epigenetic changes occur across most, if not all, tissues that are impacted by diabetes mellitus [49, 61]. In the cardiovascular system, the heart, circulatory system, and regulating immune system are all transcriptionally regulated through epigenetic alterations [48, 62], resulting in cellular adaptations to the environmental stress. Examining atrial appendages, the results obtained in this study are a direct reflection of changes within the heart. While blood is more easily acquired in type 2 diabetic patients, cardiac tissue, which is mitochondrially rich, provides a direct connection between physiological dysfunction observed in the heart and the impact of altered genomic profiles in the mitochondrion and nucleus. Machine-learning, which at current has been applied to very few genetic applications, may play a significant role in defining the epigenome of those with diabetes mellitus, likely unveiling genes and molecular pathways first impacted by the pathology. The challenges of machine learning in the clinical setting Machine-learning algorithms produce generalizations as they are inherently predictive, which means a smaller sample size can occasionally result in increased emphasis on outliers within the patient dataset and determination of the outliers‚Äô biomarker features to be most influential in disease diagnosis. With a limited 50 patient dataset, there are concerns of overfitting the model, where the derived classification tree would have branches for each patient sample encountered during training. If this was to occur, the produced tree would fail future test cases while maintaining near perfect training accuracy, which was not observed. Tenfold cross validation ensured that no single developed tree was composed solely of outliers or a group of patient data of one label type, allowing patients of different labels to train the algorithm. Additionally, choosing seed values provided an even patient distribution during model training and testing. Both tenfold cross validation and setting a seed allowed the derived models to not over fit the training data. With this being said, it should be noted that the small sample size limits the conclusions and predictions made by the machine-learning algorithms within the manuscript, and future investigations will need to validate specific features, including CpG24 of TFAM and global nuclear DNA methylation. For developed frameworks and the implemented SHAP visualization, the results are inherently regulated by HbA1c since patient HbA1c values were used to assign the labels from which the machine-learning algorithm then proceeded to train. HbA1c is used as a guide in this study to help clarify how clinically assessed progression of diabetes (commonly through HbA1c levels) is related to the biochemical and genetic signatures found in the heart. Although no specific biomarker or biomarker combinations can replace HbA1c due to the apparent diagnostic bias in this study (essentially‚Äâ~‚Äâ100% accuracy when included), they can provide predictive accuracies near that of HbA1c. While previous clinical diagnoses determined a patients‚Äô diabetic status in this study, some patients diagnosed as type 2 diabetics had HbA1c levels within normal ranges; begging the question of whether sustained, or attenuated, health effects can be accurately assessed through HbA1c levels alone when intervention (lifestyle or medicinally) occurs? Ultimately, this study provides a machine-learning algorithm utilizing the respective advantages of HbA1c in combination with other biomarkers to help circumvent the limitations of modern HbA1c diagnosis, as well as introduces completely novel cardiac risk stratification paradigms for patients with type 2 diabetes mellitus. The quantity and diversity of omics-based approaches continues to expand. Convenience and increasingly inexpensive options for biometric-based valuations incite a growing demand for the incorporation and meaningful explanation of large and diverse patient datasets. The methodology outlined in this manuscript can serve as an archetype for the development and implementation of machine-learning to other disciplines seeking to evaluate disease progression. By using various health outcomes datasets, we were able to identify, and combine, the most prominent biomarkers into an accurate predictive algorithm engineered around 50 patients. While we have identified specific genetic features that are highly predictive in 50 patients, as a much larger patient population is applied to this model, the prioritization of other features is likely to occur, enhancing the diagnostic potential for the individual diabetic or prediabetic patient. Indeed, this is the advantage of using machine-learning models, in that they continue to learn and develop more accurate predictions as the number of features and sampled population grows."
2019,Data-driven modeling and prediction of blood glucose dynamics: Machine learning applications in type 1 diabetes,"Background Diabetes mellitus (DM) is a metabolic disorder that causes abnormal blood glucose (BG) regulation that might result in short and long-term health complications and even death if not properly managed. Currently, there is no cure for diabetes. However, self-management of the disease, especially keeping BG in the recommended range, is central to the treatment. This includes actively tracking BG levels and managing physical activity, diet, and insulin intake. The recent advancements in diabetes technologies and self-management applications have made it easier for patients to have more access to relevant data. In this regard, the development of an artificial pancreas (a closed-loop system), personalized decision systems, and BG event alarms are becoming more apparent than ever. Techniques such as predicting BG (modeling of a personalized profile), and modeling BG dynamics are central to the development of these diabetes management technologies. The increased availability of sufficient patient historical data has paved the way for the introduction of machine learning and its application for intelligent and improved systems for diabetes management. The capability of machine learning to solve complex tasks with dynamic environment and knowledge has contributed to its success in diabetes research. Motivation Recently, machine learning and data mining have become popular, with their expanding application in diabetes research and within BG prediction services in particular. Despite the increasing and expanding popularity of machine learning applications in BG prediction services, updated reviews that map and materialize the current trends in modeling options and strategies are lacking within the context of BG prediction (modeling of personalized profile) in type 1 diabetes. Objective The objective of this review is to develop a compact guide regarding modeling options and strategies of machine learning and a hybrid system focusing on the prediction of BG dynamics in type 1 diabetes. The review covers machine learning approaches pertinent to the controller of an artificial pancreas (closed-loop systems), modeling of personalized profiles, personalized decision support systems, and BG alarm event applications. Generally, the review will identify, assess, analyze, and discuss the current trends of machine learning applications within these contexts. Method A rigorous literature review was conducted between August 2017 and February 2018 through various online databases, including Google Scholar, PubMed, ScienceDirect, and others. Additionally, peer-reviewed journals and articles were considered. Relevant studies were first identified by reviewing the title, keywords, and abstracts as preliminary filters with our selection criteria, and then we reviewed the full texts of the articles that were found relevant. Information from the selected literature was extracted based on predefined categories, which were based on previous research and further elaborated through brainstorming among the authors. Results The initial search was done by analyzing the title, abstract, and keywords. A total of 624 papers were retrieved from DBLP Computer Science (25), Diabetes Technology and Therapeutics (31), Google Scholar (193), IEEE (267), Journal of Diabetes Science and Technology (31), PubMed/Medline (27), and ScienceDirect (50). After removing duplicates from the list, 417 records remained. Then, we independently assessed and screened the articles based on the inclusion and exclusion criteria, which eliminated another 204 papers, leaving 213 relevant papers. After a full-text assessment, 55 articles were left, which were critically analyzed. The inter-rater agreement was measured using a Cohen Kappa test, and disagreements were resolved through discussion. Conclusion Due to the complexity of BG dynamics, it remains difficult to achieve a universal model that produces an accurate prediction in every circumstance (i.e., hypo/eu/hyperglycemia events). Recently, machine learning techniques have received wider attention and increased popularity in diabetes research in general and BG prediction in particular, coupled with the ever-growing availability of a self-collected health data. The state-of-the-art demonstrates that various machine learning techniques have been tested to predict BG, such as recurrent neural networks, feed-forward neural networks, support vector machines, self-organizing maps, the Gaussian process, genetic algorithm and programs, deep neural networks, and others, using various group of input parameters and training algorithms. The main limitation of the current approaches is the lack of a well-defined approach to estimate carbohydrate intake, which is mainly done manually by individual users and is prone to an error that can severely affect the predictive performance. Moreover, a universal approach has not been established to estimate and quantify the approximate effect of physical activities, stress, and infections on the BG level. No researchers have assessed model predictive performance during stress and infection incidences in a free-living condition, which should be considered in future studies. Furthermore, a little has been done regarding model portability that can capture inter- and intra-variability among patients. It seems that the effect of time lags between the CGM readings and the actual BG levels is not well covered. However, in general, we foresee that these developments might foster the advancement of next-generation BG prediction algorithms, which will make a great contribution in the effort to develop the long‚Äìawaited, so-called artificial pancreas (a closed-loop system).","5.1. Principal findings Recently, machine learning has received wider attentions for modeling and the prediction of BG dynamics. Regardless of its popularity, no recent reviews have analyzed and reflected on the current development. As far as our knowledge is concerned, no review has focused mainly on modeling and prediction of BG dynamics using machine learning techniques. Therefore, the purpose of this review is to assess and analyze the state-of-the-art machine learning applications in BG prediction pertinent to the controller of an artificial pancreas (a closed-loop system), modeling of a personalized profile, personalized decision support systems, and BG alarm event applications. It serves as a compact guide regarding modeling options and strategies of machine learning applications and their hybrid system in type 1 diabetes. However, some recent reviews have been conducted on diabetes in general and on BG prediction in particular [[11], [12], [13]]. For instance, Oviedo et al. [12] recently conducted a methodological review on BG prediction, focusing mainly on a closed-loop system (an artificial pancreas), which assessed a variety of approaches, including physiological models, data-driven models, and hybrid approaches. Kavakiotis et al. [11] also performed a systematic review of the applications of machine learning and data mining techniques in diabetes research in the context of diabetes prediction and diagnosis, diabetes complications, genetic background and environment, and healthcare and management. BG dynamics are affected by numerous factors, such as history of BG values, insulin medication, physical activity, and dietary intake. Moreover, they are also affected by other factors, such as an individual‚Äôs body mass index, stress level, amount of sleeping time, presence of illness, some medications, smoking habit, periods (menstruation), alcoholism, allergies, and altitude. In principle, a successful BG predictor is expected to incorporate as much information as possible to effectively track and predict BG levels. However, due to the complexity of BG dynamics, it remains difficult to achieve an accurate prediction in every circumstance. Most of the available BG prediction algorithms have their own limitations, working better in some specific circumstances. The reported BG prediction algorithms have explored various classes of machine learning, input parameters, and training algorithms. Most of these studies have neglected the effect of physical activity on BG dynamics, and only a few studies have considered the effect of patient uncontrollable parameters, such as stress, illness, and others. Generally, the reported BG prediction algorithms can be categorized under different scenarios, such as real time (online) versus offline, the age group (children, adult, and old), BG regions (hypo/eu/hyperglycemia events), the time of day (diurnal vs. nocturnal), generalizability (generic vs. specific), free-living versus non-free-living conditions, and the evaluation approach (in vivo vs in silico). Accordingly, most researchers have considered separate age groups, which are typically related with the dynamics and active lifestyles adopted by each group. Few attempts have been made to develop real-time algorithms that perform under free-living conditions. Moreover, most of the reported algorithms perform better in either of these BG regions (hypo/eu/hyperglycemia events). Furthermore, most of the algorithms rely on in silico evaluations, which further put the clinical significance in question. Also, the lack of a well-defined approach to estimate carbohydrate intake is an issue; it is mainly done manually by the individual users and is prone to an error that can severely affect the predictive performance. The lack of a universal approach to estimate and quantify the approximate effect of physical activities, stress, and infection incidence on the BG level is another challenge. For instance, regarding physical activity integration, a wide variety of approaches have been proposed, such as using a scale and level code to quantify the degree and duration of physical activity, the sum of energy expenditures during an interval of time, physical activity caloric use based on standard table, MET, exercise compartmental models, a proprietary algorithm to estimate the physical activity energy expenditure by combining different physiological signals such as transversal acceleration (a measure of movement), heat flux (the average heat dissipated or absorbed by the arm), longitudinal acceleration (measure of movement), skin and near-body temperature, and galvanic skin response (electrical conductivity between two points on the arm). It seems that almost all the studies have followed quite different approaches, and this poses a challenge in regarding one‚Äôs approach as universal. In addition, also few studies have been done regarding model portability that can capture the inter- and intra-variation among the patients. It also seems that the effect of time lags between the CGM reading and the actual BG levels is not well covered. Generally, the review indicates the lack of a one-fits-all algorithm that performs better under totally free-living conditions. Any successful BG prediction algorithm should at least consider both the patient‚Äôs controllable parameters (BG, insulin, diet, physical activity, and others) and patient uncontrollable parameters (stress, infections, medications, and others). Moreover, it is also necessary to consider any relevant contextual information, such as intra- and inter-variability among the patient‚Äôs changes in lifestyles, the time of day (diurnal vs nocturnal) and others. Future researchers need to reflect on a longer prediction horizon (giving more response time) with reasonable clinical accuracy, approaches to improve time lags from the CGM, real-time capability under free living conditions, and a thorough validation using real patients (clinical trials) with ample subjects over a longer period of time. Moreover, the predictor should give proper weights and penalties for errors in hypoglycemia, euglycemia, and hyperglycemia regions. It is also necessary to consider a proper way to estimate the amount and effect of dietary consumption and physical activity during integration with the machine learning model. Stress and infections have a prominent effect on BG dynamics, which could in turn affect the predictor performances. To this end, it is necessary to test and assess the effects of a change in either lifestyle or physiology (infections) on the predictor performance using subjects who are monitored within different periods. Furthermore, the effect of different CGM devices on the quantitative performance of the prediction algorithms should be explored along with the associated time lag. 5.2. Summary of existing efforts (Machine learning techniques) 5.2.1. Artificial neural network (ANN) An artificial neural network (ANN) is a computational model consisting of various processing elements known as neurons and a scaled connection between them called weights [94]. Various forms of artificial neural networks are used, but the network topology could be generally categorized as feed-forward networks (SLP, MLP, and radial basis function) and recurrent/feedback networks (Elman net, Kohonen‚Äôs SOM, and Hopfield Networks). The feed- forward network is the most common topology, where it consists of a connection between different neurons that are directed only in one direction (forward) from the earlier stage to the next level. Recurrent or feedback network topology involves at least one feedback loop in the architecture [94]. Both of these network topologies have been successfully employed in modeling and for the prediction of BG levels in type 1 diabetes patients. Regarding the feed-forward network, for example, Allam et al. and others [18,44,45] have developed a feed-forward neural network from CGM data using the back propagation Levenberg-Marquardt optimization training algorithm. Pappada et al. and others [46,47,65] have also proposed time-lagged feed-forward neural networks trained through a back-propagation gradient descent algorithm, which is capable of storing previous values of data within the network. Zainuddin et al. [29] have proposed a wavelet neural network, integrating different wavelet families as an activation function for modeling BG dynamics trained through pseudo-inverse with fixed parameter initialization. Zarkogianni et al. [27] developed a seven-layer neuro-fuzzy network using wavelets as an activation function and Gaussian function as a membership function trained through a gradient-based algorithm with an adaptive learning rate. Compared to these shallow networks, Mhaskar et al. [52] proposed a semi-supervised deep learning neural network with a judge predictor based on the function approximation on data-defined manifolds, using diffusion polynomials. Baghdadi et al. [19] implemented a radial basis function network using Gaussian function in the hidden layer neuron. Georga et al. [57] investigated the applicability of an extreme learning machine (ELM), specifically an online sequential ELM (OS-ELM) and online sequential ELM kernels (KOS-ELM) for training single hidden-layer feed-forward neural networks. In a surgical care setting, Pappada et al. [48] trained a feed-forward network from CGM data for bedside monitoring using a back-propagation training algorithm. Apart from the feed-forward network, recurrent or feedback networks have been utilized in BG prediction; that is, recurrent neural networks, autoregressive neural networks and self-organizing maps. For example, Daskalaki et al. [22] developed an online adaptive ANN-based model using a fully connected, multilayered ANN with two feedback loops trained through a teacher-forced, real-time, recurrent algorithm. Sandham et al. [38,42] and Robertson et al. [40] have used an Elman recurrent network trained through a backpropagation gradient descent algorithm with momentum and an adaptive learning rate and Levenberg-Marquardt algorithm, respectively. Alanis et al. [73,79] developed an autoregressive version of a neural network called neural network autoregressive external input (NNARX), which is trained through an extended Kalman filter (EKF) algorithm. Chernetsov et al. [21] performed a comparative analysis of three recurrent or feedback networks: the layer recurrent network (LRN), Elman net, and nonlinear autoregressive network (NARX-net). They investigated the effect of different learning algorithms, network architectures, prediction horizons, data sample sizes, and tapped delay line lengths on the performance of the network. Moreover, Zarkogianni et al. [26] conducted a comparative analysis of four machine learning techniques in the modeling of BG dynamics: a feed-forward neural network (FNN) trained through a backpropagation algorithm, a self-organizing map (SOM) achieved by applying a vector quantization method, a neuro-fuzzy network using wavelets as activation functions (WFNN), and a linear regression model (LRM). They used CGM data and also explored the effect of physical activity data collected from a SenseWear Armband. The study demonstrated the superiority of SOM and its ability to capture both the complexity of the dynamics and also the inter- and intra-variations among the patients [26]. 5.2.2. Support vector machines (SVM), kernel function (KF), and gaussian process regression Support vector machines have been widely exploited across a wide range of applications, such as pattern identification and recognition, categorization or classification, regression, and prediction [95]. Support vector regression (SVR) is the most widely used class of SVMs in BG prediction and modeling. In this regard, for example, Reymann et al. [41] investigated the applicability of BG prediction using a mobile platform based on SVR, with radial basis function (RBF) as a kernel. Moreover, Li et al. [54] tried to use pooled patient data to capture patient similarities, which led to the development of a personalized BG prediction model using smartphone-collected data based on SVR. Georga et al. [58] investigated the potential performance enhancement from using a feature ranking algorithm, random forests (RF), and RReliefF algorithms, where the predictor is based on SVR-exploiting Gaussian radial basis function (RBF) as a kernel. As a solution to the artificial neural network requirement of larger training data and much more information to learn, Naumova et al. developed a novel fully adaptive regularized learning (FARL) approach using meta-learning to choose the kernels and regularization parameters in kernel-based regularization learning algorithms [35]. Gaussian process regression is a useful nonparametric regression tool that has been widely adopted in various applications, such as a vital-sign ‚Äúearly warning system,‚Äù patient physiological monitoring, disease prediction, and the discovery of biomarkers in microarray gene expression data. Tomczak et al. [32] investigated the applicability of Gaussian process regression in BG prediction coping with categorical inputs. The input consisted of the data, time, code (categorical), and BG level (numeric). The categorical code was used to describe the type of measurement (e.g., insulin dose, meal intake, physical exercise, pre-prandial BG measurement, and others). The covariance function was proposed to deal with the categorical inputs [32]. 5.2.3. Genetic programming and genetic algorithms An evolutionary algorithm (EA) is a biologically inspired approach to problem solving [96]. The two most used variants of EA in BG prediction and modeling approaches are genetic programming (GP) and genetic algorithms (GA). Hidalgo et al. [76,77] used a genetic programming-based symbolic regression known as grammatical evolution to develop an individualized model of BG dynamics. Moreover, Contreras et al. [71] used the grammatical evolution approach to develop a standalone BG prediction model. Furthermore, Hidalgo et al. [69] assessed the performance of different predictors, genetic programming, random forests, k-nearest neighbors, and grammatical evolution along with a new enhanced modeling algorithm, a variant of grammatical evolution that uses optimized grammar, and a variant of tree-based genetic programming that uses a three-compartment model for carbohydrate and insulin dynamics. 5.2.4. Random Forest (RF) Random forests or random decision forests are an ensemble approach of learning for classification and regression applications, which learns by constructing a multitude of decision tress generating the mode of the class or the mean of prediction. In this regard, for example, Xao et al. [30] developed a random forest regression and support vector regression-based BG predictors and assessed the performance improvement gained through the selection of an optimal feature representative using a combined approach of feature importance scores of ensemble learning and a sequential backward selection (SBS) algorithm. Furthermore, Georga et al. [59] used a random forest regression to predict BG levels with a multivariate dataset containing a subcutaneous glucose profile, plasma insulin concentration, intestinal absorption of meal-derived glucose, and daily energy expenditure. 5.2.5. Hybrid approach Hybridization involves combining two or more different approaches, either at the preprocessing, feature extraction, or learning stage when looking for improved performance. The majority of the BG prediction models involve the hybridization of physiological (compartmental) models along with different machine learning techniques. Regarding support vector regression, for example, Plis et al. [43] combined support vector regression along with a physiological model, where the latter generates informative input features to be used to train the SVR model. Furthermore, Georga et al. [[60], [61], [62], [63]] combined support vector regression with compartmental models, which are used to quantify the absorption of subcutaneously administered insulin, glucose from the gut following a meal, and the effects of exercise on plasma glucose and insulin dynamics. Regarding the hybridization of an artificial neural network with other approaches, some researchers have reported success in this direction. For example, Mougiakakou et al. [50] combined an artificial neural network with a compartmental model, where the latter is used to estimate the effect of food on BG levels and the influence of injected insulin on plasma insulin concentration; this output along with the previous BG measurements were used to train the ANN model. Mougiakakou et al. [51] further investigated the combination of a recurrent neural network along with three compartmental models, which estimated the effect of short-acting (SA) insulin intake on blood insulin concentration, intermediate-acting (IA) insulin intake on blood insulin concentration, and, carbohydrate intake on BG absorption from the gut. Zecchin et al. [23,24] combined an artificial neural network and a physiological model to exploit meal information to be used along with the CGM data. Moreover, Zecchin et al. [15,25] further explored the applicability of a jump neural network, which is feed by a meal physiological model and CGM data, and compared their result with a previously proposed artificial neural network [23,24]. Briegel et al. [74] explored a nonlinear state space model for modeling an individual BG dynamic using a compartmental model and an artificial neural network. Furthermore, Otto et al. [49] developed a hybrid model combining an artificial neural network and fuzzy logic, where the fuzzy logic was used to approximate food, insulin, and the level of exercise. Several researchers have attempted to hybridize genetic programming along with physiological models. For example, Contreras et al. [70] developed a hybrid model using a genetic programming-based algorithm known as grammatical evolution and a physiological model. Self-organizing maps (SOMs) have been used to develop a hybrid model along with a physiological model. For example, Zarkogianni et al. [28] used the physiological model to simulate the subcutaneous insulin kinetics and glucose absorption from the gut into the blood, which are in turn fed into the SOM. Jankovic et al. [56] developed a two-layer (prediction and correction layer) online adaptive personalized BG prediction model. The prediction layer consisted of an autoregressive model with external input (ARX) and an artificial neural network, which made the first estimates and then the output was further optimized in the second (correction) layer through an extreme learning machine (ELM). 5.2.6. Ensemble approach ‚Äì merging different predictors for performance improvement Due to the complexity of BG dynamics, it remains difficult to achieve an accurate prediction in every circumstance (i.e., hypo/eu/hyperglycemia events). One prediction model can have a better prediction power in either of these circumstances, and the other model can achieve better predictive power where the first model fails to accurately predict. Therefore, it is natural to look for opportunities to exploit the strengths from these different predictors to achieve better predictive power in most of these circumstances, which has led to ensemble approaches. An ensemble approach is generally favored when one is interested in merging two or more different predictors for improved performance. Various approaches have been taken to ensemble predictors (e.g., heuristic algorithms; bagging, boosting, and weighted majorities; the Bayesian model averaging approach, and online versions of these) [33]. The main differences between these approaches are how the weights are determined to achieve the best possible predictive power. In this regard, for example, Wang et al. [31] proposed a novel approach that is able to combine several prediction algorithms, where the adaptive weight of each algorithm is determined through an inversely proportional relationship to its sum of the squared prediction errors. The proposed approach was tested using an autoregressive (AR) model, an extreme learning machine, and support vector regression and achieved a satisfactory result [31]. Moreover, Stahl et al. [34] proposed a novel Bayesian approach to merge multiple predictors by using recursive weighting for a single prediction through a regularized optimization technique. Stahl et al. [33] further investigated a novel merging approach that combines elements from switching and averaging techniques to form a soft switcher in a Bayesian framework. Botwey et al. [66] investigated three different data fusion techniques to merge two predictors, an autoregressive model with output correction, cARX, and a recurrent neural network, RNN, based on the Dempster-Shafer evidential theory (DST), genetic algorithms (GA), and genetic programming (GP). Moreover, Daskalaki et al. [68] merged an autoregressive approach with an output correction module (cARX) model, and recurrent neural network (RNN) models, where the fusion is implemented using a linear combination of the two models‚Äô output and the balancing factor (weight) is determined through a customized cost function."
2019,A data-driven approach to predicting diabetes and cardiovascular disease with machine learning,"Background Diabetes and cardiovascular disease are two of the main causes of death in the United States. Identifying and predicting these diseases in patients is the first step towards stopping their progression. We evaluate the capabilities of machine learning models in detecting at-risk patients using survey data (and laboratory results), and identify key variables within the data contributing to these diseases among the patients. Methods Our research explores data-driven approaches which utilize supervised machine learning models to identify patients with such diseases. Using the National Health and Nutrition Examination Survey (NHANES) dataset, we conduct an exhaustive search of all available feature variables within the data to develop models for cardiovascular, prediabetes, and diabetes detection. Using different time-frames and feature sets for the data (based on laboratory data), multiple machine learning models (logistic regression, support vector machines, random forest, and gradient boosting) were evaluated on their classification performance. The models were then combined to develop a weighted ensemble model, capable of leveraging the performance of the disparate models to improve detection accuracy. Information gain of tree-based models was used to identify the key variables within the patient data that contributed to the detection of at-risk patients in each of the diseases classes by the data-learned models. Results The developed ensemble model for cardiovascular disease (based on 131 variables) achieved an Area Under - Receiver Operating Characteristics (AU-ROC) score of 83.1% using no laboratory results, and 83.9% accuracy with laboratory results. In diabetes classification (based on 123 variables), eXtreme Gradient Boost (XGBoost) model achieved an AU-ROC score of 86.2% (without laboratory data) and 95.7% (with laboratory data). For pre-diabetic patients, the ensemble model had the top AU-ROC score of 73.7% (without laboratory data), and for laboratory based data XGBoost performed the best at 84.4%. Top five predictors in diabetes patients were 1) waist size, 2) age, 3) self-reported weight, 4) leg length, and 5) sodium intake. For cardiovascular diseases the models identified 1) age, 2) systolic blood pressure, 3) self-reported weight, 4) occurrence of chest pain, and 5) diastolic blood pressure as key contributors. Conclusion We conclude machine learned models based on survey questionnaire can provide an automated identification mechanism for patients at risk of diabetes and cardiovascular diseases. We also identify key contributors to the prediction, which can be further explored for their implications on electronic health records.","Diabetic Prediction Models trained on diabetic patients (Case I) generally obtain a higher predictive power (86.2%) when compared to the Case II models which has a highest recorded accuracy of 73.7%. The decrease in detection performance in comparison to Case I is primarily due to two factors ‚Äî 1) smaller number of observations, and 2) boundary conditions for the recorded observations. Case II only has 16,426 observations available in comparison to 21,091 observations available in Case I. The model also has difficulty in discerning fringe cases of patients, i.e. patients who are borderline diabetic versus normal. The accuracy also decreases slightly (AU-ROC at 72.5% for XGBoost) for the time-frame of 2003-2014, where there are even lower number of observations available for a larger number of variables. The consistency of the precision, recall, and F1 values suggests stable models with similar predictive power for diabetic (label=1) and non-diabetic (normal label=0) patients. The WEM and XGBoost models developed in the study surpass prior research done by Yu et al. [13] where they obtained 83.5% (Case I) and 73.2% (Case II) using non-linear SVM models. While the number of observations and additional feature variables play a key part in the increased accuracy of our models, the ensemble based model consistently out-performed SVM in the diabetic study (especially for Case I). Comparing time-frames within our data, we observe for the window of 2003-2014 the best performing model (RFC) had a lower AU-ROC score was at 84.1% for Case I. While the timeframe has a larger set of features (168 versus 123), the drop in the number of observations (16,443 versus 21,091) leads to the reduction in accuracy by 2% when compared to 1999-2014. Similar results are also observed in Case II where the AU-ROC drops by 1.2% as a result of decrease in the number from 16,446 (in 1999-2014) to 12,636 (in 2003-2014). Inclusion of laboratory results in Case I (1999-2014 timeframe) resulted in substantial increase the predictive capabilities (AU-ROC score of XGBoost - 95.7%). Contrary to previous observations, in the timeframe of 2003-2014, accuracy increases to 96.2% with XGBoost performing the best. This suggests availability of key laboratory variables within the 2003-2014 timeframe, leading to increased accuracy. Case II performance analysis with the laboratory variables also results in a large performance increase to AU-ROC score of 80.2% in the timeframe of 1999-2014 and 83.4% in 2003-2014 timeframe. XGBoost models perform the best in laboratory results in each of the cases, closely followed by the WEM model. Model performance metrics for Case I shows tree based ensemble models - Random Forest and XGBoost along with the WEM model constantly outperform linear models such as Logistic Regression and Support Vector Machine. This is further highlighted in the ROC curves in Fig. 2. In Case II, the distinction is less obvious with similar performance recorded from all models as shown in Fig. 3. In such a case, computationally less demanding models such as Logistic Regression can be used to achieve similar classification performance when compared to other complex models such as SVM or ensemble classifiers. Analysis of feature variables in non-laboratory based models (within the diabetes data) shows features such as waist size, age, weight (self-reported and actual), leg-length, blood-pressure, BMI, household income, etc. contribute substantially towards the prediction of the model. This is similar to the observations and variables used in prior research [12, 13]. However, in our study we observe several dietary variables such as sodium, carbohydrate, fiber, and calcium intake contribute heavily towards diabetes detection in our models. Caffeine and alcohol consumption, along with relatives with diabetes, ethnicity, reported health condition, and high cholesterol also play key roles. Within the laboratory based data, the feature importance measures suggest blood osmolality, blood urea nitrogen content, triglyceride, and LDL cholesterol are key factors in detection of diabetes. Each of the variables have been shown in prior research [30‚Äì33] to be key contributors or identifiers in diabetic patients. Age, waist circumference, leg length, weight, and sodium intake operate as common important variables for prediction between laboratory and survey data. Prior research in the domain of predicting diabetes have reported results with high degree of accuracy. Using a neural network based approach to predict diabetes in the Pima Indian data set, Ayon et al. [34] observed an overall F1-score of 0.99. The analysis was based on data collected only from females of Pima Indian decent, and contained plasma glucose and serum insulin (which are key indicators of diabetes) as features for prediction. In comparison, our approach is a more generalized model where the demography of the patients is not restricted and does not contain plasma glucose and serum insulin levels (even in our laboratory based models). In [35] authors compare J48, AdaboostM1, SMO, Bayes Net, and Na√Øve Bayes, to identify diabetes based on non-invasive features. The study reports an F1 score of 0.95, and identify age as the most relevant feature in predicting diabetes, along with history of diabetes, work stress, BMI, salty food preferences, physical activity, hypertension, gender, and history of cardiovascular disease or stroke. While age, BMI, salt intake, and gender, were also identified in our study as pertinent variables, NHANES dataset does not contain (or has a high percentages of missing values) features of stress, history of cardiovascular disease, and physical activity. As a result the overall accuracy of the two studies cannot be compared directly. Heydari et al. [36] also compared SVM, artificial neural network (ANN), decision tree, nearest neighbors, and Bayesian networks, with ANN reporting the highest accuracy of 98%. However, study pre-screened for type 2 diabetes and was able to collect features of family history of diabetes, and prior occurrences of diabetes, gestational diabetes, high blood pressure, intake of drugs for high blood pressure, pregnancy and aborted pregnancy. Within our approach we consider both pre-diabetic and diabetic patients. Therefore, the results of this paper should be more accurate when applied to a diverse population which has not been screened for any pre-existing conditions. Cardiovascular (CVD) Prediction Model performance towards the detection of at-risk patients of cardiovascular disease was pretty consistent across all models (AU-ROC difference of 1%, Fig. 6). While the WEM performed the best (AU-ROC 83.9%), other simplistic models such as logistic regression can provide similar results. This is partly due to the lack of large number of observations in the data, with total number of samples at 8,459, and also as a result of a high degree of imbalanced data with negative (0 label) versus positive (1 label) samples at 7,012 and 1,447 respectively. The applicability of ensemble based models (WEM, RFC, and XGBoost) can be further explored in the situations where large amounts of training observations are available, but in cases with limited observations computationally simple models like Logistic Regression can be used. Models developed based on laboratory based variables do not show any significant performance gain with an increase of only 0.7%. This suggests a predictive model based on survey data only can provide an accurate automated approach towards detection of cardiovascular patients. Analyzing the features present in non-laboratory data, the most important features include age, diastolic and systolic blood pressure, self-reported greatest weight, chest pain, alcohol consumption, and family history of heart attacks among others. Incidents of chest pain, alcohol consumption, and family history of cardiac issues have been identified in prior research [37‚Äì39] as high risk factors for heart disease. As shown in study conducted by Lloyd-Jones et al. [40], age of the patients is a key risk variable in patients that is also identified by our models. A large number of feature importance variables are common across diabetes and cardiovascular patients, such as physical characteristics, dietary intake, and demographic characteristics. Similar factors (other than dietary variables) were identified by the study conducted by Stamler et al. [41], where they identified diabetes, age stratum, and ethnic background to be key contributors for cardiovascular disease. The laboratory based data analysis suggests features such as age, LDL and HDL cholesterol, chest pain, diastolic and systolic blood-pressure, self-reported greatest weight, calorie intake, and family history of cardiovascular problems as important variables. LDL and HDL cholesterol have been shown as high risk factors of cardiovascular diseases in prior research [42, 43]. Segmented neutrophils, monocyte, lymphocyte and eosinophilis counts recorded in the laboratory variables also have importance in this classification model. Similar to non-laboratory results, dietary variables such as calorie, carbohydrate, and calcium intake reappear in the list of important features."
2019,Artificial intelligence predicts the progression of diabetic kidney disease using big data machine learning,"Artificial intelligence (AI) is expected to support clinical judgement in medicine. We constructed a new predictive model for diabetic kidney diseases (DKD) using AI, processing natural language and longitudinal data with big data machine learning, based on the electronic medical records (EMR) of 64,059 diabetes patients. AI extracted raw features from the previous 6 months as the reference period and selected 24 factors to find time series patterns relating to 6-month DKD aggravation, using a convolutional autoencoder. AI constructed the predictive model with 3,073 features, including time series data using logistic regression analysis. AI could predict DKD aggravation with 71% accuracy. Furthermore, the group with DKD aggravation had a significantly higher incidence of hemodialysis than the non-aggravation group, over 10 years (N‚Äâ=‚Äâ2,900). The new predictive model by AI could detect progression of DKD and may contribute to more effective and accurate intervention to reduce hemodialysis.","In this study, we showed that AI could predict the progression of DKD using big data machine learning, according to the EMR of T2DM patients. Our study used three novel approaches to improve the predictive capacity of disease-specific complications. First, we constructed a new predictive model of diabetic complications before the patients showed clinical signs or symptoms such as microalbuminuria. Second, we used big EMR data for machine-learning by AI without any objective of clinical research; we included cases not defined clinically as T2DM in their text on EMR. Third, AI used time-series data from 6 months before the reference periods and predicted the progression of DKD for 6 months after the reference periods. DKD is one of the most common diabetic complications and its progression results in hemodialysis for end-stage renal disease (ESRD)3,22. DKD is the major cause of hemodialysis in many countries3. Diabetes patients with normoalbuminuria have been reported to progress to microalbuminuria at 2.8%/year23,24. Because microalbuminuria is considered to be an early marker predicting diabetic nephropathy and subsequent ESRD, remission of microalbuminuria should mean less ESRD in the future25,26. There are several reports concerning the remission of early stage DKD, such as diabetic nephropathy at stage 2, where patients have 30‚Äì300‚Äâmg urinary microalbumin/day6‚Äì9. Theoretically, the earlier the intervention for DKD, the better the outcome we can expect in terms of remission. However, early intervention in stage 1 DKD must be less cost-effective and has the risk of overdiagnosis and/or overtreatment. Other biomarkers in diabetes patients with normoalbuminuria, such as urinary L-type fatty acid binding protein and serum tumor necrosis factor-Œ± and its receptors, could also be surrogate markers of diabetic nephropathy27, but none of these markers is perfect. Liao et al. recently reported that urinary proteomics analysis could be useful to detect early diabetic nephropathy and that the haptoglobin-to-creatinine ratio might provide a better predictive value for early renal functional decline in 4.2 years than the microalbumin-to-creatinine ratio28. In this study, we constructed a model of early stage DKD at stage 1 to 2 diabetic nephropathy. With this approach, we could define T2DM at an early stage of DKD but with a higher future risk of its progress. It may be beneficial to provide more intensive care, such as statins and anti-hypertensive medicine, for these patients. Proteinuria is related to atherosclerosis, resulting in cardiovascular diseases, such as ischemic heart disease and apoplexy29. For diabetes patients, we used microalbuminuria as a surrogate marker to predict ESRD and other atherogenic cardiovascular events30. We showed here that progression of DKD in 6 months could result in a higher incidence of hemodialysis due to chronic renal failure in our patients over 10 years. Furthermore, the unstable proteinuria group had a higher incidence of cardiovascular events than the stable non-proteinuria group. These results suggest that very early intervention to reduce proteinuria could contribute to a better prognosis for both renal and cardiac diseases. Many countries have progressed to super-aging societies and elderly patients are liable to have several diseases at the same time. Therefore, clinical medicine in super-aging societies is more complicated and clinical trials to find effective treatments are more difficult. In previous works to predict diabetes complications, they calculated the risks with several clinical information such as current age, sex, ethnicity, smoking status, presence or absence of microalbuminuria or worse, and laboratory data for diabetes, hypertension and dyslipidemia31. With this approach, we could pick up known risk factors according to the previous report but could not include unknown risk factors. In addition, when we perform the clinical trials to prove the efficacy of the treatment, we need to register many untreated patients as control. In our approach to find an AI-supported predictive model for chronic diseases such as T2DM, we can elucidate the combination of clinical risk factors with less expense and less effort than current clinical trials. AI has the advantages of improving clinical medicine in the field with digital data such as imaging11,12, pharmacokinetics13, genetics14 and oncology15. Recent studies with AI in the field of diabetes represent a diverse and complex set of innovative approaches that aim to transform diabetes care in four main areas: automated retinal screening, clinical decision support, predictive population risk stratification, and patient self-management tools32. AI could improve imaging techniques such as diabetic retinopathy screening33, because digital imaging is an aggregation of many pixels with the same processing condition. Recently, the US Food and Drug Administration (FDA) permitted the marketing of the first medical device to use AI to detect diabetic retinopathy. There are several innovative studies using a machine-learning approach to develop phenotyping frameworks to detect diabetes16, the progression of diabetes18 and hypoglycemia17. However, an AI-oriented predictive model of diabetic complications has not yet been developed. Our current study suggests that AI could support our decision to reduce future clinical events at an early stage of complications in chronic diseases such as T2DM. There are some limitations to this study. First, the information obtained from each EMR, especially from the medical doctors‚Äô records, varies considerably and we could not unify the data extraction from each patient. Second, the duration between each laboratory test was not uniform and depended on the individual patient. Third, this study was carried out in a single center and has not been reevaluated using EMR from other institutions. Fourth, we could not find any relationship between progression of DKD for 6 months and medication. Because the patients without DKD are likely to be treated less intensively, we suggest that the medication itself may not have affected the progression of DKD in this study. Therefore, we still need prospective study to prove very early intervention to DKD could prevent macrovascular events including ESRD and CVD in T2DM patients. In conclusion, the new predictive model using AI could detect the progression of DKD, which may contribute to more effective and accurate intervention to reduce hemodialysis and cardiovascular events."
2019,Machine Learning for the Prediction of New-Onset Diabetes Mellitus during 5-Year Follow-up in Non-Diabetic Patients with Cardiovascular Risks,"Purpose Many studies have proposed predictive models for type 2 diabetes mellitus (T2DM). However, these predictive models have several limitations, such as user convenience and reproducibility. The purpose of this study was to develop a T2DM predictive model using electronic medical records (EMRs) and machine learning and to compare the performance of this model with traditional statistical methods. Materials and Methods In this study, a total of available 8454 patients who had no history of diabetes and were treated at the cardiovascular center of Korea University Guro Hospital were enrolled. All subjects completed 5 years of follow up. The prevalence of T2DM during follow up was 4.78% (404/8454). A total of 28 variables were extracted from the EMRs. In order to verify the cross-validation test according to the prediction model, logistic regression (LR), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), and K-nearest neighbor (KNN) algorithm models were generated. The LR model was considered as the existing statistical analysis method. Results All predictive models maintained a change within the standard deviation of area under the curve (AUC) <0.01 in the analysis after a 10-fold cross-validation test. Among all predictive models, the LR learning model showed the highest prediction performance, with an AUC of 0.78. However, compared to the LR model, the LDA, QDA, and KNN models did not show a statistically significant difference. Conclusion We successfully developed and verified a T2DM prediction system using machine learning and an EMR database, and it predicted the 5-year occurrence of T2DM similarly to with a traditional prediction model. In further study, it is necessary to apply and verify the prediction model through clinical research.","Recently, as medical records have become electronic databases, the utilization of big data is considered to be clinically valuable. However, if these data cannot be made clinically relevant to our real-world clinical practice, they become useless. In order to be useful and valuable, data must be analyzed, interpreted, and translated into clinical practice. Machine learning is an emerging tool for processing and utilizing big data.14,15,16,17 The development of machine learning in clinical medicine is expected to be a powerful tool for clinicians.15 Thus, studies are being actively conducted to apply machine learning to clinical medicine.22,26,28 In the present study, we generated a predictive model of T2DM using LR, LDA, QDA, and KNN algorithms and performed a cross-validation test to verify the performance of a machine learning disease prediction model. Moreover, in the prediction of T2DM, optimization of the prediction model according to the hyper-parameter settings of the KNN learning model was sought, and the performance of the optimized prediction models was compared. This approach successfully predicted the 5-year occurrence of T2DM compared with a traditional prediction model. Machine learning develops a programmed prediction model using data, algorithms, and computing power. This process requires more computing power as the number of data variables increases. Accordingly, the efficient use of meaningful variables is important. The present study collected 28 features for analysis, including patient information, disease status, test results, and medication information, from a single-center EMR database, which was used to analyze 8454 non-diabetic subjects. In order to generate an efficient prediction model of T2DM, the information gain attribute evaluation method and a 10-fold cross-validation test were performed, and 20 out of the 28 features were selected for model generation. Generally, in the data mining and machine learning field, 10-fold cross-validation is performed to assess the validity of the generated features or models. However, use of 10-fold cross-validation in the field of clinical medical data is very limited.22,25,26 In this study, LR, LDA, and QDA learning models, as well as the KNN learning model (using 1, 10, and 100 neighbors with the Euclidian distance measurement method), were created to verify the validation test according to the learning models, and the cross-validity test was performed from 1 to 30 fold. The cut-off of the section that was most stable was searched. As shown in Fig. 3B, all of the predictive models showed a SD of the 3-fold AUC of less than 0.05 and a SD of the 10-fold AUC of less than 0.01. Our results indicated that the 10-fold cross-validation test is an effective method for verifying clinical data. Previous studies that have reported predictive models of T2DM have been developed in the form of regression formula or risk scores using regression analysis, such as Cox proportional or logistic, with predictive ranges of 0.71 to 0.91 in AUC measurement.12,13 Meanwhile, however, these predictive models were evaluated in the same cohort in which they were developed, thus allowing for overfitting.25,26 This can be a very important limitation. Thus, if the cross-validation test in the generation of predictive models is applied, it could improve problems with overfitting. In this study, the LR model was considered as a standard regression analysis method. Thus, a LR model was created to compare the machine learning predictive models, such as LDA, QDA, and KNN model. Along with LR, the LDA, QDA, and KNN algorithms are the most common and proven machine learning algorithms in the computer science field. Since the principles of these algorithms are slightly different, it is worth exploring algorithms that exhibit optimal performance. All predictive models for performance comparisons were finally assessed with the 10-fold cross-validation test, and performance was compared by analysis of AUC. LDA and QDA algorithms are the most commonly used statistical algorithms in the field of machine learning.23,24 The KNN algorithm measures the distance of the nearest K neighbors among the given data and clustering of similar groups. This can be seen as a way of assessing risk according to the attributes of a particular group. We considered that this may be effective when the target group is local or a variable whose risk is unknown is used as a predictor in the analysis of clinical medical data. Unlike the LR, LDA, and QDA algorithms, the KNN algorithm needs to be verified for model generation because the performance of the model depends on the setting of hyper-parameters.24 The hyper-parameters of the KNN algorithm are the number of near neighbors and the distance measurement. In clinical medicine, the proper distance measurement of the KNN algorithm is unclear. As shown in Table 2 and Fig. 3, we measured the change in the predictive performance of the model according to the hyper-parameters and were able to select the best performing model. However, these methods must be re-evaluated according to the number of cohort subjects, samples, and variables that will be specific to each study. In this study, we developed a prediction system using machine learning algorithms, including LR, LDA, QDA, and KNN models with 200 neighbors and a city block or 300 neighbors and the Euclidian. The machine learning predictive models have successfully predicted the 5-year occurrence of T2DM and showed similar prediction performance with a traditional prediction model. As shown in Fig. 4, all of the models developed in this study showed concordant discrimination, with AUCs consistently around 0.77. Our results may have been influenced by the fact that all of the predictive models for T2DM were developed using the same 20 features. This can be an important reason for the consistent performance of all the predictive models. Also, regression analysis has traditionally been a representative method for assessing the causal relationship between features and diseases in medical science. The development of predictive models using typical medical features and LR algorithms (one regression analysis) may have shown the best performance of the LR algorithm model. In our study, the source data of the predictive model were readily obtained from an EMR database. We suspect that prediction models could be programmed into EMR databases, facilitating race or locality-optimized diagnosis or prediction models of a disease. Furthermore, when patient information is updated and unknown parameters are discovered and applied, the performance of these models may be improved. Further, this may help reduce the development costs of prediction models. With this expectation, many researchers are working on applying machine learning or deep learning to medicine. However, at the moment, the performance improvements with machine learning do not yet expand beyond the abilities of humans. In our study, the maximum performance among all of the developed models showed an AUC of 0.78, which was not significantly different from that of a previous study. Similarly, Gulshan, et al.28 verified the deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. In the evaluation of retinal fundus photographs of diabetic patients, the deep running algorithm showed high sensitivity and specificity for detecting diabetic retinopathy; however, there was no statistical difference with current ophthalmologic assessment. As such, while machine learning methods using computer power, mathematical algorithms, and EMR data can provide convenience in model development and use, it seems that this does not yet show the performance level to replace humans. Further research is needed to determine the feasibility of applying machine learning in a clinical setting and to determine whether machine learning can lead to improved outcomes in comparison to clinical assessments. In this study, there were several limitations. First, the source data of this study included subjects with cardiovascular risks, so the results of this study cannot be generalized to everyone. Thus, in further study, it is necessary to collect cases and improve performance based on the model from this study. Second, ICD codes were used to diagnose disease. The use of ICD codes indicates the presence or absence of disease, but does not reflect the progression of the disease. To overcome these drawbacks, the results of blood tests and medication information were used for analysis, although this may not be enough. Third, the study used an EMR database, and missing information from the EMR was not reflected. This can influence the outcomes of the study. Fourth, unlike previous traditional studies, our study applied 10-fold validation in the development of the models. However, throughout the study, model development and validation was conducted with only one database. Thus, it is necessary to collect additional cases and verify the model derived in this study using other data sources. Finally, the LR model was considered as a standard regression analysis method in this study. Nevertheless, the LR model is derived from machine learning and may show the different performance than regression formulas and risk scores based on regression analysis."
2020,Application of Machine Learning Models to Evaluate Hypoglycemia Risk in Type 2 Diabetes,"Introduction To identify predictors of hypoglycemia and five other clinical and economic outcomes among treated patients with type 2 diabetes (T2D) using machine learning and structured data from a large, geographically diverse administrative claims database. Methods A retrospective cohort study design was applied to Optum Clinformatics claims data indexed on first antidiabetic prescription date. A hypothesis-free, Bayesian machine learning analytics platform (GNS Healthcare REFS‚Ñ¢: Reverse Engineering and Forward Simulation) was used to build ensembles of generalized linear models to predict six outcomes defined in patients‚Äô 1-year post-index claims history, including hypoglycemia, antidiabetic class persistence, glycated hemoglobin (HbA1c) target attainment, HbA1c change, T2D-related inpatient admissions, and T2D-related medical costs. A unified set of 388 variables defined in patients‚Äô 1-year pre-index claims history constituted the set of predictors for all REFS models. Results The derivation cohort comprised 453,487 patients with a T2D diagnosis between 2014 and 2017. Patients with comorbid conditions had the highest risk of hypoglycemia, including those with prior hypoglycemia (odds ratio [OR]‚Äâ=‚Äâ25.61) and anemia (OR‚Äâ=‚Äâ1.29). Other identified risk factors included insulin (OR‚Äâ=‚Äâ2.84) and sulfonylurea use (OR‚Äâ=‚Äâ1.80). Biguanide use (OR‚Äâ=‚Äâ0.75), high blood glucose (>‚Äâ125 mg/dL vs.‚Äâ<‚Äâ100 mg/dL, OR‚Äâ=‚Äâ0.47; 100‚Äì125 mg/dL vs.‚Äâ<‚Äâ100 mg/dL, OR‚Äâ=‚Äâ0.53), and missing blood glucose test (OR‚Äâ=‚Äâ0.40) were associated with reduced risk of hypoglycemia. Area under the curve (AUC) of the hypoglycemia model in held-out testing data was 0.77. Patients in the top 15% of predicted hypoglycemia risk constituted 50% of observed hypoglycemic events, 26% of T2D-related inpatient admissions, and 24% of all T2D-related medical costs. Conclusions Machine learning models built within high-dimensional, real-world data can predict patients at risk of clinical outcomes with a high degree of accuracy, while uncovering important factors associated with outcomes that can guide clinical practice. Targeted interventions towards these patients may help reduce hypoglycemia risk and thereby favorably impact associated economic outcomes relevant to key stakeholders.","In this study, six predictive model ensembles, including hypoglycemic events, antidiabetic medication class persistence, HbA1c target attainment, HbA1c change from baseline, T2D-related inpatient admissions, and T2D-related medical costs, were trained on a T2D population derived from administrative claims data. A retrospective cohort study design and hypothesis-free Bayesian network models were used to explore associations between thousands of unique variables, their interactions, and outcomes to identify those variables most predictive of each outcome. Model performance was moderately strong to very strong across model ensembles in held-out testing data. Notably, the hypoglycemia model performed comparably to other machine learning models applied in a similar, but more homogeneous cohort [18]. In addition, we determined that significant healthcare resource utilization was densely concentrated among patients with the highest risk of hypoglycemia, providing an estimate for the utility of our models if deployed in real-world patient populations. Previous Value-Based Analyses Historically, clinical trials and cost-effectiveness research have been the primary sources of evidence supporting value-based contracts. However, the former often fails to capture real-world scenarios involving patients outside strict control of the trial, as well as information on healthcare resource utilization and cost; while the latter (in the form of quality-adjusted life years (QALYs), incremental cost-effectiveness ratios (ICERs), etc.) often fails to capture important details of the individual patient experience [19]. This study offers an alternative solution, by leveraging predictive models applied to real-world data to (1) target interventions or risk-sharing strategies towards patients on the basis of identified adverse and/or protective factors of outcomes; or (2) target interventions or risk-sharing strategies towards patients on the basis of model predictions directly. Utility of ‚ÄúTop Predictors‚Äù Selected by Model Among variables most frequently selected by models across the ensemble, several are well established in previous literature. Notably, patients who indexed on insulin prescriptions (2.84, 2.79‚Äì3.03) and sulfonylurea prescriptions (1.80, 1.75‚Äì1.81) had increased risk of hypoglycemia, whereas patients who indexed on biguanide prescriptions (0.75, 0.74‚Äì0.75) had reduced risk. This is consistent with use of insulin being the prime cause of hypoglycemia, and sulfonylureas being a known cause, most frequently in combination with other medications. Likewise, pre-index hypoglycemia was an expected risk factor for hypoglycemia (25.61, 23.55‚Äì25.61), given that patients in this study were prevalent diabetics taking antidiabetic medications where recurrent hypoglycemia is common. Apart from antidiabetic medications, furosemide prescriptions (1.29, 1.29‚Äì1.30) were highly predictive and positively associated with hypoglycemic events and may merit further study. In particular, the association of furosemide with other conditions which are indicative of more serious diabetes could suggest an epiphenomenon, or the potential impact of kidney disease on drug metabolism. Other risk factors frequently selected by the hypoglycemia models were more specific to healthcare administration data, including Medicare plan type (vs. Commercial 1.32, 1.32‚Äì1.35), and Southern (vs. Midwest 1.39, 1.38‚Äì1.40) and Western (vs. Midwest 1.12, 1.12‚Äì1.12) regions. In addition to having the highest prevalence of diabetes in the USA, health in the South is generally worse and associated with critical risk factors including obesity and sedentary lifestyle [20]. In these models, region may proxy for these risk factors, which are not captured in claims data. Alternatively, these variables may also reflect differences in healthcare administration, or access to care across the USA and may be particularly important for rollout of a value-based contract on a national scale. Model Accuracy and Ensembling An important aspect of predictive models is their ability to perform accurately in diverse patient populations. Model ensembling is an attractive solution to the problem of overfitting on a single data set, and in some cases can be invaluable for practitioners seeking to deploy models across multiple healthcare entities‚Äîa likely case in the US marketplace. For example, an interaction between ‚Äúlow-income subsidy status‚Äù and ‚Äúproduct type: health maintenance organization (HMO)‚Äù was in 7 of 128 models in the full T2D-related inpatient admissions ensemble, implying this relationship was captured by a different set of variables in the remaining 121 models. Therefore, if the model was applied to data sets where this variable did not exist, its performance would not be significantly altered. Diverse Outcomes for Value-Based Contracting A diverse set of outcomes were explored in this study in order to capture both the clinical and economic impact of T2D. Each model, representing a distinct outcome measure, contains a set of variables that REFS determined were most predictive of the associated outcome. Importantly, many of these predictors co-occur across different outcome models. Patients with high baseline HbA1c levels, for example, were less likely to hit their HbA1c target thresholds, but more likely to experience significant changes in their HbA1c and be persistent to their antidiabetic prescriptions. Similar conclusions can be drawn from the concentration of observed outcomes within predicted risk categories of different models. In particular, patients in the top percentiles of hypoglycemia risk also constitute large proportions of other adverse clinical and economic outcomes. This may be a particularly useful result to health policymakers requiring simpler risk-adjustment schema; that is, targeting patients for preventive interventions in T2D can be done effectively through a single outcome measure (e.g., hypoglycemia) rather than attempting to solve a complex optimization problem across multiple outcomes. Furthermore, as value-based contracts must ultimately be adopted by patients and physicians to be successful, they should necessarily present clear clinical advantages and objective outcome measures, respectively [5]."
2020,Clinical characterization of data-driven diabetes subgroups in Mexicans using a reproducible machine learning approach,"Introduction Previous reports in European populations demonstrated the existence of five data-driven adult-onset diabetes subgroups. Here, we use self-normalizing neural networks (SNNN) to improve reproducibility of these data-driven diabetes subgroups in Mexican cohorts to extend its application to more diverse settings. Research design and methods We trained SNNN and compared it with k-means clustering to classify diabetes subgroups in a multiethnic and representative population-based National Health and Nutrition Examination Survey (NHANES) datasets with all available measures (training sample: NHANES-III, n=1132; validation sample: NHANES 1999‚Äì2006, n=626). SNNN models were then applied to four Mexican cohorts (SIGMA-UIEM, n=1521; Metabolic Syndrome cohort, n=6144; ENSANUT 2016, n=614‚Äâand CAIPaDi, n=1608) to characterize diabetes subgroups in Mexicans according to treatment response, risk for chronic complications and risk factors for the incidence of each subgroup. Results SNNN yielded four reproducible clinical profiles (obesity related, insulin deficient, insulin resistant, age related) in NHANES and Mexican cohorts even without C-peptide measurements. We observed in a population-based survey a high prevalence of the insulin-deficient form (41.25%, 95%‚ÄâCI 41.02% to 41.48%), followed by obesity-related (33.60%, 95%‚ÄâCI 33.40% to 33.79%), age-related (14.72%, 95%‚ÄâCI 14.63% to 14.82%) and severe insulin-resistant groups. A significant association was found between the SLC16A11 diabetes risk variant and the obesity-related subgroup (OR 1.42, 95%‚ÄâCI 1.10 to 1.83, p=0.008). Among incident cases, we observed a greater incidence of mild obesity-related diabetes (n=149, 45.0%). In a diabetes outpatient clinic cohort, we observed increased 1-year risk (HR 1.59, 95%‚ÄâCI 1.01 to 2.51) and 2-year risk (HR 1.94, 95%‚ÄâCI 1.13 to 3.31) for incident retinopathy in the insulin-deficient group and decreased 2-year diabetic retinopathy risk for the obesity-related subgroup (HR 0.49, 95%‚ÄâCI 0.27 to 0.89). Conclusions Diabetes subgroup phenotypes are reproducible using SNNN; our algorithm is available as web-based tool. Application of these models allowed for better characterization of diabetes subgroups and risk factors in Mexicans that could have clinical applications.","Clustering of data-driven diabetes subgroups is heavily influenced by variable selection. Using metabolic surrogates yielded low reproducibility of diabetes subgroups, a discrepancy which was corrected for using SNNN models. Our study confirms that SNNN models trained using population-based data can better reproduce diabetes subgroup classification using surrogate measures. Application of these models allowed for the characterization of diabetes subgroups in Mexicans using a unique combination of cohorts, which comprises a wide pathophysiological spectrum ranging prior to diabetes onset, early diagnosis and clinical trajectories, and assessing risk of chronic complications in a heterogeneous population with elevated genetic risk for diabetes.19 Ours is the first attempt to generalize diabetes subgroup classification using surrogate measures by using supervised ML algorithms. Widespread use of ML to improve research in metabolism has led to significant improvements in risk prediction.21 The use of unsupervised clustering is particularly useful in situations where C-peptide and HbA1c measurements are available for subgroup classification. By developing SNNN algorithms trained on clustered data from ethnically diverse cohorts such as NHANES, one is able to minimize the effect of surrogate measure variability in diabetes subgroup classification that unsupervised clustering would otherwise produce, resulting in profiles that are more reproducible in independent cohorts. Our approach could promote application of these subgroups in populations with a variety of risk profiles, in whom large-scale studies with C-peptide or even insulin measurements are unavailable, improving reproducibility at lower costs. Mexican population is admixed with predominant Amerindian ancestry and a higher risk of T2D compared with European populations.22 The elevated prevalence of T2D in Mexicans is the result of genetic predisposition and an increased prevalence of obesity and MS due to unhealthy lifestyles.23 Unsurprisingly, prevalence of diabetes subgroups in Mexican population did not follow reported patterns from European, US and Chinese cohorts.1 2 11 The larger prevalence of insulin-deficient cases could be attributable to poor metabolic control resulting from health-related disparities and high rates of long-standing undiagnosed diabetes in Mexicans, which was reinforced with our finding of increased SIDD prevalence in subjects with >5 years of disease and by considering that incidence for SIDD was low, despite higher risk profiles in the MS Cohort. Impaired Œ≤-cell function could result from glucotoxicity in uncontrolled diabetes, which could be reversed with prompt and adequate treatment.24 The large increase in MOD/MARD and the drastic reduction in SIDD prevalence after a 3-month multidisciplinary intervention to improve glycemic control showed that most SIDD cases were transient. In contrast with prevalence data, we also reported a large incidence of obesity-related and insulin-resistant cases, possibly influenced by the more adverse risk profile of study participants. A high prevalence of MS, hypoalphalipoproteinemia and abdominal obesity as well as earlier diabetes onset have previously been reported in Mexicans.21 23 Mexicans are more susceptible to ectopic and visceral fat accumulation, resulting in an increased cardiometabolic risk profile, which increases the risk of chronic complications,23 including DKD and NAFLD, both of which are primarily associated with SIDD/SIRD and MOD, respectively.2 11 Our data show that diabetes subgroup classification could lead to better treatment selection and risk profiling for chronic complications and support the idea that diabetes phenotypes are dynamic and should be reassessed periodically to understand clinical trajectories and reassess the risk of personalized medicine. A potential limitation of our approach is the exclusion of the SAID subgroup. Adult-onset autoimmune diabetes usually presents with acute diabetes-related complications and poor metabolic control, which increases clinical suspicion and prompts autoantibody testing, despite measures of autoantibodies varying over time. Since ML methods rely on non-readily observed patterns between variables, the use of a variable which is definitive to establish a subgroup does not benefit from this approach. Instead, future efforts to characterize and improve SAID prediction should focus on predicting who might require antibody testing and its heterogeneity might be addressed from independent cluster analysis, as has been carried out for type 1 diabetes.25 26 Finally, previous reports have suggested that autoimmune diabetes has a lower prevalence and incidence in the Mexican population compared with other populations which reduces the likelihood of undiagnosed SAID cases in our population.27 The inclusion of diverse cohorts is a robust approach; however, given that these studies were not specifically designed to investigate factors related to diabetes subgroups, the results require additional replication in independent datasets. Given the flexibility of our approach, this can be performed using a wide variety of available datasets."
2020,Use of Machine Learning Approaches in Clinical Epidemiological Research of Diabetes,"Purpose of Review Machine learning approaches-which seek to predict outcomes or classify patient features by recognizing patterns in large datasets-are increasingly applied to clinical epidemiology research on diabetes. Given its novelty and emergence in fields outside of biomedical research, machine learning terminology, techniques, and research findings may be unfamiliar to diabetes researchers. Our aim was to present the use of machine learning approaches in an approachable way, drawing from clinical epidemiological research in diabetes published from 1 Jan 2017 to 1 June 2020. Recent Findings Machine learning approaches using tree-based learners-which produce decision trees to help guide clinical interventions-frequently have higher sensitivity and specificity than traditional regression models for risk prediction. Machine learning approaches using neural networking and ""deep learning"" can be applied to medical image data, particularly for the identification and staging of diabetic retinopathy and skin ulcers. Among the machine learning approaches reviewed, researchers identified new strategies to develop standard datasets for rigorous comparisons across older and newer approaches, methods to illustrate how a machine learner was treating underlying data, and approaches to improve the transparency of the machine learning process. Machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by use of universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions.","In our review of machine learning approaches for the study of diabetes clinical epidemiology, we found three common themes. First, it is increasingly common to generate risk scores for diabetes complications, including both macrovascular and microvascular outcomes, as well as progression from pre-diabetes to diabetes, using tree-based machine learning methods such as random forest or gradient boosting machines. The literature has consistently found that these tree-based approaches may have key advantages over standard logistic or survival methods for designing a risk score. In particular, the tree-based methods have the advantage of being able to capture nonlinear interactions with greater ease in a data-driven manner and have the ability to rigorously identify subgroups with uniquely higher or low risk than the mean patient. The success of the XGBoost algorithm, in particular, demonstrates that tree-based methods can provide substantial improvements over standard logistic regression with some complex risk prediction problems. In addition, the increasing popularity of ensemble methods highlights the fact that the ideal learner for any given problem may not be known a priori, but a combination of learners can often address complex problems empirically. Effectively, this means that researchers do not have to choose a single learner; one can apply logistic regression, random forest, gradient boosting machines, and other approaches to the same problem. Additionally, the review found the usefulness of neural networking methods applied to image data analysis, particularly for the study of diabetes retinopathy and diabetic skin ulcers. The key limitation of this field is the assembly and widespread agreement on reference datasets that are judged by experts and can be used to fairly compare and train newer machine learners. Finally, our review found a common struggle among researchers to clearly explain and illustrate what variables, or relationships among variables, were causing machine learning models to improve prediction or classification of the outcomes of interest, and how to identify and communicate the internal workings of the machine learner. The three themes also relate to key insights for future research. First, the increasing popularity of machine learning model explanation methods, such as variable important ranking methods and partial dependence plots to illustrate how machine learners are using different variables, will be vital to ensuring that the machine learners can be explained and communicated. Even if such learners are being used purely for ‚ÄúBlack Box‚Äù predictions, clinicians will inevitably want to understand how the learners are working, even if such learners cannot be interpreted as causal inference tools or as providing a mechanistic explanation for an underlying relationship. Machine learning experts have increasingly used a method called locally interpretable model explanations (LIME), to provide examples of how different types of patients would be treated by a learner, effectively as a sophisticated subgroup analysis tool [128]. The LIME method may be increasingly helpful for diabetes researchers generating risk prediction, stratification, or clustering tools. Additionally, the wide application of neural networks to image analysis has shown potential but requires extensive translation into practice. In particular, due to the structure of clinical practice, it remains unclear when the clinician would benefit from consulting a machine learning model before, after, or instead of an expert peer such as an ophthalmologist or dermatologist. The risk in terms of harm to the patient and liability structures of modern medicine may make it challenging to initially adopt such technologies. Hence, it is important to plan future randomized clinical trials to evaluate the true effectiveness of these novel methods, similarly to how we would evaluate any other intervention designed to improve patient care. In the future, we anticipate that machine learners will be increasingly built into electronic health record systems, lowering the threshold and barriers to utilization, similarly to how prognostic risk models are currently built into such record systems. It therefore serves the clinician to understand the benefits and limitations of these modeling methods. In particular, although such learners increasingly have predictive power over their traditional alternatives, the most important caveat we have from reviewing the literature is that it is critical for the learners to be tested on data independent from the datasets on which they were trained. It is quite common, in our view, for machine learning authors to claim that their learners are superior to the status quo but not to test the learners on broad independent datasets from diverse populations. A related problem is that of implicit bias. Many recent machine learning commentaries have indicated that if the datasets against which the machine learners are trained have implicit biases‚Äîsuch as confusing lower diagnostic rates among minorities as being indicative of lower risk among those minority groups‚Äîthen the learners will propagate bias and inequality in the system [129]. It is imperative to sample and train learners in ways that help to detect such biases and actively reverse them, rather than assuming our most convenient datasets are necessarily accurate ones. As these problems are addressed in ongoing research studies, our review finds that machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by using universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions."
2020,Machine Learning Models for Data-Driven Prediction of Diabetes by Lifestyle Type,"The prevalence of diabetes has been increasing in recent years, and previous research has found that machine-learning models are good diabetes prediction tools. The purpose of this study was to compare the efficacy of five different machine-learning models for diabetes prediction using lifestyle data from the National Health and Nutrition Examination Survey (NHANES) database. The 1999‚Äì2020 NHANES database yielded data on 17,833 individuals data based on demographic characteristics and lifestyle-related variables. To screen training data for machine models, the Akaike Information Criterion (AIC) forward propagation algorithm was utilized. For predicting diabetes, five machine-learning models (CATBoost, XGBoost, Random Forest (RF), Logistic Regression (LR), and Support Vector Machine (SVM)) were developed. Model performance was evaluated using accuracy, sensitivity, specificity, precision, F1 score, and receiver operating characteristic (ROC) curve. Among the five machine-learning models, the dietary intake levels of energy, carbohydrate, and fat, contributed the most to the prediction of diabetes patients. In terms of model performance, CATBoost ranks higher than RF, LG, XGBoost, and SVM. The best-performing machine-learning model among the five is CATBoost, which achieves an accuracy of 82.1% and an AUC of 0.83. Machine-learning models based on NHANES data can assist medical institutions in identifying diabetes patients.","4.1. Main Findings Using five machine-learning models (CATBoost, XGBoost, RF, LR, and SVM), we attempted to predict diabetes based on lifestyle-related variables. We preprocessed the input data before training the model and used the mean to impute data with <5% missing values. In addition, we used SMOTE-NC to class-balance the data (the number of negative samples was much larger than the number of positive samples) to prevent the machine-learning model from outputting a single negative conclusion when making predictions when our dataset is class-imbalanced. Ultimately, we found that the performance ranking of the five machine-learning models was CATBoost > RF > LR > XGBoost > SVM. CATBoost has the best performance indicators among the five machine-learning models, with an AUC of 0.83 and an accuracy rate of 82.1%. Therefore, CATBoost may be employed as the best model for diabetes prediction for individuals in the prediction of machine-learning models based on or even modality variables. 4.2. Model Performance Previous studies have attempted to build machine-learning models for predicting diabetes. However, most previous studies employed random forests, logistic regression, k-nearest neighbors, and other machine learning models based on bagging algorithms to predict diabetes [45,46,47,48]. For example, Hu et al. [47] built a diabetes prediction model for adolescents using logistic regression and Gradient Boosted Tree and finally obtained a machine-learning model with an RUC of 71%. Krishnamoorthi [49] et al. An intelligent framework for diabetes prediction was constructed by applying four machine learning methods, with an RUC of 0.8 and final prediction accuracy of 83%. Although previous researchers have achieved good model results, few machine learning models for diabetes prediction based on the Boosting algorithm are still few. For example, Kumar et al. used CatBoost, logistic regression, support vector machines, and artificial neural networks to predict the probability of diabetes in gestational women and finally got an AUC of 0.86. Zhang et al. used logistic regression, support vector machines, random forests, and Catboost and Xgboost to predict childhood insulin resistance and obtained an AUC of 0.85. Using the Boosting algorithm to develop a model can better solve the problem of gradient bias and prediction offset, thereby reducing the occurrence of overfitting and improving the accuracy and generalization ability of the algorithm [45,46,47,48]. Compared with previous studies, our study optimized the previous researchers‚Äô diabetes prediction model, which achieved higher AUC and accuracy rates on easy access to characteristic variables. 4.3. Model Features As characteristic factors in our study, we selected demographics data and 18 lifestyle data from NHANES. Gender, age, race, country of birth, education level, poverty ratio, BMI, energy, protein, carbohydrates, sugar, total fat, cholesterol, smoking status, sleep duration, alcohol consumption, and systolic and diastolic blood pressure were among them. Most previous researchers [50,51,52] included biochemical indicators as an essential variable in their diabetes-prediction models. Lifestyle-related indicators have better collectability and de-aggression than biomarkers. Therefore, the model we established is independent of biochemical indicators, and our goal is to construct a practical and user-friendly screening model. Figure 2 depicts the relative importance of various variables, which is consistent with past reports [53], with sleep duration, daily nutrient intake (such as energy, carbohydrates, fat, etc.), and age being the most important variables influencing model design. Furthermore, according to Civeira‚Äôs research [54], age ranks third in feature importance as an essential demographic variable. 4.4. Model Advantage In the diabetes domain, diabetes datasets are often class-imbalanced datasets (a large number of people without diabetes and a small number of people with diabetes). Therefore, in contrast to earlier studies [46], we employed the SMOTE-NC method to deal with imbalanced class data. In contrast to prior research that did not use class imbalanced data, our machine-learning model could reduce missing and misdiagnosis rates. In addition, having too many variables in the model makes it heavy and slow. The significant increase in the data dimension will in-crease the complexity of the classification model, as well as the phenomenon of overfitting [32]. Feature selection plays an important role in traditional [55,56] and deep machine learning [57]. Thus we utilized the quantifiable AIC forward [33] propagation metric to filter the variables and eliminate the variables that contributed the least to the model. 4.5. Prospective to the Future In the future, our research will be more inclined to the field of deep learning, combining big data samples with deep learning models. In addition, we will further increase the sample size and strive to optimize the model further to have better model prediction performance."
2020,Use and performance of machine learning models for type 2 diabetes prediction in community settings: A systematic review and meta-analysis,"Objective We aimed to identify machine learning (ML) models for type 2 diabetes (T2DM) prediction in community settings and determine their predictive performance. Method Systematic review of ML predictive modelling studies in 13 databases since 2009 was conducted. Primary outcomes included metrics of discrimination, calibration, and classification. Secondary outcomes included important variables, level of validation, and intended use of models. Meta-analysis of c-indices, subgroup analyses, meta-regression, publication bias assessments and sensitivity analyses were conducted. Results Twenty-three studies (40 prediction models) were included. Studies with high-, moderate-, and low- risk of bias were 3, 14, and 6 respectively. All studies conducted internal validation whereas none conducted external validation of their models. Twenty studies provided classification metrics to varying extents whereas only 7 studies performed model calibration. Eighteen studies reported information on both the variables used for model development and the feature importance. Twelve studies highlighted potential applicability of their models for T2DM screening. Meta-analysis produced a good pooled c-index (0.812). Sources of heterogeneity were identified through subgroup analyses and meta-regression. Issues pertaining to methodological quality and reporting were observed. Conclusions We found evidence of good performance of ML models for T2DM prediction in the community. Improvements to methodology, reporting and validation are needed before they can be used at scale.","Meta-analysis demonstrated good discrimination ability of ML models for T2DM prediction in community settings, suggesting ML could enhance T2DM detection in the general population since hospital and primary care data were excluded. Nevertheless, findings should be considered cautiously given the heterogeneity, publication bias and other shortcomings. Limitations in current ML studies for T2DM prediction (Supplementary Table S21) and recommendations to overcome them (Supplementary Table S22) are discussed below. Artificial neural networks performed best, closely followed by logistic regression, decision trees and random forests. This is in tandem with recent findings by Lai et al. [50] whose prediction models built with gradient boosting and logistic regression outperformed random forest and decision trees. Moreover, linear and non-linear classifiers excelled over ensembles, confirming logistic regression could be as robust as other algorithms for certain classification tasks. A number of studies reported sparingly on study design. Studies which developed prognostic models did not always consider time-varying covariates whilst analyses were conducted cross-sectionally. This is crucial when temporal decay in predictors occur and for judging causality of associations. Also, none of the studies used algorithms amenable to longitudinal designs such as mixed-effects machine learning [51], RE-EM trees [52], or random survival forests [53]. Cross-sectional studies by default do not support causal inference but over 60 % of the studies (14/23) were cross-sectional. Although it would be prudent to restrict the sampling of a cross-sectional study to undiagnosed cases, this was not universally followed. Furthermore, biases associated with observational designs were rarely accounted for. Since subgroup analyses revealed prospective cohort and interventional studies produced more robust models than cross-sectional studies, whilst studies with low risk of bias performed better than moderately biased ones, data quality seemingly plays an important role in achieving higher predictive performances. Although thorough reporting of various dimensions of predictive performance is essential to determine the value of a prediction model, studies often lacked adequate information on predictive performance. Most studies described a single dimension of predictive performance; c-index or classification accuracy. Confusion matrices were presented sparingly. Moreover, uncalibrated models are likely to be of limited use in real-world scenarios [54]. Therefore, detailed reporting of model performance, consisting of information such as classification, discrimination, calibration measures, variable importance, applicability, and acceptability, is recommended. Noteworthily, none of the studies conducted external validation, creating uncertainty about their generalizability. Multiple internal validation methods, though could be more efficient, were applied only by 1 study. Even when large samples feasible for random splitting were available, some studies resorted to cross-validation, which is likely to be less efficient than random partitioning, as the validation is done on alternating sub-samples of the same data used for training models. A recent study concluded cross-validation is insufficient for ML model validation [55]. Models devoid of stringent validation offer limited applicability. Therefore, we recommend at least a thorough internal validation is performed before ML prediction models are used at scale. Methodological flaws were seen in several areas specific to ML approach. Only 8 studies conducted hyperparameter tuning and feature selection. Sample size was unduly small in some studies, the smallest being 234 and less than 1000 in 4 studies. Machine learning, by default, is effective with large samples as they account for multi-dimensionality [56]. Also, smaller studies are less likely to be of broad public health significance. Although class imbalance was prevalent, few studies attempted to address it with recommended techniques such as resampling [57] and cost-sensitive learning [58]. As this is encountered in many disease conditions, it is imperative that class imbalance handling is incorporated into future guidelines. Despite the ability of ML to tackle multidimensionality, majority of studies (n‚ÄØ=‚ÄØ16) used less than 20 features for modelling. As ML is evolving from its ‚Äúblack box‚Äù paradigm to more interpretable stages, a narrow focus on predictive performance per se is unwarranted and further insights into underlying dynamics are expected [59]. For example, most algorithms currently produce measures of variable importance in addition to predictive performance metrics [60,61]. However, 3 studies did not contain any information on important predictors. Since ML is an iterative ‚Äútrial and error‚Äù process, combined use of algorithms, preferably a mix of linear, non-linear, and ensemble learners would be best to generate an optimal model. However, such extensive modelling approaches were not frequently adopted. For instance, only 14 studies used multiple algorithms while 9 were developed using a single linear or non-linear algorithm. Unsupervised ML, which could discover underlying structures and patterns of multidimensional data [62], were sparingly used. Also, hybrid algorithms combining steps such as pre-processing, feature selection and modelling together, or with other techniques such as systems dynamics, although known to perform well [63,64], were not applied. A range of biases was identified by a recent systematic review of ML clinical prediction models which highlighted the need for improvements in methodology and reporting [65]. The current review demonstrated that these drawbacks prevailed in community-based studies as well. Inverse associations between predictive performance and ethically-approved studies and those conducted in low- or middle-income countries are intriguing. Presumably, due to the nature of data sources, ethics approval may not have been required from the countries within which the studies were conducted. Regardless, these findings point to the importance of conducting a comprehensive evaluation of the methods employed in predictive modelling without solely focusing on predictive performance. Lack of reporting standards in ML modelling studies to assist in systematic reviews was a challenge. Related guidelines such as CHARMS [34] and TRIPOD [35] have not incorporated unique features that should be assessed in ML models. Furthermore, PROBAST guidelines [37] also have not incorporated certain biases associated with ML. Also, guidelines are required to inform researchers on feature selection, as this was altogether omitted or conducted in an ad hoc manner using diverse methods. Perhaps due to lack of reporting guidelines, we observed variations of the extent and style of reporting of studies across journals. Therefore, a set of guidelines for conducting, reporting, and evaluating ML predictive modelling studies in healthcare, is recommended. While high discrimination ability was achieved by majority of models, issues of applicability, feasibility, and translatability were not sufficiently discussed by respective studies. Two studies had no clear presentation of the developed models as formulas or graphically whilst eleven studies did not develop any prediction tools. This perhaps indicates lack of emphasis on translating ML models into scalable products. Moreover, 5 studies did not present clear information about intended use of their models. Therefore, translation of these prediction models into broader use such as population-wide screening is likely to face obstacles."
2020,Use of Machine Learning Approaches in Clinical Epidemiological Research of Diabetes,"Purpose of Review Machine learning approaches‚Äîwhich seek to predict outcomes or classify patient features by recognizing patterns in large datasets‚Äîare increasingly applied to clinical epidemiology research on diabetes. Given its novelty and emergence in fields outside of biomedical research, machine learning terminology, techniques, and research findings may be unfamiliar to diabetes researchers. Our aim was to present the use of machine learning approaches in an approachable way, drawing from clinical epidemiological research in diabetes published from 1 Jan 2017 to 1 June 2020. Recent Findings Machine learning approaches using tree-based learners‚Äîwhich produce decision trees to help guide clinical interventions‚Äîfrequently have higher sensitivity and specificity than traditional regression models for risk prediction. Machine learning approaches using neural networking and ‚Äúdeep learning‚Äù can be applied to medical image data, particularly for the identification and staging of diabetic retinopathy and skin ulcers. Among the machine learning approaches reviewed, researchers identified new strategies to develop standard datasets for rigorous comparisons across older and newer approaches, methods to illustrate how a machine learner was treating underlying data, and approaches to improve the transparency of the machine learning process. Summary Machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by use of universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions.","In our review of machine learning approaches for the study of diabetes clinical epidemiology, we found three common themes. First, it is increasingly common to generate risk scores for diabetes complications, including both macrovascular and microvascular outcomes, as well as progression from pre-diabetes to diabetes, using tree-based machine learning methods such as random forest or gradient boosting machines. The literature has consistently found that these tree-based approaches may have key advantages over standard logistic or survival methods for designing a risk score. In particular, the tree-based methods have the advantage of being able to capture nonlinear interactions with greater ease in a data-driven manner and have the ability to rigorously identify subgroups with uniquely higher or low risk than the mean patient. The success of the XGBoost algorithm, in particular, demonstrates that tree-based methods can provide substantial improvements over standard logistic regression with some complex risk prediction problems. In addition, the increasing popularity of ensemble methods highlights the fact that the ideal learner for any given problem may not be known a priori, but a combination of learners can often address complex problems empirically. Effectively, this means that researchers do not have to choose a single learner; one can apply logistic regression, random forest, gradient boosting machines, and other approaches to the same problem. Additionally, the review found the usefulness of neural networking methods applied to image data analysis, particularly for the study of diabetes retinopathy and diabetic skin ulcers. The key limitation of this field is the assembly and widespread agreement on reference datasets that are judged by experts and can be used to fairly compare and train newer machine learners. Finally, our review found a common struggle among researchers to clearly explain and illustrate what variables, or relationships among variables, were causing machine learning models to improve prediction or classification of the outcomes of interest, and how to identify and communicate the internal workings of the machine learner. The three themes also relate to key insights for future research. First, the increasing popularity of machine learning model explanation methods, such as variable important ranking methods and partial dependence plots to illustrate how machine learners are using different variables, will be vital to ensuring that the machine learners can be explained and communicated. Even if such learners are being used purely for ‚ÄúBlack Box‚Äù predictions, clinicians will inevitably want to understand how the learners are working, even if such learners cannot be interpreted as causal inference tools or as providing a mechanistic explanation for an underlying relationship. Machine learning experts have increasingly used a method called locally interpretable model explanations (LIME), to provide examples of how different types of patients would be treated by a learner, effectively as a sophisticated subgroup analysis tool [128]. The LIME method may be increasingly helpful for diabetes researchers generating risk prediction, stratification, or clustering tools. Additionally, the wide application of neural networks to image analysis has shown potential but requires extensive translation into practice. In particular, due to the structure of clinical practice, it remains unclear when the clinician would benefit from consulting a machine learning model before, after, or instead of an expert peer such as an ophthalmologist or dermatologist. The risk in terms of harm to the patient and liability structures of modern medicine may make it challenging to initially adopt such technologies. Hence, it is important to plan future randomized clinical trials to evaluate the true effectiveness of these novel methods, similarly to how we would evaluate any other intervention designed to improve patient care. In the future, we anticipate that machine learners will be increasingly built into electronic health record systems, lowering the threshold and barriers to utilization, similarly to how prognostic risk models are currently built into such record systems. It therefore serves the clinician to understand the benefits and limitations of these modeling methods. In particular, although such learners increasingly have predictive power over their traditional alternatives, the most important caveat we have from reviewing the literature is that it is critical for the learners to be tested on data independent from the datasets on which they were trained. It is quite common, in our view, for machine learning authors to claim that their learners are superior to the status quo but not to test the learners on broad independent datasets from diverse populations. A related problem is that of implicit bias. Many recent machine learning commentaries have indicated that if the datasets against which the machine learners are trained have implicit biases‚Äîsuch as confusing lower diagnostic rates among minorities as being indicative of lower risk among those minority groups‚Äîthen the learners will propagate bias and inequality in the system [129]. It is imperative to sample and train learners in ways that help to detect such biases and actively reverse them, rather than assuming our most convenient datasets are necessarily accurate ones. As these problems are addressed in ongoing research studies, our review finds that machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by using universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions."
2020,Prediction of progression from pre-diabetes to diabetes: Development and validation of a machine learning model,"Aims Identification, a priori, of those at high risk of progression from pre-diabetes to diabetes may enable targeted delivery of interventional programmes while avoiding the burden of prevention and treatment in those at low risk. We studied whether the use of a machine-learning model can improve the prediction of incident diabetes utilizing patient data from electronic medical records. Methods A machine-learning model predicting the progression from pre-diabetes to diabetes was developed using a gradient boosted trees model. The model was trained on data from The Health Improvement Network (THIN) database cohort, internally validated on THIN data not used for training, and externally validated on the Canadian AppleTree and the Israeli Maccabi Health Services (MHS) data sets. The model's predictive ability was compared with that of a logistic-regression model within each data set. Results A cohort of 852‚Äâ454 individuals with pre-diabetes (glucose ‚â•‚Äâ100‚Äâmg/dL and/or HbA1c‚Äâ‚â•‚Äâ5.7) was used for model training including 4.9 million time points using 900 features. The full model was eventually implemented using 69 variables, generated from 11 basic signals. The machine-learning model demonstrated superiority over the logistic-regression model, which was maintained at all sensitivity levels ‚Äì comparing AUC [95% CI] between the models; in the THIN data set (0.865 [0.860,0.869] vs 0.778 [0.773,0.784] P <‚Äâ.05), the AppleTree data set (0.907 [0.896, 0.919] vs 0.880 [0.867, 0.894] P <‚Äâ.05) and the MHS data set (0.925 [0.923, 0.927] vs 0.876 [0.872, 0.879] P <‚Äâ.05). Conclusions Machine-learning models preserve their performance across populations in diabetes prediction, and can be integrated into large clinical systems, leading to judicious selection of persons for interventional programmes.","We hereby describe the training of a machine learning model in the prediction of progression from pre-diabetes to diabetes in a large population. This model is unique in its nonlinearity, versatility, and ability to predict diabetes continuously. The predictive ability of the model was superior to alternative methods of risk stratification of pre-diabetes individuals such as the use of logistic regression or clinically acceptable cut-offs. Furthermore, it can be used to predict progression to diabetes over short or long time-periods, while compromising its predictive ability in longer time-frame predictions, yet maintaining superiority over other predictive methods. Several aspects of the model merit further discussion. The model is versatile and enables the user to choose the sensitivity most suitable to the particular clinical condition or intended intervention, considering its cost, risk-benefit ratio and the available budget. Thus, for example, we may consider its use in two extreme clinical situations. 1. Delivery of a costly intervention ‚Äì for example, an intensive lifestyle programme. For this purpose, the health administration may wish to identify a small population (low PR) with a high PPV ‚Äì aiming to treat only those who are at extremely high risk. Use of this model compared to simple logistic regression will allocate a smaller number of persons to the intervention. 2. Delivery of a low-cost/low risk intervention ‚Äì for example, the prescription of metformin. Choosing a higher sensitivity threshold may better address this goal, and with the use of the model the number needed to treat will be smaller. In this scenario, the majority of the people receiving treatment would probably not have developed diabetes during the subsequent year, yet the treatment generally carries a low risk and is justified. Unsurprisingly, glucose and HbA1c, including all their derived parameters, were the strongest contributors to the model. Use of statins had a modest contribution to the model supporting their minor role in progression to diabetes. Of note, even when compromising on a low sensitivity the positive predictive value of the model was only ~50% highlighting the inherent biological difficulty of predicting diabetes. Progression to diabetes is dependent upon multiple factors, many of which cannot be captured in any medical database including personal decisions for lifestyle modification, environmental circumstances and supporting ecosystem. Interestingly, in the majority of the THIN cohort an HbA1c level was not available, a situation reflective of an overall low-risk population, in which HbA1c is justifiably not used as a screening test. Our model may assist in highlighting those high-risk individuals in whom an HbA1c test, or an OGTT may be considered, which may diagnose pre-existing diabetes. Additionally, the model calculates the risk continuously, thus at any point in time it is possible to assess the individual risk of each person irrespective of whether laboratory measurements were taken at the time. Consequently, the model may be used to dictate individualized testing intervals rather than the global annual testing proposed by the ADA.26 Previous studies have assessed the clinical utility of various prediction models for assessment of the risk of developing diabetes. Abbasi et al. reviewed 25 prediction models and noted that most can identify people at high risk of developing diabetes within 5 to 10‚Äâyears, yet the diabetes risk was generally overestimated.16 Additionally, models which included biomarkers performed slightly better than the classic models.16 Risk assessment based on biomarkers has been shown to be superior to a risk score based on non-laboratory parameters in a Korean population,17 although the combination of the Finish Diabetes Risk Score and HbA1c improved the sensitivity and specificity of detection of diabetes and pre-diabetes in an American population.18 Multiple biomarkers such as CRP, ALT and GGT have been used to identify the risk of progression to diabetes. A recent systematic review which assessed the ability of over 150 biomarkers to predict incident diabetes concluded that these failed to improve prediction over a model consisting of the traditional diabetes predictors, glucose and HbA1c.19 The above models are limited in their reliance upon measurements in a single point in time, generally the last available. However, the progression of pre-diabetes to diabetes follows a non-linear trajectory and often persons initially oscillate around the threshold until they present with overt diabetes.8 Recent adoption of electronic medical records (EMR) provides us with the opportunity to use data spanning over a decade or more for more accurate prediction. As shown in our sensitivity analysis, use of data spanning over 3 to 5‚Äâyears is also of benefit, however the predictive ability of the model while using 1-year historical data is significantly limited. Whereas the ease and scalability of the predictions and possible integration within the EMR are clear advantages of this approach, the use of EHR is currently, for the most, limited to numerical or coded data. Lifestyle related information, family history, socioeconomics, smoking status and other patient related information are often not coded, or the coding is unreliable, and are therefore not included in the EMR based models. Future advances in natural language processing approaches may overcome this barrier to some extent. The use of machine learning models, as opposed to linear models, carries the capability of capturing subtle multivariate relationships which may be otherwise difficult to detect. Additionally, machine learning methods have the capability of dealing with large numbers of variables whiles producing powerful predictive models.27 Employment of these methods in the predictions of diabetes has been described in several studies, yet these were based on small and select populations (less than 10‚Äâ000 individuals) limiting the generalizability of the results.27 The strength of our study lies in the inclusion of >1 million individuals with pre-diabetes and the use of modern machine learning techniques. Moreover, the continuity, versatility and flexibility of our model enable its employment in multiple clinical set-ups. However, several limitations of our study should be noted. Similar to other studies based upon EMR, our study does not take into account parameters such as exercise schedule, family history of diabetes or adherence to any dietary regimen. Additionally, waist circumference which is an important predictor of diabetes beyond BMI is not reliably available in the data. Furthermore, the definition of the pre-diabetes and diabetes registries did not include OGTT, which is a more sensitive criterion, yet was not available in our databases, since it is not commonly performed in standard clinical care. Additionally, we did not include comorbidities, diagnoses, procedures, and READ codes in the features of our model. We restricted our model to the use of features, such as lab data and drugs code groups, which are more easily transferred between different data sources, allowing the option for simpler future external validation on different data sources. Nevertheless, the inclusion of these data may have improved our results. In conclusion, we describe the employment of a machine learning model to predict the progression to diabetes in over 1 million persons with pre-diabetes during an average 5‚Äâyears of follow up. The model may be incorporated in the EMRs and alert for screening intervals or enable selection of high-risk individuals for interventional programmes, demonstrating a better PPV than current alternatives."
2021,Predicting adverse outcomes due to diabetes complications with machine learning using administrative health data,"Across jurisdictions, government and health insurance providers hold a large amount of data from patient interactions with the healthcare system. We aimed to develop a machine learning-based model for predicting adverse outcomes due to diabetes complications using administrative health data from the single-payer health system in Ontario, Canada. A Gradient Boosting Decision Tree model was trained on data from 1,029,366 patients, validated on 272,864 patients, and tested on 265,406 patients. Discrimination was assessed using the AUC statistic and calibration was assessed visually using calibration plots overall and across population subgroups. Our model predicting three-year risk of adverse outcomes due to diabetes complications (hyper/hypoglycemia, tissue infection, retinopathy, cardiovascular events, amputation) included 700 features from multiple diverse data sources and had strong discrimination (average test AUC‚Äâ=‚Äâ77.7, range 77.7‚Äì77.9). Through the design and validation of a high-performance model to predict diabetes complications adverse outcomes at the population level, we demonstrate the potential of machine learning and administrative health data to inform health planning and healthcare resource allocation for diabetes management.","This research demonstrated the feasibility of applying machine learning methods to administrative health data for public health planning. Our model can predict the 3-year risk of adverse outcomes due to diabetes complications (hyper/hypoglycemia, tissue infection, retinopathy, cardiovascular events, and amputation) with a test AUC of 77.7 (range 77.7‚Äì77.9, Fig. ‚ÄãFig.2).2). It was not our goal for this model to be used for individual level patient care. Our model was trained on data from over 1.5 million patients from Ontario, which is among one of the most diverse populations in the world and, to our knowledge, one of the largest prediction modelling studies that takes into account multiple types of diabetes complications22‚Äì34,51‚Äì53. Our model was also well-calibrated and showed good discrimination. While diabetes complications have been better managed in recent years, they remain a large burden because the incidence of diabetes continues to grow and even in the presence of interventions, not all cases can be prevented54. Thus, there is a need to effectively manage diabetes complications at both the individual patient and system levels. This is further emphasized as increasing age and years lived with diabetes have been found to independently predict diabetes morbidity and mortality55. Moreover, it has been well established that the complications of diabetes drive costs4,5. In Ontario alone, with a population of 14.5 million in 2019, adverse outcomes due to diabetes complications had an annual cost of over $3.9 billion, making diabetes a critical condition that warrants investment into analytic data-driven solutions for health system planning. Health systems planning, for diabetes and other conditions, requires accurate assessments of population risk35,36. From the cost analysis in Fig. ‚ÄãFig.4b,4b, we observe that the top 1% of most at-risk patients predicted by our model account for over $440‚ÄâM or 11% of the overall annual cost. This increases to over $850‚ÄâM or nearly 22% of the top 3% of patients‚Äô total cost. In contrast, random selection would only capture 1% and 3% of the cost, respectively. Targeting policy interventions (e.g., subsidizing access to fruits and vegetables, community planning to facilitate active transportation) and resource allocation (e.g., incentivizing physicians to have more intensive diabetes follow-up care, either virtually or in-person) to communities projected at highest risk based on our model outputs could help maximize their effectiveness in changing the trajectories of diabetes complications11,36. The observed differences in model calibration across complication type may be impacted by the inclusion of both episodic and progressive types of diabetes complications, which by nature have a different epidemiology and trajectory2. More specifically, episodic complications, such as tissue infection, can be treated and recur multiple times, whereas progressive complications, such as cardiovascular disease, generally result over an elongated period of time due to chronic damage to the organ system2. The overprediction of high-risk individuals could also be due to the relationship between age and years lived with diabetes as key drivers of complications55. Finally, it is possible that our overprediction of those at high risk could be due to the lack of valuable clinical features such as body mass index, smoking status, biomarkers in AHD. At the population level, applications that overpredict would still be appropriate for targeting resources and identifying individuals that would benefit from closer follow-up, including the use of other prediction models which include biomarkers and other individual risk factors. The analysis of top features in Fig. ‚ÄãFig.33 provides insight into the types of information used by our model to make predictions for each complication. Explainability is a major benefit of decision tree models, and is one of the main reasons why we focus on decision trees for this study. Administrative health databases typically have billions of records spread across multiple datasets making it highly challenging to work with. Moreover, predictive patterns inferred by the model at this scale can identify new trends at the population level (or validate existing hypotheses)56. In Fig. ‚ÄãFig.3,3, we observe that socio-demographic factors such as length of stay in Canada for immigrants and ethnic concentration in the area of residence, play an important role in model prediction. We consistently found that features based on immigration status, age/sex, area of residence (particularly census statistics such as neighbourhood-level income, unemployment, ethnic concentration etc.) and other related information appeared within the top 20 most predictive features. This is also observed from Fig. ‚ÄãFig.4d,4d, which shows that there are significantly fewer immigrants and lower ethnicity marginalization in the top 1% of the most at-risk patients predicted by the model as compared to the full cohort. Lower proportion of immigrants aligns with previous studies showing that immigrants have a different diabetes trajectory and are less at risk for these complications57. Clinical prediction models generally exclude such types of features and mainly focus on health data for each patient. Our results indicate that the social determinants of health, even at the census level, can be highly predictive for severe health outcomes. Thus the application of a model such as ours for population health planning, which leverages detailed information on the social determinants to allocate resources and plan policies to improve diabetes complications outcomes could offer a data-driven approach to addressing health disparities58‚Äì60. Our study features a number of important strengths and contributions. The proposed model was developed and tested on a large cohort of over 1.5 million patients with minimal exclusion criteria, capturing virtually all incidences of target adverse outcomes. The cohort is ethnically diverse, with wide representation from across world regions. We demonstrate the applicability of machine learning methods using population data available in multiple jurisdictions around the world. We conducted extensive feature engineering and selection to capture correlations between different AHD sources and target outcomes. The final model has over 700 features from a variety of datasets such as demographics, census information, laboratory results, diagnosis history, physician billing claims, hospitalization and ambulatory usage, prescription medication history and others. Given the nature of administrative data, we believe that our approach could be applied for the forecasting of other chronic diseases at the population level. This is especially important given rising rates of multimorbidity internationally. One study in 2009 found that 24.3% of Ontarians were diagnosed with multiple comorbidities61. Since AHD is thought to be the most basic level of information collected by a healthcare system, we believe that our approach to population-level risk prediction would be feasible in other jurisdictions with universal health coverage and databases suitable for linkage such as the Scandinavian countries, United Kingdom, Australia, and New Zealand or within large private insurers in the United States. Finally, modern machine learning approaches are often criticized for lack of interpretability, and are sometimes referred to as black-box models62. Using a model based on decision trees enabled us to determine which features are important for prediction, and how they are combined inside the model. This is important for transparency and practical deployment of such systems that clinical and health system specialists need to be audited. Despite the mentioned strengths, our study also has several important limitations. First, we are limited by the algorithm that we used to flag diabetes and build our cohort42. This ‚Äú2-claim‚Äù algorithm has a specificity of 97%, meaning that there are almost no healthy patients in our cohort. However, its 86% sensitivity means that we did not capture all patients diagnosed with diabetes. Moreover, we are working with a joint cohort of patients diagnosed with type 1 and patients diagnosed with type 2. While patients diagnosed with both types share the complications and adverse outcomes we explored in this paper, their diabetes trajectory differs, with type 1 patients typically being diagnosed at a much younger age2. We considered using a validated type 1 diabetes algorithm63 to identify and remove the type 1 subcohort, but with a sensitivity of 80.6% on administrative health data, it would leave out hundreds of patients diagnosed with type 1 in our cohort. We argue that it is preferable for a system-level analysis to predict adverse outcomes of diabetes complications from both patients diagnosed with type 1 and patients diagnosed with type 2 since systems-level barriers are shared between the two populations11. We focused on hospitalization and ambulatory care service usage due to diabetes complications. Hence, we do not account for associated adverse events treated in the primary care settings as they could not be identified accurately in our data. In addition, we lacked prescription information for individuals under 65 years old (Ontario‚Äôs health system provides age-based drug coverage for individuals 65 years and older and those receiving social assistance). If available, they may improve predictive performance even further. More generally, as AHD systems around the world are being increasingly integrated with other data sources such as EHRs, we can believe that our models could be retrained to leverage newly linked databases, with increased discriminative performance. However, as it has been shown with EHRs64, one must always keep in mind that AHD reflect not only the health state of a patient but also the interactions they had with the healthcare system. Our temporal sliding window framework is robust to the bias of events in the administrative data reflecting past true health states (time of diagnosis is posterior to the time when symptoms started). Our model learns correlations between observed events and target adverse outcomes. Most of these correlations are not causal, and cannot be used to explain why a specific outcome has occurred. Inferring causal relationships would require a different conceptual and analytic framework, which is for future work65. Finally, as with other predictive models, external validation with recalibration and prospective validation as well as monitoring for distribution shifts over time would be important to conduct prior to widespread implementation and adoption. In conclusion, we outline the development and validation of a machine learning model to predict adverse outcomes due to a range of diabetes complications three years ahead at the population level using routinely collected administrative data. We believe that after such models are externally and prospectively validated, public health officials will have a powerful tool for the ongoing risk assessment and cost-effective targeting of prevention efforts and resource allocation related to diabetes complications care at a population-scale."
2021,Development and Validation of a Machine Learning Model Using Administrative Health Data to Predict Onset of Type 2 Diabetes,"Importance Systems-level barriers to diabetes care could be improved with population health planning tools that accurately discriminate between high- and low-risk groups to guide investments and targeted interventions. Objective To develop and validate a population-level machine learning model for predicting type 2 diabetes 5 years before diabetes onset using administrative health data. Design, Setting, and Participants This decision analytical model study used linked administrative health data from the diverse, single-payer health system in Ontario, Canada, between January 1, 2006, and December 31, 2016. A gradient boosting decision tree model was trained on data from 1‚Äâ657‚Äâ395 patients, validated on 243‚Äâ442 patients, and tested on 236‚Äâ506 patients. Costs associated with each patient were estimated using a validated costing algorithm. Data were analyzed from January 1, 2006, to December 31, 2016. Exposures A random sample of 2‚Äâ137‚Äâ343 residents of Ontario without type 2 diabetes was obtained at study start time. More than 300 features from data sets capturing demographic information, laboratory measurements, drug benefits, health care system interactions, social determinants of health, and ambulatory care and hospitalization records were compiled over 2-year patient medical histories to generate quarterly predictions. Main Outcomes and Measures Discrimination was assessed using the area under the receiver operating characteristic curve statistic, and calibration was assessed visually using calibration plots. Feature contribution was assessed with Shapley values. Costs were estimated in 2020 US dollars. Results This study trained a gradient boosting decision tree model on data from 1 657 395 patients (12 900 257 instances; 6 666 662 women [51.7%]). The developed model achieved a test area under the curve of 80.26 (range, 80.21-80.29), demonstrated good calibration, and was robust to sex, immigration status, area-level marginalization with regard to material deprivation and race/ethnicity, and low contact with the health care system. The top 5% of patients predicted as high risk by the model represented 26% of the total annual diabetes cost in Ontario. Conclusions and Relevance In this decision analytical model study, a machine learning model approach accurately predicted the incidence of diabetes in the population using routinely collected health administrative data. These results suggest that the model could be used to inform decision-making for population health planning and diabetes prevention.","This decision analytical model study found that accurate prediction of type 2 diabetes onset at the population level 5 years in advance was possible solely from routinely collected administrative health data for the purposes of public health planning and health resource allocation. It was not our goal for this model to be applied in the context of individual patient care. Our model was trained and validated on more than 2 million patients, which, to our knowledge, is one of the largest cohorts for predicting diabetes incidence. Our model showed consistent calibration across sex, immigration status, racial/ethnic and material deprivation, and a low to moderate number of events in the health care history of the patient. The cohort was representative of the whole population of Ontario, which is itself among the most diverse in the world.50 The model was well calibrated, and its discrimination, although with a slightly different end goal, was competitive with results reported in the literature for other machine learning‚Äìbased studies that used more granular clinical data from electronic medical records without any modifications to the original test set distribution.23,24,25 Assessing risk in populations is the basis of health system planning and a critical element of diabetes prevention.51,52 When managing risk in populations, there are critical questions regarding the most efficient usage of resources, and without a comprehensive estimate of risk in populations, strategies can be costly and ineffective. Furthermore, it is widely recognized that the prevention of diabetes is not only influenced by factors at the individual level but must be complemented by whole population approaches, such as food policies and environmental changes.6 The use of machine learning methods for predicting risk in populations offers an important opportunity to inform resource and policy-level decisions that can change diabetes risk trajectories as well as allow for more efficient targeting of resources within a health system. The growing burden of diabetes is a challenge faced by other jurisdictions across the globe.1,2,3 Continuous risk assessment using the multi-instance approach we proposed could reduce this cost through the targeting of preventive health measures, even more so given the fact that our model did not require additional data collection. Such an approach could be feasible in countries such as the UK, Australia, New Zealand, and the Scandinavian countries, which have large, administrative databases suitable for linkage.53,54,55,56,57 Furthermore, this approach could also be deployed in populations covered under a singular health insurance system, such as Medicare or private insurers.58 Our features not only captured each patient‚Äôs medical history but also included the social and demographic determinants of health, which are important predictors of a patient‚Äôs overall risk of developing diabetes and are often missing in clinical data sources.59,60,61 Moreover, the calibration of our machine learning model across demographic subgroups suggests that it may be possible to apply it to target-specific population segments with preventive measures (Table 2 and Figure 3). Diabetes prevention strategies can be targeted toward those above a certain risk threshold.62 Our model results suggest that older patients from the most marginalized neighborhoods in terms of race/ethnicity and material deprivation were at the highest risk and may therefore benefit the most from preventive measures. Given the growing costs associated with the diabetes cohort, our work suggests a quantitative financial incentive toward the direction of preventive measures that consider those at greatest risk, including from a socioeconomic perspective.59 Because our machine learning model included social determinants of health that are known to contribute to diabetes risk, our population-wide approach to risk assessment may represent a tool for addressing health disparities.59,63,64"
2021,Prediction of Type 2 Diabetes Based on Machine Learning Algorithm,"Prediction of type 2 diabetes (T2D) occurrence allows a person at risk to take actions that can prevent onset or delay the progression of the disease. In this study, we developed a machine learning (ML) model to predict T2D occurrence in the following year (Y + 1) using variables in the current year (Y). The dataset for this study was collected at a private medical institute as electronic health records from 2013 to 2018. To construct the prediction model, key features were first selected using ANOVA tests, chi-squared tests, and recursive feature elimination methods. The resultant features were fasting plasma glucose (FPG), HbA1c, triglycerides, BMI, gamma-GTP, age, uric acid, sex, smoking, drinking, physical activity, and family history. We then employed logistic regression, random forest, support vector machine, XGBoost, and ensemble machine learning algorithms based on these variables to predict the outcome as normal (non-diabetic), prediabetes, or diabetes. Based on the experimental results, the performance of the prediction model proved to be reasonably good at forecasting the occurrence of T2D in the Korean population. The model can provide clinicians and patients with valuable predictive information on the likelihood of developing T2D. The cross-validation (CV) results showed that the ensemble models had a superior performance to that of the single models. The CV performance of the prediction models was improved by incorporating more medical history from the dataset.","This study proposed a machine learning model to predict the occurrence of T2D in the following year. While previous works in [21] and [53] developed a scheme for forecasting the occurrence of diabetes, this paper dealt with the possible transition among three classes: normal, prediabetes, and diabetes. Few studies have addressed the prediction of prediabetes, as most research has been focused on the prediction of undiagnosed diabetes. In this study, a large dataset and ensemble ML techniques were employed to develop the prediction models as compared to the studies mentioned above. Furthermore, the impact of the cumulated medical data on the prediction accuracy was also presented by changing the number of years used to train the models. A data-driven feature selection was employed to find predictors that were significant for detecting the distinct classes in the dataset. The resultant 12 features were FPG, HbA1c, triglycerides, BMI, gamma-GTP, age, uric acid, sex, smoking, drinking, physical activity, and family history. FPG and HbA1c were the most important predictors based on the information-gain criteria; they were followed by gamma-GTP, BMI, triglycerides, and age. Compared to using the traditional five predictors of T2D (FPG, HbA1c, BMI, age, and sex), the proposed models employing the selected features showed a superior prediction performance. When four years of data were utilized in training, the maximum CV accuracy was 81% for the selected features and 77% for the traditional features. It can be concluded that the additional seven features contributed to improved accuracy of prediction. We also note that in addition to the traditional predictors, clinicians must pay attention to the changes in gamma-GTP, uric acid, and triglycerides over the years. The study presented in [5] reported the application of an ML model to identify the occurrence of prediabetes in advance. In their study, they have indicated the difficulties of predicting the prediabetes condition. The best accuracy presented was 69.9% for the KNHANES dataset. Our experimental results have shown a better prediction performance in predicting the occurrence of not only diabetes and normal but also the prediabetes condition too. The highest CV classification accuracy observed was 78% by using last year‚Äôs medical records as training data. However, the performance of the prediction model was improved by increasing the number of years to train the models. The study presented in [53] reported a comparison of three data mining models for predicting diabetes or prediabetes by risk factors. The dataset for the study was collected from two communities in Guangzhou, China: 735 patients confirmed to have diabetes or prediabetes and 752 normal controls. The risk factors (predictors) used were age, family history of diabetes, marital status, education level, work stress, duration of sleep, physical activity, preference for salty food, gender, eating fish, drinking coffee, and body mass index. Three ML algorithms: logistic regression, artificial neural networks (ANNs), and decision tree models were employed for predicting diabetes or prediabetes using the predictors. The decision tree model (C5.0) had the best classification accuracy (77.87%), followed by the logistic regression model (76.13%), and the ANN gave the lowest accuracy (73.23%). LR, RF, SVM, XGBoost, CIM, stacking classifier, and soft voting algorithms were utilized to generate the prediction models. Experimental results showed that the generated prediction models performed slightly better than the LR model, the existing statistical analysis method. However, the performance difference among the algorithms was negligible on the test data. This can be explained by class overlap in the feature space. The prediabetes class especially had a high degree of class overlap with normal and diabetes classes. The confusion matrix results confirmed that most of the prediction errors were from the prediabetes class. This lowered the overall performance of the prediction models and limited the maximum accuracy to 73%. The CV results showed a significant performance difference among the prediction models. The ensemble models (CIM, ST, and SV) had a superior CV performance to that of the single models including LR. The CV performance of the prediction models was improved by incorporating more medical history from the dataset. Overall, the results of the present study demonstrated that the generated prediction models performed better than the existing clinical screening model (LR). The application of the developed prediction models and findings of this study redound to the benefit of both clinicians and patients. The models can be used as viable support in clinical decision-making and patient counseling for practitioners. Furthermore, early prediction of the disease enables diabetes patients and those at risk for diabetes to take preventive measures that can delay the progression of the disease and its life-threatening complications. This study has certain limitations. First, FPG level was the only measurement that was used to define normal, prediabetes, and diabetes; HbA1c and oral glucose tolerance test (OGTT) were not taken into consideration. However, the use of FPG level was consistent with the model developed by [5,54]. Second, in this study 10-fold cross-validation was utilized in the evaluation of the models. However, the development and validation of the models were conducted with only one dataset. Thus, it is compulsory to utilize additional data sources to verify the models derived in this study. Our study suggests two additional investigations that are worth pursuing. The first would be to incorporate diverse datasets to mitigate the difficulty of classifying prediabetes, which stems from the overlap with normal and diabetes classes. The second would be to increase the accessibility of the prediction models and improve the user experience for web and mobile applications."
2021,Early Prediction of Gestational Diabetes Mellitus in the Chinese Population via Advanced Machine Learning,"Context Accurate methods for early gestational diabetes mellitus (GDM) (during the first trimester of pregnancy) prediction in Chinese and other populations are lacking. Objectives This work aimed to establish effective models to predict early GDM. Methods Pregnancy data for 73 variables during the first trimester were extracted from the electronic medical record system. Based on a machine learning (ML)-driven feature selection method, 17 variables were selected for early GDM prediction. To facilitate clinical application, 7 variables were selected from the 17-variable panel. Advanced ML approaches were then employed using the 7-variable data set and the 73-variable data set to build models predicting early GDM for different situations, respectively. Results A total of 16 819 and 14 992 cases were included in the training and testing sets, respectively. Using 73 variables, the deep neural network model achieved high discriminative power, with area under the curve (AUC) values of 0.80. The 7-variable logistic regression (LR) model also achieved effective discriminate power (AUC = 0.77). Low body mass index (BMI) (‚â§‚ÄÖ17) was related to an increased risk of GDM, compared to a BMI in the range of 17 to 18 (minimum risk interval) (11.8% vs 8.7%, P = .09). Total 3,3,5‚Ä≤-triiodothyronine (T3) and total thyroxin (T4) were superior to free T3 and free T4 in predicting GDM. Lipoprotein(a) was demonstrated a promising predictive value (AUC = 0.66). Conclusions We employed ML models that achieved high accuracy in predicting GDM in early pregnancy. A clinically cost-effective 7-variable LR model was simultaneously developed. The relationship of GDM with thyroxine and BMI was investigated in the Chinese population.","Our paper explores prediction models based on a large sample of the Chinese population using clinical data before 12 weeks of gestation, 2 months earlier than previous state-of-the-art ML models. We used ML variable selection methods to screen for risk factors for early development of GDM. Of the 73 extracted variables, 17 variables were selected for our models, which included sociodemographic data (age, agea, smoking, and family history of diabetes in a first-degree relative), clinical characteristics (multiple pregnancy, multipara, and previous GDM history), glucose metabolism (FPG, FPGa, HbA1c, and HbA1ca), lipid metabolism (lipoprotein[a], apolipoprotein A, apolipoprotein B, TG), and thyroid function (TT3, TT4). Of these 17 variables, 7 were selected based on intravariable correlation and clinical importance for our parsimonious model: age, family history of diabetes in a first-degree relative, multiple pregnancy, previous GDM history, FPGa, HbA1c, and TG. Details of how the 7 variables were selected are discussed in the Supplementary text (18). As shown in Fig. 3, our all-variable DNN model achieved the highest accuracy in predicting GDM in early pregnancy, followed by SVM and KNN. Our parsimonious models using 7 variables performed similarly and with increased efficiency. The DCA of the different models also showed similar results (Supplementary text; Supplementary Fig. S4 [18]). Model comparisons The advantage of DNN is its ability to capture subtle nonlinear relationships between variables and outcomes. However, DNNs have a risk of overfitting, and because DNN is a black box to end users, the individual weighted contribution of each variable can be difficult to explain (30). On the other hand, LR highlights a clear contribution of each variable, making it useful for real-time clinical implementation. Our method of including only the important variables in each model resulted in a negligible running time difference between prediction models. The HL test was adopted to evaluate the calibration of prediction models (31). As KNN only results in a binary outcome rather than individual predicted probabilities, the HL test and DCA curve were not used to evaluate these models. The P values of all the models for the HL test were less than .001, which implied that the model calibrations were not optimal. This shows that although the models were to be able to distinguish high-risk status of GDM in early pregnancy, the specific risk probabilities provided by these models can be further improved (32). However, the 7-variable LR model revealed slightly better calibration than the DNN model. This may be due to the poor correlation between threshold probability and risk probability in DNN and SVM, indicating the HL test is not optimal to measure calibration for complex ML models. Furthermore, compared to existing LR prediction models (Supplementary Table S2 [18]), our 7-variable LR and DNN models demonstrated very promising results in predicting GDM in early pregnancy. There have been limited studies predicting GDM using ML algorithms. A retrospective electronic medical record study with 580 000 pregnancies in Israel reported an AUC of 0.85 using all variables and an AUC of 0.80 using only 9 variables (17). However, the clinical data collected from studies in Israel were obtained at 20 weeks of pregnancy, unlike our prediction using variables extracted only from the first trimester. This allowed them to use variables that are useful only during the second and third trimesters to predict GDM, such as human placental growth hormone, human chorionic somatomammotropin, progesterone, and placental growth hormone (33). Risk factor evaluation The selected variables were found to be consistent with previous clinical studies. Advanced age, previous GDM history, family history of diabetes, and blood glucose are well-known risk factors of GDM (34). Women with twin pregnancies have an increased risk of GDM, and higher rates of adverse pregnancy outcomes occur in GDM twin pregnancies (35). HbA1c reflects the average blood glucose levels over the last 1 to 2 months (36, 37). Previous studies hypothesized that the link between higher parity and insulin resistance could be explained by the decreasing Œ≤-cell reserve in consecutive pregnancies (38, 39). However, prediction models showed that parity plays a more complicated role, with multipara without previous GDM history reducing the risk of future GDM (OR = 0.5, P = .05), and multipara with previous GDM history increasing the risk of future GDM (OR = 1.6, P = .55) (40, 41). We therefore believe that parity, when used with other selected variables, is conditionally correlated to GDM, and that its predictive power can be increased through such a combination. Lipoprotein(a) was one of the 17 predictors and demonstrated high prediction power (AUC = 0.66, 95% CI, 0.65-0.68). Previous studies indicated that high levels of TGs and apolipoproteins are risk factors for GDM (42, 43). However, lipoprotein(a) transports oxidized phospholipids that have proinflammatory activity, so the possible association of higher lipoprotein(a) levels with GDM remains controversial (44, 45). For our model, the predicted effect of lipoprotein was better than that of apolipoproteins (Supplementary Table S3 [18]). The reasons for this are not known. Despite obesity being a well-known risk factor for GDM, our variable selection model did not choose BMI, instead highlighting biochemical indicators that reflect the level of lipid metabolism, such as TG. There are several explanations for this. First, compared to Europeans, Asians have more subcutaneous fat and higher s-leptin levels in early pregnancy, despite having lower BMI (46). Second, the relationship between BMI and GDM is complex, with high BMI individuals having an insulin resistance mechanism and low BMI individuals having a defective insulin secretion mechanism in GDM (47, 48). Our study showed that both an increased BMI and a very low BMI (‚â§‚ÄÖ17) (n = 432) are related to an increased risk of GDM (Supplementary Fig. S5 [18]), compared to a BMI in the range of 17 to 18 (minimum risk interval) (n = 915), but this association was not statistically significant (11.8% vs 8.7%, P = .09). Existing studies have not shown that extremely low BMI could increase the risk of GDM (17), but it has been found that BMI had J-shaped associations with overall mortality and diabetes mortality (48), supporting our findings. A large portion of the selected variables were of a biochemical nature (Supplementary Table S1 [18]). For example, TT3 and TT4 were selected as predictors of GDM, strongly suggesting the existence of a close relationship between thyroid function and GDM. In our training group, the GDM group had higher levels of TT3 (median, 2.1 nM vs 2.02 nM, P < .001) and free 3,5,3‚Ä≤-triiodothyronine (FT3) (median, 4.80 pM vs 4.60 pM, P < .001) and lower levels of TT4 (median, 114.2 nM vs 116.0 nM, P < .001) and free thyroxin (FT4) (median, 13.6 pM vs 14.0 pM, P < .001) compared to the non-GDM group. This result was consistent with previous studies (49, 50). Current research findings remain divided with respect to the question whether high T3 or low T4 in early pregnancy is a risk factor for GDM, as this may be affected by variations between populations (49-51). A study from a US cohort showed that FT4 was not associated with GDM, but high FT4-FT3 conversion efficiency (increased FT3/FT4 ratio) increased the risk of GDM (51). Several studies noted that FT3 levels were positively associated with insulin secretion and hyperinsulinemia (52). A study of the Chinese population suggested that increasing FT4 levels functioned as a protective mechanism against GDM, in that higher FT4 levels were associated with a lower incidence of GDM (P < .001) (49). Most prior research has focused on the relationship between FT3 and FT4 and GDM, because FT3 and FT4 have much higher biological activity than TT3 and TT4 and can directly reflect thyroid function (51). Interestingly, when we included thyroxine in the prediction model, the TT3 and TT4 levels had better predictive power than FT3 and FT4 (Supplementary Table S4 [18]). This suggests that the relationship between thyroxine and GDM is conditionally dependent on factors such as TT3 and TT4. However, further research on the relationships among TT4, FT4, and the risk of GDM in the Chinese population is needed."
2021,"Machine learning risk score for prediction of gestational diabetes in early pregnancy in Tianjin, China","Aims This study aimed to develop a machine learning‚Äìbased prediction model for gestational diabetes mellitus (GDM) in early pregnancy in Chinese women. Materials and methods We used an established population-based prospective cohort of 19,331 pregnant women registered as pregnant before the 15th gestational week in Tianjin, China, from October 2010 to August 2012. The dataset was randomly divided into a training set (70%) and a test set (30%). Risk factors collected at registration were examined and used to construct the prediction model in the training dataset. Machine learning, that is, the extreme gradient boosting (XGBoost) method, was employed to develop the model, while a traditional logistic model was also developed for comparison purposes. In the test dataset, the performance of the developed prediction model was assessed by calibration plots for calibration and area under the receiver operating characteristic curve (AUR) for discrimination. Results In total, 1484 (7.6%) women developed GDM. Pre-pregnancy body mass index, maternal age, fasting plasma glucose at registration, and alanine aminotransferase were selected as risk factors. The machine learning XGBoost model-predicted probability of GDM was similar to the observed probability in the test data set, while the logistic model tended to overestimate the risk at the highest risk level (Hosmer‚ÄìLemeshow test p value: 0.243 vs. 0.099). The XGBoost model achieved a higher AUR than the logistic model (0.742 vs. 0.663, p < 0.001). This XGBoost model was deployed through a free, publicly available software interface (https://liuhongwei.shinyapps.io/gdm_risk_calculator/). Conclusion The XGBoost model achieved better performance than the logistic model.","In our study, we developed a new tool to predict GDM using an ML algorithm. In the population-based prospective cohort, pregnant women with high risk scores estimated by the ML-based prediction model were considered to be at higher risk for GDM events. In particular, the risk prediction model derived from the ML method achieved a larger area under the ROC curve, which was as high as 74.2%, and had a better discrimination ability for GDM than the traditional risk prediction tool created using the logistic regression model (AUR: 66.3%, 95% CI: 63.5%‚Äì69.2%). Furthermore, the new model was able to achieve fewer false negatives for classifying pregnant women at risk for GDM. To date, there are many prediction models that can identify pregnant women at high risk for GDM.10-12 However, the use of ML techniques to identify risk factors and predict the development of GDM is limited. In our study, significant risk factors confirmed by ML for the identification of GDM included FPG at registration, maternal age, pre-pregnancy BMI, ALT, WC, HP, weight gain, income, family history of diabetes, education level, blood pressure, and gravidity, which correspond with a previous report.13 Although it is still debatable whether ALT could help identify women at high risk for gestational diabetes,27, 28 Yarrington et al.29 conducted a nested case‚Äìcontrol study (N = 330) and reported that when the pre-pregnancy BMI was less than 30 kg/m2, the adjusted odds ratio of ALT for GDM was 4.56 (1.45, 14.27). Similarly, in our previous study, we found a non-linear relationship between the ALT level measured in the first trimester and the occurrence of GDM with the use of a restricted cubic splines approach.30 In this study, one of the advantages of the ML method is handling the complex relationships of a large number of risk factors with non-linear interactions. Compared with conventional statistical approaches, the XGBoost method can learn complex non-linear decision boundaries by boosting, while linear models such as logistic regression assume a linear relationship between the feature and the target outcome.9 Decision trees in the XGBoost method are free to learn complex non-linear decision boundaries as long as the boundaries are aligned to the feature axes. In our study, these results once again demonstrated the importance of variables with non-linear relationships for GDM prediction, and the predictive performance of the XGBoost model, with a false-negative rate of approximately 23.1%, was superior to that achieved by the logistic model (29.8%). Recently, de Ruiter et al.31 assessed first-trimester prediction models for GDM and showed moderate to low methodological quality with AURs ranging from 63% to 89%, a median sensitivity of 67% and a specificity of 66%. Although our predictive model for GDM created using the ML method only achieved an AUR value of 74%, sensitivity of 61.6%, and specificity of 76.9% at the selected cut-off point of 0.384, the ML method easily takes advantage of patient information to significantly improve the accuracy of the prediction due to its inherent ability to handle large sets of variables. The XGBoost model does not require careful cleaning or preparation of the data, such as outlier scaling and collinearity. When the decision tree model is established, variables and optimal split points are determined. Therefore, there is no need to consider the interactions among variables and the influence of outliers on the split points, which greatly increases the overall efficiency of prediction. Research in other fields has reported that the XGBoost algorithm is better than traditional logistic regression. For example, Khemasuwan et al.32 performed prognostic prediction for parapneumonic empyema, and the XGBoost model achieved a better performance than the logistic regression model. On the other hand, the XGBoost model may be more complicated than the logistic regression model; once a predictive model is established, an accompanying application is easily deployed to identify pregnant women for target intervention (https://liuhongwei.shinyapps.io/gdm_risk_calculator/). Our research has important public health implications. Women with prior GDM are an identifiable group at high risk for diabetes and CVD in later life. In our previous meta-analysis, we concluded that women with previous GDM had a higher risk of CVD than those without GDM, and we also showed that lifestyle interventions could reduce the risk of GDM before Week 15 of pregnancy.7, 8 Therefore, women identified by the XGBoost model as high risk for GDM would have the opportunity to utilize lifestyle interventions early in pregnancy to reduce their risk of GDM. In our analysis, compared with the logistic model, the XGBoost model showed a significant increase in AUR from 0.663 to 0.742. Therefore, our model can more accurately identify women at high risk for GDM and help them take measures to reduce their risks earlier. Our research has some strengths and weaknesses. The main strength of the study is its large sample size, multi-centre design, and population-based prospective data set. As a limitation, it must be noted that the predictive performance is not excellent, as expected. The main reason might be that some level was collected through self-reports (i.e., income, gravidity and education attainment), which might lead to information bias in the outcome. In addition, basic maternal information obtained by routine collection did not have enough power to explain the development of GDM. Ruiter et al.10 suggested that biomarkers might improve the predictive performance of models for GDM. Based on a Dutch cohort, the performances of 12 prognostic models for GDM established by basic routine and measurement variables were assessed in an external validation study. The resulting C statistics ranged from 0.67 to 0.78. Therefore, further studies need to consider the potential role of biomarkers in predicting gestational diabetes. Second, we only performed internal validation, and the generalizability of our XGBoost model in other populations is unknown. In the future studies, the validation of prediction models created by ML in a new population is needed. In conclusion, our study demonstrated that GDM could be predicted in early pregnancy using an ML-based prediction model, which had a better performance than the logistic prediction model. Further studies are needed to verify the performance of the ML-based prediction model in other populations of pregnant women. Given the moderate performance of the current ML prediction model, an exploration of biomarkers in early pregnancy for the prediction of GDM is also warranted in the future."
2022,A Catalogue of Machine Learning Algorithms for Healthcare Risk Predictions,"Extracting useful knowledge from proper data analysis is a very challenging task for efficient and timely decision-making. To achieve this, there exist a plethora of machine learning (ML) algorithms, while, especially in healthcare, this complexity increases due to the domain‚Äôs requirements for analytics-based risk predictions. This manuscript proposes a data analysis mechanism experimented in diverse healthcare scenarios, towards constructing a catalogue of the most efficient ML algorithms to be used depending on the healthcare scenario‚Äôs requirements and datasets, for efficiently predicting the onset of a disease. To this context, seven (7) different ML algorithms (Na√Øve Bayes, K-Nearest Neighbors, Decision Tree, Logistic Regression, Random Forest, Neural Networks, Stochastic Gradient Descent) have been executed on top of diverse healthcare scenarios (stroke, COVID-19, diabetes, breast cancer, kidney disease, heart failure). Based on a variety of performance metrics (accuracy, recall, precision, F1-score, specificity, confusion matrix), it has been identified that a sub-set of ML algorithms are more efficient for timely predictions under specific healthcare scenarios, and that is why the envisioned ML catalogue prioritizes the ML algorithms to be used, depending on the scenarios‚Äô nature and needed metrics. Further evaluation must be performed considering additional scenarios, involving state-of-the-art techniques (e.g., cloud deployment, federated ML) for improving the mechanism‚Äôs efficiency.","Applying ML techniques and algorithms in several diverse domains is a matter of investigation in a plethora of research and enterprise initiatives. ML provides the right tools to analyze data and extract useful knowledge. More specifically, regarding the healthcare domain, ML is capable of processing large amounts of data and then providing useful insights regarding the planning and the delivering of care by the clinicians [101]. ML can lead to better decision-making, thus minimizing the cost whilst, at the same time, maximizing the efficiency and efficacy of healthcare-related processes [102]. It is an undeniable fact that a variety of research approaches have been proposed, presenting and applying diverse ML algorithms, even combining those algorithms for achieving high rates of predictions‚Äô data accuracy [103], focusing on performing predictions on multidimensional heterogeneous health-related data for inference in medical practices. As previously stated, all of these current methodologies have been effectively used in medical research for the construction of prediction models, leading in undoubtedly effective and correct decision-making. A summarization of various conducted research works upon diverse healthcare-related use case datasets can be found in Table 16. It should be noted that the illustrated healthcare-related research works refer to the diverse healthcare scenarios (i.e., stroke, COVID-19, diabetes, breast cancer, kidney disease, heart failures) that are under investigation in the current manuscript. Regarding the aforementioned list of existing research works, it is also worth mentioning the corresponding key components that are part of every approach‚Äôs workflow towards the accomplishment of the required predictions (except for the ML algorithms that they utilize, as depicted in Table 16). Through this analysis, it becomes feasible to determine the works‚Äô applicability and complexity in comparison with the manuscript‚Äôs proposed mechanism, based on the separate components that both of them put in place. Table 17 depicts in deep detail such information, including a list of the existing approaches in comparison with the proposed mechanism. To be more specific, the components listed in this table refer to ‚ÄúGateway‚Äù, ‚ÄúData Reliability‚Äù, ‚ÄúHyperparameters‚Äô Tuning‚Äù (included into the Model Training component), ‚ÄúData Storage‚Äù, and ‚ÄúModel Evaluation‚Äù that are considered to be the major contributions of the current manuscript (as described in Section 1). It is worth mentioning that regarding the first two components (i.e., ‚ÄúGateway‚Äù, ‚ÄúData Reliability‚Äù), those do not refer to simple data collection and data cleaning techniques (e.g., data are stored into a simple local file and are cleaned by dropping rows of erroneous data), since those are trivial procedures. Instead, they refer to approaches that the corresponding components perform more complex tasks, such as those that are showcased in the present manuscript (further analyzed in Section 2.2). Moreover, it should be noted that the ‚ÄúData Storage‚Äù component does not refer to the fact whether the existing research works exploit a NoSQL database for storing their data (as in the case of the proposed mechanism), but it just refers to the fact as to whether the stated research works are putting in place in their overall workflow a Data Storage component for handling the storage of the investigated data. Based on the results captured in Table 16 and Table 17, it has become clear that even though new and better software technologies have considerably reduced the complexity of implementation for many ML algorithms in recent years, most of these approaches are use-case specific, whereas specific algorithms and components have been applied upon the effective completion of their predictions. For this reason, this manuscript proposes a mechanism that utilizes a list of widely used and well-established ML algorithms to train models to perform predictions across diverse healthcare anomalies‚Äô scenarios, and based on specific metrics, it compares the algorithms‚Äô efficiency. By the time that this process gets complete, the mechanism creates a catalogue with the most proper algorithms to be applied on each given scenario. The outcomes of this process are further described below, regarding each different metric that was estimated across the diverse chosen scenarios. More specifically, regarding the diabetes use case, it is observed that the most suitable algorithm, in terms of the accuracy parameter, is LR with a percentage equal to 77%, given that the number of correct predictions (insulin administration) divided by the total number of predictions are correctly defined. Furthermore, as for the heart failure scenario, it is observed that the most proper algorithm is RF with an accuracy equal to 86. Moreover, in the stroke use case scenario, the most efficient algorithm is SGD with an accuracy percentage of 96%. As for COVID-19 use case scenario, RF performed most sufficiently since it achieved the highest accuracy of 92%. Additionally, on finding breast cancer, the results indicate that LR had the best performance with 92%, referring to all the cases in which the patients will have benign cancer, while for the kidney disease case, it seems that this will not happen in the given patients, with 100% accuracy of the three algorithms of DT, RF, and NN representing a strong prediction. Additionally, the recall metric is considered quite significant because it shows the ratio of correctly predicted positive observations to all observations in the actual class. For all the use cases studied in this manuscript it is observed that the recall metric is above 50%. In the diabetes use case, the highest corresponding score is equal to 77% and is achieved by the LR algorithm. In the heart failure use case, a percentage of 89% is achieved by LR and RF. In the rest of the use cases, it appears that recall scores are greater than 90%, except for the use case of COVID-19, where the recall score is 79%. Regarding the precision metric and the diabetes use case, it is observed that the most suitable algorithm is RF with a rate equal to 70%, given the number of correct predictions (insulin administration) divided by the total defined number of predictions. Furthermore, in the heart failure use case, it is observed that the most suitable algorithms were LR, RF, and SGD, with a precision score of 67%. Additionally, in the stroke use case, the most effective algorithms were BNB, KNN, LR, and SGD, with a perfect precision score equal to 100%. As for the COVID-19 use case, RF had the most adequate performance as it achieved the highest precision score of 44%. Additionally, for the breast cancer use case, the mechanism shows that LR was quite precise (100%), while the rest of the algorithms range between 90% and 100%, showing that the given patients will have benign cancer, while in the case of kidney disease, it seems that there will not be any kidney disease to the patients with 100% precision for three algorithms (DT, RF, NN), which is a strong prognostic factor. Additionally, regarding the F1-score metric, the weighted average of precision and recall was tested. Initially, in the diabetes use case, it appears that BNB adapts better with a percentage of 80%, followed by LR with a score equal to 79%. In the heart failure use case, it is observed that RF‚Äôs F1-score is 67%. However, in general the algorithms have a quite low score regarding F1-score (around 50%). In the same way, in the use case of COVID-19, it seems that only RF surpasses 50%, whilst for the remaining scenarios (i.e., stroke, breast cancer, and kidney disease), all the algorithms appear to match well with percentages greater than 90%. For example, in the stroke case it appears that SGD has a percentage equal to 98%, in the case of breast cancer LR achieves a score equal to 100%, while in the same notion, in the kidney disease case it appears that several algorithms (DT, RF, NN) achieve a perfect score (100%) as well. Of course, it is worth mentioning that the current approach has certain limitations. Regarding the Gateway microservice, this utilizes a mechanism to efficiently retrieve large amount of data by splitting them into batches and storing them into the database. However, the size of the batches is currently at a default value. If the batch size was dynamically changing based on the size and structure of the collected data, the data collection would probably be even more efficient. Moreover, this functionality has been tested with a limited number of external sources and third-party APIs, so further testing should take place. As for the Data Reliability microservice, this depends on a set of ML techniques that even include NLP. This fact suggests that more time and/or computational cost should be needed in order to effectively eradicate all the possible data inconsistencies. As a result, further development should take place to make the corresponding processes more efficient, at a software level. Moreover, the Data Reliability microservice should split the data to batches to perform data cleaning, when it comes to large datasets. As for the microservices of Model Training, Model Evaluation, and Model Validation, it is difficult to compare algorithms objectively across studies, since each study‚Äôs performance is reported using different methodologies on different populations with distinct sample distributions and features. To be fair, algorithms must be compared using the same independent test set that is representative of the target population and the same performance criteria. Without this, healthcare practitioners would have a difficult time determining which algorithm is most likely to perform well for their patients. To fully examine the performance of the different available algorithms in a representative sample of their community, each healthcare practitioner may use the curation of separate local test sets. Such independent test sets should be constructed using an unenriched representative sample and data that are not intended to be used to train algorithms. Furthermore, prior to formal testing, an additional local training dataset for the Model Serving microservice could be provided to allow fine tuning of the chosen algorithms. ML algorithms are susceptible to a variety of flaws, including inapplicability outside of the training domain, bias, and brittleness (i.e., the ability to be easily deceived [138]). The following have to be considered: the dataset shift, the fitting confounders rather than the true signal, the spreading inadvertent biases in clinical practice, the offering of algorithm interpretability, the creation of correct evaluations of model confidence, and the difficulty of applicability to new populations. Given the current velocity of innovation, the significant risks involved, and the potentially fluid nature of ML models, this is a one-of-a-kind problem. Furthermore, proactive regulation will create trust in professionals and healthcare systems for the Prediction microservice. What is more, currently there is a trade-off between the performance and the explainability for the developed Performance Monitor microservice. The highest performing models (e.g., DL) are frequently the least explainable, whereas models with worse performance (e.g., LR, DT, or RF) are the most explainable. DL models currently have a significant disadvantage in the way that they lack explicit declarative knowledge representation, making it difficult to provide the necessary explanatory structures [139]. For the Orchestrated Experiment microservice, the currently exploited ML models do not rely on a long history of research in classical symbolic AI techniques to allow for the encoding of data semantics and the use of ontologies to assist the learning process, which may help healthcare specialists to better understand and re-trace decision processes [140]. Finally, regarding the developed UI, all the underlying microservices are directly or indirectly connected and visualize their produced results through the provided interfaces, thus following the MSA towards code‚Äôs reuse and efficient operations. However, in the case of adding more complex ML/DL mechanisms, more complex code compositions are required that should be further studied to respond to the requests returned to the developed UI."
2022,Machine learning-based classification of arterial spectral waveforms for the diagnosis of peripheral artery disease in the context of diabetes: A proof-of-concept study,"Background: Point-of-care duplex ultrasound has emerged as a promising test for the diagnosis of peripheral artery disease (PAD). However, the interpretation of morphologically diverse Doppler arterial spectral waveforms is challenging and associated with wide inter-observer variation. The aim of this study is to evaluate the utility of machine learning techniques for the diagnosis of PAD from Doppler arterial spectral waveforms sampled at the level of the ankle in patients with diabetes. Methods: In two centres, 590 Doppler arterial spectral waveform images (PAD 369, no-PAD 221) from 305 patients were prospectively collected. Doppler arterial spectral waveform signals were reconstructed. Blinded full lower-limb reference duplex ultrasound results were used to label waveform according to PAD status (i.e., PAD, no-PAD). Statistical metrics and multiscale wavelet variance were extracted as discriminatory features. A long short-term memory (LSTM) network was used for the classification of raw signals, and logistic regression (LR) and support vector machines (SVM) were used for classification of extracted features. Signals and feature vectors were randomly divided into training (80%) and testing (20%) sets. Results: The highest overall accuracy was achieved using a logistic regression model with a combination of statistical and multiscale wavelet variance features, with 88% accuracy, 92% sensitivity, and 82% specificity. The area under the receiver operating characteristics curve (AUC) was 0.93. Conclusion: We have constructed a machine learning algorithm with high discriminatory ability for the diagnosis of PAD using Doppler arterial spectral waveforms sampled at the ankle vessels.","Early pioneering work of Strandness et al. reported on morphological differences in Doppler arterial waveforms of normal and atherosclerotic peripheral arteries.15,16 This was followed by rapid technological and methodological advancement, which established vascular ultrasound as the single most important noninvasive vascular diagnostic imaging modality. Despite important early efforts to define certain aspects of waveform morphology, such as resistance and pulsatility, in quantitative terms,17,18 waveform assessment has not changed for almost 50 years. To the best of our knowledge, this is the first study to apply machine learning to the classification of Doppler arterial spectral waveforms at the ankle for the diagnosis of PAD. We have shown that machine learning can achieve high diagnostic accuracy for PAD from the interpretation of ankle Doppler arterial waveforms. The performance of machine learning (sensitivity 92%, specificity 82%) in this study is comparable to that of waveform interpretation by expert vascular scientists reported in the TrEAD study (sensitivity 95%, specificity 77%).10 However, it has the added advantage of standardising assessment and eliminating interobserver variation, which represents a significant challenge given the qualitative and subjective nature of waveform interpretation. This approach may also shorten the learning curve for point-of-care DUS by removing waveform interpretation as a barrier and hence further facilitate its adoption in routine clinical practice. This is important given that point-of-care DUS is a bedside test for use by frontline health care professionals looking after patients with diabetes (surgeons, podiatrists, nurses, and physicians), who are unlikely to have had formal training in vascular ultrasound. Our algorithm also outperformed a machine learning model trained using diverse clinical, demographic, imaging, and genomic information (AUC = 0.87).19 This highlights the value of highly discriminatory information that can be extracted from physiological Doppler signals. However, additional gains in performance may be gained from combining these data with other clinical data and this would be an interesting line of future research. There is also evidence in the literature that machine learning can be harnessed to classify toe photoplethysmography (PPG) signals for the detection of PAD as diagnosed using ankle‚Äìbrachial pressure indices as the reference standard (overall accuracy of 88.9%).20 In the future, direct comparison of the diagnostic accuracy of these two approaches would be of interest. Although our study is related to the specific application of point-of-care DUS for the detection of PAD in patients with diabetes, our findings have wider implications for the field of vascular ultrasound. Recently, acknowledging significant heterogeneity in waveform interpretation, there has been an attempt to standardise key definitions and descriptors of waveform morphology by expert consensus.21,22 However, it remains the case that waveform morphology is complex and is dependent on location in the arterial tree as well as severity of disease. Waveform interpretation will therefore likely remain challenging and will continue to be associated with significant inter-observer variation. Machine learning tools, such as those tested in this study, may be useful in standardising assessment and reducing inter-observer variation when applied to other vessels or patient groups (e.g., carotid imaging). In this study, we have found higher classification accuracy when using statistical time-domain and multiscale wavelet variance time-frequency features for classification, as compared to the ‚Äòend-to-end‚Äô based on the raw signal. However, this may not be an exhaustive list of putative features and further work is necessary to investigate optimal feature selection, which may further improve classification accuracy. Additionally, our study has focused on determining the feasibility of this approach and has not exhausted algorithm optimisation through hyperparameter tuning or alterations in the waveform reconstruction methodology (e.g., varying the step size when reconstructing the signal). Furthermore, improvements in accuracy may also be achieved by establishing a large repository of waveforms and thereby increasing the size of the dataset available for training. Importantly, these will have to be labelled accurately using a suitable reference test. In this study, we used a full lower-limb DUS as our reference standard. This has the advantage of being inexpensive, noninvasive and has also been shown to have a good agreement with intra-arterial digital subtraction angiography (DSA).23 However, it may be less reliable in interrogating the commonly affected distal vessels in diabetes9,23 and may fail to detect isolated atherosclerotic PAD lesions in the foot vessels. Doppler arterial spectral waveform machine learning analysis may be able to detect isolated disease in the foot which would be associated with increased vascular resistance and a change in waveform morphology. It is possible that cases of isolated PAD in the foot may have been present but mislabelled using our chosen reference test. Alternative strategies, such as magnetic resonance angiography (MRA) and computed tomography angiography (CTA), may be suitable reference test alternatives. Surprisingly, in our analysis we observed that a deep learning approach underperformed compared to logistic regression and support vector machine techniques. We also observed that support vector machines underperformed as compared to logistic regression. This may be because logistic regression is more vulnerable to overfitting. Although this is out of the scope of this proof-of-concept study, future work should focus on exploring this observation and systematically evaluating the effect of hyperparameter tuning, signal preprocessing, and a larger dataset on classification accuracy. Further work, such as using advanced recurrent neural networks,24 is also necessary to prospectively evaluate the diagnostic accuracy of our constructed machine learning algorithm and the feasibility of its implementation in real time clinical practice. To achieve this, the algorithm could be combined with a programme that automatically reconstructs the Doppler waveform without the need for manual user demarcation, which can be time-consuming and impractical in a busy clinical setting. Furthermore, recruited patients were representative of those presenting to high-risk diabetic foot clinics, with a high prevalence of PAD, neuropathy, and active ulceration. Therefore, although our results will be highly relevant to routine diabetic foot clinic practice, evaluation of its performance should also be assessed in low PAD prevalence settings such as primary and community care. A significant strength of this study is that patients were representative of those that would be managed in routine clinical practice with high incidence of neuropathy and ulceration. Furthermore, as mentioned, reference imaging was used to determine the presence or absence of PAD."
2022,Identification and epidemiological characterization of Type-2 diabetes sub-population using an unsupervised machine learning approach,"Background Studies on Type-2 Diabetes Mellitus (T2DM) have revealed heterogeneous sub-populations in terms of underlying pathologies. However, the identification of sub-populations in epidemiological datasets remains unexplored. We here focus on the detection of T2DM clusters in epidemiological data, specifically analysing the National Family Health Survey-4 (NFHS-4) dataset from India containing a wide spectrum of features, including medical history, dietary and addiction habits, socio-economic and lifestyle patterns of 10,125 T2DM patients. Methods Epidemiological data provide challenges for analysis due to the diverse types of features in it. In this case, applying the state-of-the-art dimension reduction tool UMAP conventionally was found to be ineffective for the NFHS-4 dataset, which contains diverse feature types. We implemented a distributed clustering workflow combining different similarity measure settings of UMAP, for clustering continuous, ordinal and nominal features separately. We integrated the reduced dimensions from each feature-type-distributed clustering to obtain interpretable and unbiased clustering of the data. Results Our analysis reveals four significant clusters, with two of them comprising mainly of non-obese T2DM patients. These non-obese clusters have lower mean age and majorly comprises of rural residents. Surprisingly, one of the obese clusters had 90% of the T2DM patients practising a non-vegetarian diet though they did not show an increased intake of plant-based protein-rich foods. Conclusions From a methodological perspective, we show that for diverse data types, frequent in epidemiological datasets, feature-type-distributed clustering using UMAP is effective as opposed to the conventional use of the UMAP algorithm. The application of UMAP-based clustering workflow for this type of dataset is novel in itself. Our findings demonstrate the presence of heterogeneity among Indian T2DM patients with regard to socio-demography and dietary patterns. From our analysis, we conclude that the existence of significant non-obese T2DM sub-populations characterized by younger age groups and economic disadvantage raises the need for different screening criteria for T2DM among rural Indian residents.","Rationale of the workflow in clustering epidemiological data The clustering workflow used arises from some important observations that we will discuss here. To begin with, we have a population of 10,125 T2DM patients with a diverse ensemble of features accounting for information on medical history, dietary and addiction habits, socio-economic and lifestyle patterns. Moreover, the features in the considered dataset are also diverse in terms of data types. We have a total of 36 features, out of which 4 are continuous features, 7 nominal features and 25 ordinal features, all of equal importance by assumption. The aim is to find significant sub-populations in our data such that the identified sub-populations are interpretable in terms of the considered features. Note here that, by significant sub-populations, we mean a sub-population consisting of at least 10 percent of the total population. If there exist such sub-populations and we can explain the sub-populations in terms of the considered features, we can argue that these patterns exist in a significant number of patients. We have already argued in favour of using UMAP for our unsupervised approach to find clusters in the data. However, we observed that applying UMAP algorithm conventionally using the Euclidean similarity metric on our entire dataset with 36 features turns out to be ineffective. The reason is, in this case, the continuous features have an overpowering effect over the other feature types in determining the distribution of clusters. This can be observed in Fig. 2a, b. Note that Fig. ‚ÄãFig.2a2a shows UMAP clustering with all 36 features and 2(b) shows UMAP clustering with only four continuous features. Note that, there is a similarity in the clustering distribution of these figures, each containing one major cluster and seven small minor clusters. We observed that this is because of the fact that UMAP, when applied to all 36 features of the dataset using the Euclidean similarity measure is largely biased towards finding similarity among data points only in terms of the continuous features. Given that we have only four continuous features out of 36, this poses a problem as the diverse information present in the dataset in the form of the ordinal and nominal features is largely ignored. To solve this problem, the clustering of continuous, ordinal and nominal features was treated separately by using different similarity matrices for them, giving rise to our clustering paradigm. We argued on our choice of similarity measures in Section ‚ÄúClustering paradigm using UMAP‚Äù. This generates for each feature type a data representation of lower dimension shown in Fig. 2b‚Äìd. We finally integrated these lower dimension data representations by taking two-dimensional representations for continuous and ordinal features and a one-dimensional representation (the one consisting of the most variance) for nominal features. The reason behind considering one-dimensional representation for nominal features is that using Hamming metrics for such data results in retaining a lot of variance in the data resulting in multiple clusters as we observe in Fig. ‚ÄãFig.2d.2d. Considering a two-dimensional representation for this data while integrating these lower dimension data representations carry forward this variance and result in multiple small clusters in the final clustering distribution, which contradicts our aim of finding significantly large sub-populations (of at least 10 percent of the total population). Finally, the integration is done by applying UMAP on the five-dimensional reduced representation of the dataset using the Euclidean similarity measure (shown in Fig. ‚ÄãFig.3b).3b). Note here that, in our final clusters, we can observe patterns in all of the continuous, ordinal and nominal data types. For example, in Cluster 4 the continuous feature ‚ÄòTime to Water source (min)‚Äô shows very high values compared to other clusters. In Clusters 1 and 3, the nominal feature ‚ÄòCooking fuel used‚Äô shows a higher percentage for Gas/Oil users while in Clusters 2 and 4 the same feature shows a higher percentage for plant-based fuel users. In Cluster 3, the ordinal feature ‚ÄòFish intake frequency‚Äô shows 97% of people to be never consuming fish. Thus, we infer that our clustering paradigm enables us to find significant sub-populations while keeping the clustering distribution unbiased, that is no feature type continuous, ordinal and nominal has an overpowering effect on the other. Significance of T2DM clusters T2DM was identified as a homogeneous disease with Insulin Resistance followed by Œ≤-cell dysfunction being the underlying pathology. However, recent studies have explored and found T2DM to be a heterogeneous entity with the relative contribution of Insulin Resistance and Œ≤-cell dysfunction to differ across T2DM clusters [3]. These studies were performed on clinical and biochemical data with variables having uniform data types. On the other hand, our clustering approach takes into account the diverse data types obtained from an epidemiological dataset and discovers clusters among the T2DM population. Interestingly, two of the four clusters obtained in our study belonged to the non-obese T2DM phenotype where the mean BMI was below 25. These two non-obese clusters also had lower mean age compared to the other clusters. Both these non-obese clusters had a larger proportion of rural residents and a lower proportion of people belonging to the highest wealth quintile concluding to the fact that a large majority of T2DM people from rural India have lower BMI and are younger in age. The T2DM patient sub-population belonging to these clusters has a relatively lower quality of life judging by analysis of the lifestyle pattern-based features. The non-obese phenotype of T2DM has been increasingly reported over the last two decades raising concern about the uniqueness of its underlying pathophysiology with a greater contribution of Œ≤-cell dysfunction compared to Insulin Resistance [25‚Äì28]. This non-obese T2DM phenotype has been found among Asians and studies depicting and investigating its similarities and differences have been in place. Studies have concluded that T2DM occurs among Asians at a lower BMI cut-off and also at a younger age [29, 30]. This finding of two non-obese clusters with lower mean age provides confirmation to this. Among the studies aimed to identify T2DM subtypes, the two subtypes severe insulin deficient diabetes (SIDD) and mild-age-related diabetes (MARD) were found to be common [3, 4]. Both cluster 2 and cluster 4 in our study seem to have similarities to the SIDD subtype though the reasons behind obtaining two different epidemiological clusters within the SIDD subtype need further investigation. As our dataset had patients below 49 years of age, we couldn‚Äôt obtain any cluster that may be compared to the mild-age-related diabetes (MARD) subgroup. The remaining two clusters in our study, cluster 1 and cluster 3 are both obese groups and therefore may be the epidemiological counterparts of either mild obesity-related diabetes (MOD) or severe insulin-resistant diabetes (SIRD). Hence, the T2DM clusters obtained from epidemiological data provide further strength to the clinical T2DM subtypes and raise the need to further investigate the epidemiological risk factors of T2DM subtypes. Though non-obese T2DM is being considered a unique phenotype, epidemiological studies for identifying high-risk population groups still remain undone. This is especially important for many Asian countries where over half of the T2DM population is of non-obese phenotype [25]. This analysis, reporting an increased presence of Rural residents in both the non-obese T2DM clusters, calls for a modification in BMI and Age cut-off for T2DM screening among rural residents. However, identification of risk factors for T2DM specific to the rural population needs to be done. Representation of people from the highest wealth quintile was much lower in both the non-obese T2DM clusters. T2DM is a multifactorial disease requiring strict compliance to lifestyle modification, proper diet and antidiabetic therapy. Non-obese T2DM clusters with reduced representation from the highest wealth quintile suggest the possibility of unequal access to care for non-obese T2DM people thereby generating the need for a more equitable healthcare policy in terms of prevention and therapy. On the other hand, both the obese T2DM clusters had higher ages and more urban residents. The proportion of people from the highest wealth quintile was higher in both the obese clusters. Interestingly one of the obese clusters (Cluster 3) had invariably a low intake of non-vegetarian foods (egg, fish, chicken and meat) pointing out the fact this T2DM cluster comprised vegetarian people mainly. Dietary requirements in diagnosed T2DM patients involve a reduced amount of carbohydrates and fats with an increased amount of protein-rich foods [31]. Animal products, being rich sources of dietary protein, need to be included in the diet. One of the obese T2DM clusters with a strict vegetarian dietary pattern suggests the need to design proper dietary guidelines for this group. As already mentioned, T2DM is a multifactorial disease with socio-economic inequality suggested to play an important role in the pathology and management of the disease [32]. Studies have identified socio-economic inequalities and allostatic load to associate with T2DM [33]. The negative effect of social stress, uncertainty and poor nutrition [34] seems to be more relevant for clusters 2 and 4 in this study where individuals majorly belong to a weaker socio-economic class. Though this study doesn‚Äôt have the data to investigate this association, the possibility of obtaining T2DM subtypes based on the allostatic load seems to be a promising area of diabetes research. Designing a customized healthy diet and lifestyle plan for certain T2DM subtypes with a view to reducing the allostatic load may emerge as an important strategy in T2DM management."
2022,Overview of global publications on machine learning in diabetic retinopathy from 2011 to 2021: Bibliometric analysis,"Purpose To comprehensively analyze and discuss the publications on machine learning (ML) in diabetic retinopathy (DR) following a bibliometric approach. Methods The global publications on ML in DR from 2011 to 2021 were retrieved from the Web of Science Core Collection (WoSCC) database. We analyzed the publication and citation trend over time and identified highly-cited articles, prolific countries, institutions, journals and the most relevant research domains. VOSviewer and Wordcloud are used to visualize the mainstream research topics and evolution of subtopics in the form of co-occurrence maps of keywords. Results By analyzing a total of 1147 relevant publications, this study found a rapid increase in the number of annual publications, with an average growth rate of 42.68%. India and China were the most productive countries. IEEE Access was the most productive journal in this field. In addition, some notable common points were found in the highly-cited articles. The keywords analysis showed that ‚Äúdiabetic retinopathy‚Äù, ‚Äúclassification‚Äù, and ‚Äúfundus images‚Äù were the most frequent keywords for the entire period, as automatic diagnosis of DR was always the mainstream topic in the relevant field. The evolution of keywords highlighted some breakthroughs, including ‚Äúdeep learning‚Äù and ‚Äúoptical coherence tomography‚Äù, indicating the advance in technologies and changes in the research attention. Conclusions As new research topics have emerged and evolved, studies are becoming increasingly diverse and extensive. Multiple modalities of medical data, new ML techniques and constantly optimized algorithms are the future trends in this multidisciplinary field.","Trend analysis of publications and citations From 2011 to 2020, the number of publications grew from 10 to 245 and the overall growth rate reached 42.68%, indicating significant growth in research interests in this field. In addition, the rapid expansion of the annual citations reflected the increasing impact of related publications. On the one hand, this growing trend is due to the breakthroughs in AI technology and its wide application in medicine: in 2012, a well-trained deep convolutional neural network won the ImageNet challenge (40); in 2014, the generative adversarial network was invented (41). As a subarea of ML, DL was gradually applied to various domains of medicine, including radiology, pathology, dermatology, ophthalmology, and so on (42). On the other hand, multiple public ophthalmic datasets were set up around 2010, which accelerated the development of relevant research. For example, Kaggle EyePACS (2015) consists of over 80000 annotated fundus images with DR staging; the Messidor dataset (2008) consists of 1200 fundus images accompanied with medical diagnosis. These public large-scale datasets have created a great opportunity for academic groups worldwide to test and benchmark their models/systems/algorithms. Furthermore, the establishment of recognized DR grading standards (e.g., ICDRSS scale) (7) also promoted the comparison of diagnostic ability between different models or between man and machine. In general, there is still a distance between the current ML in DR and the clinical practice as most studies are in silico and aim to optimize algorithms and propose new techniques based on recognized public datasets or local private datasets. The prospective studies in this field mainly focus on the real-world viability test, clinical validation of algorithms/software and human-machine comparison (43‚Äì45). However, as machine learning becomes mature in this area, the number and proportion of real-world-oriented studies are increasing. Table 3 shows that the most impactful articles were published after 2015. After Gulshan et al. published the most impactful in 2016 and received widespread attention from ophthalmic researchers, many DL-based studies have sprung up, which is also consistent with the publication trend and the development of technologies and databases. Some common points of impactful articles were found out: 1. Published by influential journals (e.g. JAMA - IF:56.27; Ophthalmology, IOVS ‚Äì the top journals of ophthalmology); 2. New techniques (e.g. deep learning in 2016, 2017); 3. Excellent results (e.g., great performance of algorithms with an area under the receiver operating curve > 0.99); 4. Involved in multiple tasks (e.g. automatic grading of DR severity or detection of multiple diseases including DR). These articles led the developing trend in this field and many articles were based on these achievements. Publication pattern and collaboration analysis Researchers all over the world have contributed to the field of ML in DR. The publication pattern reveals that India and China have been the most productive countries. The two densely populated developing countries contributed to nearly half of the relevant publications, which is uncommon in other bibliometric studies on the topic of AI technologies in medicine (17, 25), as developed countries such as the USA or England are usually the main force. In addition, there are 5 developing countries in the top 10 countries ranked by publication count, all with considerable academic output. However, in terms of the H-index and citations of different countries, developed countries performed relatively better compared to developing countries. This can be explained by differences in social medical resources and technologies between countries. With the global epidemic of diabetes, the prevalence of DR is also rising predominantly, especially in densely populated countries like India and China (46, 47). There is a clear but unmet need to comprehensively screen DR in the diabetic population in the rural area of these developing countries due to the disproportionally low ophthalmic population (13). Developing countries are urgently calling for a cost-effective way to manage DR. Therefore, the automatic system based on ML is widely explored by academic groups from developing countries. As for developed countries, institutions and researchers benefit from technological breakthroughs and the mature ophthalmic system. Researchers are more likely to publish impactful articles. The National University of Singapore is the most productive institution and most publications also belong to Singapore National Eye Center. The two institutions tend to publish articles that push forward the clinical application of ML techniques in DR, including the clinical validation of DL systems based on the Singapore National Diabetic Retinopathy Screening Program or other multiethnic DR screening data and reviews that discussed the current status of AI techniques in the real-word DR screening (48, 49). By analyzing the top institutions (documents ‚â• 20), we found that most studies from National University of Sciences Technology Pakistan, Indian Institute of Technology System and Northeastern University China are ML technique-oriented. Most studies from two Singaporean institutions are medicine-oriented. Researchers from Sun Yat-Sen University published both technique-based studies and clinical validation studies as they collaborated a lot with hospitals and computer science laboratories. From the perspective of citations, those medicine-oriented and pragmatic studies are more popular than technique-oriented studies. The collaboration analysis also revealed that productive countries/institutions have more options for international collaborations. In addition, the nodes in the middle of Figure 3A tend to appear yellow, indicating that countries/institutions with more external collaborations have a greater chance of publishing impactful articles (i.e., high average citations). Research domains and targeted sources As included documents are mainly related to computer techniques and imaging systems, journals that specialized in these domains were productive in this field. On the one hand, the advancement of computer science and engineering accelerated the pace of applying AI technologies in medicine. On the other hand, imaging techniques are commonly used in ophthalmology and produce lots of valuable data on DR patients, which is useful for developing ML algorithms. The impact factor (mostly around five) and the JCR rank of the twelve ‚Äúcore journals‚Äù indicate the overall impact and quality of relevant publications. Only Computers in Biology and Medicine and Biomedical Optics Express have published impactful articles, as shown in Table 3. Impactful journals such as JAMA and Ophthalmology are not shown due to the publication count. Keywords analysis The frequently occurred keywords in the literature always indicate the research hotspots. The co-occurrence of several keywords represents the widely discussed topic containing several basic components. By dividing the relevant literature by time, the emergence and evolution of keywords can be visualized on the word clouds. Keywords analysis reveals the mainstream topics in the field, the research focuses on different periods and the subareas that are currently popular or remained to be explored. Overall, the application of machine learning techniques in diabetic retinopathy is extensive and diverse, while most documents aim to diagnose DR automatically. ‚ÄúDiabetic retinopathy‚Äù is the most dominant keyword for the whole period, along with other frequent keywords such as ‚Äúclassification‚Äù, ‚Äúsegmentation‚Äù and ‚Äúfundus images‚Äù. Thus, fundus images are the most commonly used data for research. Classification and segmentation are the tasks for ML or the processing steps for the data. Some keywords relating to DR lesions (e.g., ‚Äúmicroaneurysms‚Äù, ‚Äúexudates‚Äù) are also dominant in Figure 5, as many documents focus on detecting characterized lesions of DR to mimic the diagnostic process of ophthalmologists. A tiny microaneurysm can be the key to distinguishing between diseases and normality, thereby the automatic detection of these lesions makes the diagnosis of ML algorithms reasonable (20). Some keywords of ML techniques were prominent in the keywords co-occurrence analysis (e.g., ‚Äúdeep learning‚Äù, ‚Äúsupport vector machine‚Äù, ‚Äúconvolutional neural network‚Äù), representing the popular tool applied in DR. By linking up the keywords, the mainstream concepts are immediately visible, for example, the diagnosis of ‚Äúdiabetic retinopathy‚Äù based on the ‚Äúautomated detection‚Äù of ‚Äúexudates‚Äù in ‚Äúretinal images‚Äù by ‚Äúdeep learning‚Äù. However, both techniques and clinical focuses change over time. From 2011 to 2021, the evolution of topics mainly focused on computer methods, clinical tasks and data modalities. First, ‚Äúdeep learning‚Äù and ‚Äúconvolutional neural network‚Äù appeared in 2016-2017 for the first time and subsequently became larger in the word cloud, indicating that deep learning and related techniques gained increased research attention, which was consistent with the publication time of the paper by Gulshan et al. and the overall development of DL techniques. The traditional technique ‚Äúsupport vector machine‚Äù became less popular in this field due to the remarkable performance of DL in feature extraction and representation. Second, the keywords of DR features (e.g., exudate, microaneurysm) became less frequent, indicating that simple lesion-detection algorithms were gradually dismissed. Many comprehensive DR grading systems and multi-disease diagnosis systems have sprung up recently as the keyword ‚Äúgrading‚Äù gradually become frequent (21). Third, due to the limited information offered by digital fundus images, the data from new imaging techniques such as optical coherence tomography, gradually emerged in this field (Figures 5C‚ÄìE). Other imaging techniques like fundus fluorescein angiography were also considered but not shown in the word cloud, which needs to be further studied (50). Moreover, the ML algorithms usually focused on the simple data modality while doctors would refer to different types of examination data and complaints of patients. As the keyword ‚Äúdataset‚Äù and ‚Äúdatabase‚Äù has become much more dominant from 2011 to 2021, the integration of multi-modal data from different sources might be the future direction for automated diagnosis. In addition, we found that although the keyword ‚Äúpatient‚Äù was less prominent from 2011 to 2021, the frequency rank kept rising. From a clinical point of view, patients are always the main components of all relevant studies. With the ML techniques in DR getting matured, more researchers designed studies that better reflect the real-world effectiveness of AI systems. These studies not only included the existing datasets but also test their algorithm/software in broader patient groups. To utilize AI as tools in real clinical settings, the algorithms in this field are constantly optimized in both the techniques (from ‚Äúsupport vector machine‚Äù to ‚Äúdeep learning‚Äù) and the capacity of dealing with more complex conditions which mimic the clinical settings (e.g., grading DR based on multi-modal data). This study is the first bibliometric analysis of ML in DR and aims to provide a holistic view of the relevant research. The results discussed in this study are objective, quantifiable and macroscopical, which would be suitable for any researchers interested in this field to get familiar with the basic knowledge structure (e.g., the mainstream topic, the outstanding achievements, the emerging trends, global publication pattern, and relevant research domains, etc.) and can help them find potential collaborators and develop relevant studies. Moreover, the change in publication trends and keywords from 2011 to 2021 indicated the potential directions of further studies in this field, including the incorporation of optimized ML techniques, multi-modal data, real-world-oriented study design, etc."
2022,Machine Learning Prediction Models for Gestational Diabetes Mellitus: Meta-analysis,"Background Gestational diabetes mellitus (GDM) is a common endocrine metabolic disease, involving a carbohydrate intolerance of variable severity during pregnancy. The incidence of GDM-related complications and adverse pregnancy outcomes has declined, in part, due to early screening. Machine learning (ML) models are increasingly used to identify risk factors and enable the early prediction of GDM. Objective The aim of this study was to perform a meta-analysis and comparison of published prognostic models for predicting the risk of GDM and identify predictors applicable to the models. Methods Four reliable electronic databases were searched for studies that developed ML prediction models for GDM in the general population instead of among high-risk groups only. The novel Prediction Model Risk of Bias Assessment Tool (PROBAST) was used to assess the risk of bias of the ML models. The Meta-DiSc software program (version 1.4) was used to perform the meta-analysis and determination of heterogeneity. To limit the influence of heterogeneity, we also performed sensitivity analyses, a meta-regression, and subgroup analysis. Results A total of 25 studies that included women older than 18 years without a history of vital disease were analyzed. The pooled area under the receiver operating characteristic curve (AUROC) for ML models predicting GDM was 0.8492; the pooled sensitivity was 0.69 (95% CI 0.68-0.69; P<.001; I2=99.6%) and the pooled specificity was 0.75 (95% CI 0.75-0.75; P<.001; I2=100%). As one of the most commonly employed ML methods, logistic regression achieved an overall pooled AUROC of 0.8151, while non‚Äìlogistic regression models performed better, with an overall pooled AUROC of 0.8891. Additionally, maternal age, family history of diabetes, BMI, and fasting blood glucose were the four most commonly used features of models established by the various feature selection methods. Conclusions Compared to current screening strategies, ML methods are attractive for predicting GDM. To expand their use, the importance of quality assessments and unified diagnostic criteria should be further emphasized.","Principal Findings This study was a pilot meta-analysis evaluating the performance of ML models for predicting GDM. Its overall pooled estimation of 25 studies showed that ML models achieved high accuracy in early recognition of GDM patients. ML models could forecast based on data from 8 to 24 weeks‚Äô gestation. There was even a model that used prepregnancy features to predict the outcome up to 28 weeks in advance, suggesting the significance of ML models for GDM prediction. Compared to the census or existing screening methods, ML methods have certain advantages. Universal screening leads to 100% detection for physicians who usually make decisions based on an OGTT test, which may place an unnecessary burden on individual women and health care resources. Current selective screening strategies are based on a list of risk factors and have fixed sensitivity (¬±65%) and specificity (¬±80%). Although the ML methods do not provide greater benefit than current available screening strategies, an advantage is that a preferred trade-off between sensitivity and specificity can be selected [43]. The choice of statistical method is more to compute a quantitative measure of existing data than to predict unknown data in a general and feasible way [44]. According to the subgroup analysis, models created using non-LR methods achieved the highest AUROC, suggesting that researchers should test more candidate models. One study aimed to review and compare the predictive performances of LR and other ML algorithms for developing or validating a multivariable prognostic prediction model for pregnancy care; that study also recommended a reanalysis of existing LR models for several pregnancy outcomes by comparing them with those algorithms that apply standard guidelines [45]. Among those non-LR models, ensemble methods, like LightGBM and GA-CatBoost, that are composed of multiple weaker models and are independently trained had a satisfactory result. Variables in the GBDT model underscored the advantage of identifying nonlinear relationships. The SVM model also achieved superior outcomes; that method builds a model that assigns new examples to one category or the other, making it a nonprobabilistic binary linear classifier. Methods like KNN, DT, and RF did not perform as well as the LightGBM and GA-CatBoost methods, which may be due to the fact that DT classifications are based on a single condition at the bottom, so small changes can lead to mistakes. For RF, the high dimension of medical data complicates the classification and prediction. Similarly, KNN cannot be used in high-dimensional feature spaces. Some researchers [23] found that the difference between two methods had no statistical significance, since LR models are suitable for simple data with linear relationships between variables and outcomes. Our study also found that LR models were conducive to achieving more stable performance according to the summary receiver operating characteristic curve. The subgroup of 0 to 13 weeks before diagnosis achieved the highest pooled sensitivity, while the subgroup of 14 to 28 weeks before diagnosis achieved the highest specificity, meaning that ML may assist clinicians identify more patients in early screening and avoid excessive misdiagnosis in the second trimester. The feature selection was also crucial for model performance and interpretation. Among the 25 studies, maternal age was used as a feature in 19 studies, as was previously reported and validated in our study. One of the included studies reported that the incidence of GDM increases after 25 years of age, the main reason being that the function of islet Œ≤-cells decreases with age, so the insulin antagonism of older adult pregnant women is aggravated [46]. Eight models considered GDM history to be a vital factor for predicting GDM. A DOR value of 21.09 appeared when a GDM history was included as a risk factor for predicting future GDM. Previous research discovered that women with GDM were more likely to have a family history of type 2 diabetes mellitus and a history of GDM, partially due to overlapping genetic bases between the diseases [18]. The nonsignificant association of GDM with a GDM history in other studies was a result of the overwhelming proportion of nulliparous women in their studies who had no risk of developing GDM. The association between GDM and blood lipid indexes, including triglyceride (TG), high-density lipoprotein, and low-density lipoprotein (LDL), has been studied, and TG level had the closest relationship with GDM [47]. Our research also found that although the levels of TG, total cholesterol, and LDL in the GDM group were higher than those in normal pregnant women in most included studies, only TG level was a high-risk factor of GDM after the feature selection. A novel model that included ultrasound data of maternal fat distribution and serum inflammatory factors observed that pregnant women with GDM had greater visceral fat thickness and subcutaneous fat thickness; the model also demonstrated that increased subcutaneous and visceral fat may lead to increased insulin resistance in muscle and adipose tissue [36]. Sweeting et al [27] observed higher leptin and lipocalin-2 levels and lower adiponectin levels in women who developed GDM and proposed adipokines as GDM features. Strengths and Limitations The main strength of the study is that its methodology was logical and described in sufficient detail to be reproducible. Almost all published prognostic models for GDM were included in this meta-analysis, which enabled their comparison. The data collection table was based on the characteristics of the GDM prediction models. Additionally, the novel PROBAST was used to assess the risk of bias and applicability of prognostic prediction model studies. The Quality Assessment of Diagnostic Accuracy Studies (QUADAS) tool is a widely used tool for estimating the bias and applicability of primary diagnostic accuracy studies, but is not perfectly suited for predictive models [48]. An increasing number of researchers prefer the PROBAST to the QUADAS tool for assessing the bias of AI-based models in systematic reviews as well as meta-analyses; this is the case because more details of the model, such as data source, processing, number of events per variable, feature selection, model development, and model validation, were checked intensively [49-52]. We found that 14 development studies had a risk of bias in methodological quality or applicability, which may lead to overfitted prediction models. It is noteworthy that the quality of recent models is higher than that of those published earlier according to the PROBAST. Some bias could be prevented if the studies reported their research according to the TRIPOD initiative [12]. Despite our study‚Äôs confirmation that ML models have promising prediction ability for GDM, there are some limitations to our research. The main limitations arose from the interstudy heterogeneity. First, the sample sizes and distributions differed among studies, affecting each model‚Äôs performance and applicability. There were also a heterogenous variety of feature selection methods. Some researchers preferred the features that have a statistically significant association with GDM, while others included the factors based on existing knowledge from previously established models in combination with predictor reliability, consistency, applicability, availability, and cost. Second, the performance of a low-quality model might be overestimated when the analysis of the internal bias of the model is ignored. As some studies have bias to various degrees, the results of the studies in this analysis must be applied with caution. It should be noticed that the PROBAST is more likely to identify bias in prediction models than other tools designed for conventional diagnostic methods. The other limitation is that few models underwent external validation to test their extensibility. However, a previous study [8] performed an external validation of 12 published GDM prediction models and suggested that most of the published models showed acceptable discrimination and calibration, but the author pointed out possible heterogeneity in these models due to variations in GDM incidence in different populations. Clinical Implications Although several GDM scoring systems have been developed, none are widely recommended by current guidelines. Based on the discussion above, several items must be considered in order to maximize the advantages of ML models for predicting GDM in clinical practice for model researchers or for decision makers. For the former, we recommend that the decision concerning which feature selection methods and ML algorithms to use should be based on clinical need rather than accuracy. A model with excess features that are difficult to obtain in routine medicine is unlikely to be applied broadly. Researchers should also provide the process of data preprocessing and outcomes of validation, discrimination, calibration, and classification to elaborate the performance of models from multiple perspectives. For decision makers, we recommend that data sources, such as a population-based cohort designed for GDM research with a unified international diagnostic criterion, promote the ML methods in this target. Studies revealed that although electronic health records provide various data, including time series and images for novel ML methods, they have inherent biases that are influenced by the interaction of the patient with the health care system. In contrast, community-based predictions may robustly capture more asymptomatic high-risk cases [53]. The incidence of GDM based on the International Association of the Diabetes and Pregnancy Study Groups (IADPSG) (22.94%) and the National Institute for Health and Care Excellence (21.72%) is over 3-fold higher than that based on the criteria from the 7th edition of the Chinese obstetrics and gynecology textbook (6.08%) published by the People‚Äôs Medical Publishing House [54]. Some experts in China have advocated implementation of the IADPSG criteria because they believe that it will guide researchers to better understand the prevalence of GDM in different regions and ensure that the country‚Äôs standards will be aligned with international ones. Nevertheless, researchers doubt that the IADPSG findings will apply to all populations, since those criteria were applied to mainly Caucasian women. All in all, it would indeed be helpful to unify the GDM diagnostic criteria as soon as possible. This meta-analysis reported the advantages of ML models and the factors requiring attention. A similar meta-analysis of ML models and deep learning algorithms used to detect patients at risk of developing diabetes reported that AI-based automated tools provide substantial benefits for reducing screening costs and can replace earlier treatments [55]."
2022,Environmental chemical exposure dynamics and machine learning-based prediction of diabetes mellitus,"Background With dramatically increasing prevalence, diabetes mellitus has imposed a tremendous toll on individual well-being. Humans are exposed to various environmental chemicals, which have been postulated as underappreciated but potentially modifiable diabetes risk factors. Objectives To determine the utility of environmental chemical exposure in predicting diabetes mellitus. Methods A total of 8501 eligible participants from NHANES 2005‚Äì2016 were randomly assigned to a discovery (N = 5953) set and a validation (N = 2548) set. We applied random forest (RF) and least absolute shrinkage and selection operator (LASSO) regression with 10-fold cross-validation in the discovery set to select features, and built an optimal model to predict diabetes mellitus, blood insulin, fasting plasma glucose (FPG) and 2-h plasma glucose after oral glucose tolerance test (2-h PG after OGTT). Results The machine learning model using LASSO regression predicted diabetes with an area under the receiver operating characteristics (AUROC) of 0.80 and 0.78 in the discovery set and validation set, respectively. The linear model predicted blood insulin level with an R2 of 0.42 and 0.40 in the discovery set and validation set, respectively. For FPG, the discovery set and validation set yielded an R2 of 0.16 and 0.15, respectively. For 2-h PG after OGTT, the discovery set and validation set yielded an R2 of 0.18 and 0.17, respectively. Conclusion We used environmental chemical exposure, constructed machine learning models and achieved relatively accurate prediction for diabetes, emphasizing the predictive value of widespread environmental chemicals for complicated diseases.","With dramatically increasing prevalence, diabetes mellitus has imposed a tremendous toll on individual well-being. Environmental chemicals acting as endocrine disruptors have been postulated as underappreciated risk factors of diabetes (Sargis and Simmons, 2019). In this study, we sought to examine associations between environmental chemical exposure and diabetes mellitus and determined the potential predictive value of environmental chemical exposure for diabetes mellitus. Machine learning-based method demonstrated that environmental chemical exposure made important contributions to predictive modeling, and a relatively good performance of our prediction model was observed when dealing with the binary outcome of diabetes rather than continuous ones (i.e., insulin, FPG and 2-h PG after OGTT). Basically, humans are exposed to various environmental chemicals in the real world, which cannot be ignored. It has been well established that exposure to environmental chemicals is significantly associated with diabetes (Mansouri and Reggabi, 2021; Tsai et al., 2019; Wang et al., 2020), providing a new perspective for the involvement of environmental chemicals in the prediction model of diabetes. However, contrary to numerous association studies, there have been few predictive modeling studies taking environmental chemicals into consideration (Cahn et al., 2020). It is vital to discover potential environmental biomarkers for a higher-resolution classifier of diabetes. Therefore, we firstly used random forest to construct a novel prediction model which led to the poor performance and overfitting. The problem of overfitting is often caused by sparse datasets, namely too few objects with too many features. On the other hand, LASSO method showed a better prediction performance and promoted the interpretability of the model by eliminating irrelevant variables. The result of the prediction model in the discovery set was highly consistent with that in the validation set, suggesting that the LASSO regression model was a robust and informative machine learning tool to construct a prediction model in our study with a sample size of 8501. For studies with larger sample sizes, however, it is recommended to try more machine learning methods to deal with different situations. In our study, Pb, Hg, As and Cd were the top environmental chemicals with major contributions in the prediction model. Heavy metals, commonly classified as endocrine disruptors (Iavicoli et al., 2009), have long been known to damage organ functions, disrupt physiological homoeostasis and consequently cause adverse health effects. According to previous studies, it has been hypothesized that heavy metals increase the risk of diabetes through mechanisms like oxidative stress, activation of inflammation, and inhibition of peroxisome proliferator-activated receptor gamma (PPAR-Œ≥) (Odegaard et al., 2016; Wu et al., 2016). Additionally, Pb up-regulates the transcription of phosphoenolpyruvate carboxykinase 1 (PCK1) and glucose-6-phosphatase (G6PC), which play important roles in glucose homeostasis (Planchart et al., 2018). Hg and As have been reported to impact glucose tolerance due to impairing insulin secretion among in Œ≤-cells (He et al., 2013; Peng et al., 2015). These could be underlying mechanisms explaining associations between the above elements and diabetes, as well as the potential predictive value. Moreover, other EDCs including organochlorine pesticides, phthalates, BPA, etc. have also been reported to induce insulin resistance possibly by downregulation of glucose transporters, influence insulin-secreting Œ≤-cells by downregulation of muscarinic receptors, and eventually promote diabetes (Lind and Lind, 2018). Association studies and mechanism studies jointly delineate that the underlined environmental chemicals in our study account for an important contribution to the discrimination of diabetes. Generally, previous studies concentrated on digging out new biomarkers for prediction of diabetes, ignoring the potential value of environmental exposure. We built prediction models using machine learning methods to detect whether environmental chemicals accurately predicted the risk of diabetes, offering a new opportunity for predicting environment relevant diseases. Noteworthy, some prediction models used clinical predictors including age, sex and ethnicity etc., and achieved an AUROC of approximately 0.68 (Noble et al., 2011), which aligned well with that characteristic information made an important contribution in our model. Even though metabolic disorders (e.g., diabetes) associate much closer with lifestyle, dietary and behavioral factors (Kolb and Martin, 2017), the prediction model including environmental chemical exposure in our study achieved an AUROC up to 0.78, suggesting the importance of environmental chemical exposure in risk prediction. With regard to those diseases closely related to environmental exposure such as respiratory diseases and cardiovascular diseases, accounting for approximately one-fourth of all diseases, released by the World Health Organization (WHO), there is no doubt that embracing environmental chemical exposure into the prediction model makes sense. Our study proposed a strategy for handling high-dimensional data and mixed effects of exposure and encouraged taking environmental chemical exposure into consideration when dealing with complicated diseases. There were some strengths of our study. First of all, we investigated the joint effects of multiple environmental chemicals on the risk of diabetes and further constructed prediction models. Secondly, our findings of major environmental contributors to diabetes were highly consistent with previous association studies. Lastly, both RF and LASSO regression were employed and the latter showed a better performance. However, there were still some major limitations in our study. First, diabetic patients were assumed to be diagnosed as type 2 diabetes due to no history of insulin injection, although we could not definitely discriminate whether they suffered from type 1 or type 2 diabetes from NHANES detailed information. Second, considering NHANES is a cross-sectional study, our prediction model should further be validated in an independent cohort study. Third, we could not assess whether the inclusion of multiple environmental chemicals could improve the predictive power of traditional models using metabolic or genetic biomarkers due to lack of such data in NHANES. Fourth, although we have employed additional evaluation metrices (i.e., AUPRC and F1-score), the class imbalance problem, which might influence the identification performance of the machine learning model, could not be fully avoided."
2022,Development and internal validation of machine learning algorithms for end-stage renal disease risk prediction model of people with type 2 diabetes mellitus and diabetic kidney disease,"Aims Diabetic kidney disease (DKD) is the most common cause of end-stage renal disease (ESRD) and is associated with increased morbidity and mortality in patients with diabetes. Identification of risk factors involved in the progression of DKD to ESRD is expected to result in early detection and appropriate intervention and improve prognosis. Therefore, this study aimed to establish a risk prediction model for ESRD resulting from DKD in patients with type 2 diabetes mellitus (T2DM). Methods Between January 2008 and July 2019, a total of 390 Chinese patients with T2DM and DKD confirmed by percutaneous renal biopsy were enrolled and followed up for at least 1‚Äâyear. Four machine learning algorithms (gradient boosting machine, support vector machine, logistic regression, and random forest (RF)) were used to identify the critical clinical and pathological features and to build a risk prediction model for ESRD. Results There were 158 renal outcome events (ESRD) (40.51%) during the 3-year median follow up. The RF algorithm showed the best performance at predicting progression to ESRD, showing the highest AUC (0.90) and ACC (82.65%). The RF algorithm identified five major factors: Cystatin-C, serum albumin (sAlb), hemoglobin (Hb), 24-hour urine urinary total protein, and estimated glomerular filtration rate. A nomogram according to the aforementioned five predictive factors was constructed to predict the incidence of ESRD. Conclusion Machine learning algorithms can efficiently predict the incident ESRD in DKD participants. Compared with the previous models, the importance of sAlb and Hb were highlighted in the current model.","After comparing the performance of the above machine learning algorithms in establishing risk prediction models for ESRD in participants with T2DM and DKD, we found that the RF predictive model displayed the highest AUC (0.90) and ACC (82.65%), suggesting that baseline features of participants with DKD can be used to predict renal survival (sensitivity = 83.33% and specificity = 81.58%, respectively). Furthermore, a nomogram based on the top five factors (CysC, sAlb, Hb, UTP, and eGFR) derived from the RF algorithm was developed to predict the possibility of renal survival, which is a simple and practical risk calculator for clinicians. In the current study, the top five factors in the predictive model partially overlapped with the findings of a previous study [9] (i.e., higher CysC levels, lower eGFR, and higher Log ACR levels). Our previous study had shown that the calculation of eGFR incorporating CysC was better than sCr-based eGFR calculations alone for the early detection of kidney injury [14]. UTP was the fifth-ranked variable in the relative importance of features included in our machine learning model. Conventionally, DKD severity was assessed by measuring urine albumin levels combined with eGFR. Increased urinary albumin excretion had been known as a major risk factor for the DKD progression [15]. In contrast to the findings from the study of Sun et al., we found variables of sAlb and Hb besides CysC levels, eGFR, and Log ACR were critical in predicting ESRD. The differences in the characteristics of the enrolled participants between the two studies may account for such findings. The participants in this study displayed higher sAlb and Hb levels than in the other study. Our previous study had strongly suggested that a lower level of sAlb had association with declining renal function and worse renal prognosis for DKD participants, independent of histopathological and clinical parameters [5]. A machine learning model for predicting long‚Äêterm ESRD by Belur Nagaraj et al. [16] also included sAlb as a crucial predictor. A significant inverse correlation of sAlb levels with glomerulopathy and proteinuria might explain the correlation between hypoalbuminemia and the incidence of ESRD. Moreover, the level of sAlb could reflect the degree of oxidative stress and inflammation to some extent. Thus, hypoalbuminemia might accelerate the deterioration of kidney function by inducing endothelial inflammatory injury and oxidative stress [17‚Äì19]. The progression of DKD might further lead to reduced energy and protein intake and malnutrition, leading to more severe hypoalbuminemia [20]. Therefore, improving hypoalbuminemia through inhibiting inflammatory state and controlling malnutrition as well as proteinuria might play a crucial role to slow down the progression to ESRD based on our model and previous study. Furthermore, anemia has been recognized as a sequela of advanced DKD, caused by tubulointerstitial damage [21]. Lower baseline Hb was found to be a risk factor for ESRD in patients with T2DM [22] and in patients with DKD [8]. Anemia induces insufficient oxygen supply in renal tubular cells, low perfusion of capillaries, and damage to energy production, and in involved in the pathogenesis of CKD [23,24]. DKD-related anemia tends to be more severe and develops earlier in comparison with non-DKD-related anemia on the basis of complex mechanisms, such as the inhibitory effects of inflammatory cytokines, poor response to erythropoietin (EPO), and the loss of EPO in urine [25]. Notably, participants who had hypoalbuminemia were also susceptible to being anemic, which could accelerate their kidney damage [26]. Indeed, our group and others had identified hypoxia-mediated pathways as potential therapeutic targets [27]. Since activation of hypoxia-inducible factor (HIF) prevents diabetes-induced tissue hypoxia, proteinuria, and renal tubular interstitial fibrosis by protecting mitochondrial function, HIF improving renal oxygen homeostasis might be a new target for DKD treatment [28]. The inhibition of the sodium/glucose cotransporter 2 was able to suppress HIF-1Œ± and activate HIF-2Œ± and thereby augment erythropoiesis, which can alleviate cellular stress and renal hypoxia, while muting organellar dysfunction, inflammation, and fibrosis29. In the current study, pathological parameters were not incorporated in the Nomogram model and were not as significant as the other predictor factors, which was in contrast to the finding of the study by Sun et al. [9]. Additionally, the addition of glomerular class did not significantly change the predictive performance of the model. That is why RPS scores were not included in our final model. Unfortunately, biopsy-based studies on DKD are limited. The clinical significance of renal biopsy in patients with T2DM with advanced CKD remains controversial. Some studies found that the predicted values of the Kidney Failure Risk Equation and the Diabetic Nephropathy Score (D-score) were not optimal [30]. In the study by Sun et al., the glomerular class of enrolled participants was different from our study (4% vs. 5% of grade I, 7% vs. 22% of grade IIa, 10% vs. 14% of IIb, 63% vs. 45% of grade III and 16% vs. 14% of grade IV, respectively), which may also contribute to the finding discrepancy. Although some pathological changes were found to be associated with dysfunction, further studies are needed to identify which types and grades of pathological lesions and scoring systems are the most appropriate way to predict renal outcomes of DKD. Interestingly, previous predictive models of the incidence of ESRD in patients with T2DM with or without mild kidney damage identified distinctly different features from our model, which predicted ESRD in patients with T2DM with DKD [2‚Äì4]. For example, age and sex were not predictive factors for the incidence of ESRD in participants with T2DM with DKD, which was consistent with the study by Sun et al. [9]. Our previous study indicated that although the rate of rapid progression of kidney disease was relatively low in the youth group, there was no significant difference in the incidence of ESRD among the age groups [31]. Moreover, Wysham et al. showed that age was a significant risk factor related to the risk of DKD and renal-related death for T2DM participants, but not ESRD. Moreover, conflicting findings had been reported in different cohorts and studies had found that the effect of sex was less apparent in DKD than in non-DKD [8]. Taken together, although age and sex were deemed to be crucial factors in the prediction of ESRD in T2DM participants, they might be not as vital in the prediction of ESRD for participants with advanced DKD. Moreover, anti-hypertension, anti-diabetes, and anti-hyperlipidemia medication were selected in the model for participants with T2DM as well, which were not included in the models for participants with advanced DKD. For patients with diabetes, the primary preventative measure is to prevent the occurrence of renal damage, while for patients with diabetes and DKD, delaying the progression and deterioration of renal function to ESRD is paramount throughout every stage of renal damage, since DKD is a chronic disorder with a long duration of disease. The risk factors for DM patients with or without DKD are totally different, even for DKD with different eGFR. DM-care physicians are suggested to strengthen routine and regular monitoring of proteinuria, renal function, serum albumin, and Hb in patients with T2DM and early DKD, pay extra attention to patients with anemia, hypoalbuminemia, proteinuria, and abnormal renal function, and provide early intervention for these patients. Taken together, in contrast with the treatment of participants with early-phase T2DM with or without mild kidney damage, major emphasis should be placed on indicators related to kidney function, nutrition, and anemia for participants with T2DM and advanced DKD to delay the ESRD, rather than age, sex, and control of hypertension and glycemia. Our study has some notable strengths. First, this is the first study to use machine learning to construct a prediction model for the incidence of ESRD in patients with DKD. Although machine learning is considered to perform well with large databases and big data sets, the RF method is generally recognized for its accuracy and its ability to deal with small sample sizes. In the current study, the RF model showed the highest AUC and ACC, indicating that the model was reliable. Second, the DKD participants of the study were biopsy-confirmed. Third, the pathological parameters of our study were more detailed than those in the model of previous studies. Fourth, although CysC, eGFR, and UTP overlapped with previous models, this is the first study to identify sAlb and Hb as important factors in a predictive model for ESRD. Next, the parameters used in our risk prediction model for ESRD are readily available in the clinic, thus making this model easily applicable in primary care clinical settings. Our predictive model has the potential to recognize participants at high risk for ESRD early in DKD progression, and to provide intensive treatment to those participants to increase the chance of early treatment. The limitations in our study were as followed. First, participants were registered from a single center and may not represent the Chinese participants as a whole. Further multicenter validation in China and external validation in different ethnic populations is needed. The study sample size was moderate as well. Additionally, some other parameters, such as history of acute kidney injury (AKI), genetic factors, diet, and socioeconomic status, which might also have an effect on survival, were not investigated for all of the participants with DKD at the time of recruitment. Notably, damaged kidney cells from DKD are more susceptible to AKI. Repeated AKI causes maladaptive repair of the diabetic kidney, resulting in the accumulation of irreversible tubulointerstitial fibrosis, which eventually leads to ESRD [32]. Moreover, due to the long enrollment period, changes in treatment plan may have an impact on the prognosis of patients. Regarding the development of the model, the RF algorithm could ignore multicollinearity, so the interpretation of the data may have been affected. Therefore, it is crucial to select the variables in conjunction with the clinical consensus. Taken together, machine learning algorithms can efficiently predict the incidence of ESRD in patients with DKD. The major predictive factors of ESRD were sAlb, CysC, Hb, eGFR, and UTP. Compared with previous models, the importance of sAlb and Hb levels were highlighted in our model."
2022,Machine learning-based models for gestational diabetes mellitus prediction before 24-28 weeks of pregnancy: A review,"Gestational Diabetes Mellitus (GDM) is a hyperglycemia state that impairs maternal and offspring health, short and long-term. It is usually diagnosed at 24‚Äì28 weeks of pregnancy (WP), but at that time the fetal phenotype is already altered. Machine learning (ML)-based models have emerged as an auspicious alternative to predict this pathology earlier, however, they must be validated in different populations before their implementation in routine clinical practice. This review aims to give an overview of the ML-based models that have been proposed to predict GDM before 24‚Äì28 WP, with special emphasis on their current validation state and predictive performance. Articles were searched in PubMed. Manuscripts written in English and published before January 1, 2022, were considered. 109 original research studies were selected, and categorized according to the type of variables that their models involved: medical, i.e. clinical and/or biochemical parameters; alternative, i.e. metabolites, peptides or proteins, micro-ribonucleic acid molecules, microbiota genera, or other variables that did not fit into the first category; or mixed, i.e. both medical and alternative data. Only 8.3 % of the reviewed models have had validation in independent studies, with low or moderate performance for GDM prediction. In contrast, several models that lack of independent validation have shown a very high predictive power. The evaluation of these promising models in future independent validation studies would allow to assess their performance on different populations, and continue their way towards clinical implementation. Once settled, ML-based models would help to predict GDM earlier, initiate its treatment timely and prevent its negative consequences on maternal and offspring health.","4.1. The importance of independent validation Only 8.3 % of the GDM predictive models presented in this review have had independent validation. This is consistent with what was reported by Lamain de Rutier et al. in 2017. Their systematic review on clinical data-based multivariate models for GDM prediction and risk estimation, found out that only four out of 14 strategies were validated in independent studies [28]. Our review demonstrates that this issue have persisted in time and is not limited to clinical variables-based models. Independent validation is an essential step before the clinical implementation of a predictive model, since it ensures the assessment of its performance in populations that are different from the one that was involved in its calibration. Consequently, it confirms or refutes if the model will predict the pathology of interest accurately in patients from different ages, ethnicity, medical background, health centers, geographical areas and time periods. Most of the reviewed models that have had independent validation are only based on clinical data, which can be explained by the fact that these strategies were the first to be developed. Moreover, clinical variables are the easiest to obtain, since they do not need to be acquired invasively. Thus, this kind of approach is the easiest to implement in medical practice. However, independent validation of these models have demonstrated that they have low (AUC 0.6‚Äì0.7) or moderate (AUC 0.7‚Äì0.8) predictive power [23], [24], [25], [26], [27]. Therefore, other approaches must be considered and assessed. 4.2. The most promising models for GDM early prediction The three models with higher predictive power presented in this review are not based on clinical variables. Xiong et al. strategy employs biochemical parameters and achieved an AUC of 0.998 [48], Koos et al. model uses metabolomics-derived data and yielded an AUC of 0.993 [106], and Zhao et al. approach combines proteomics-derived variables and reached an AUC of 0.985 [112]. All these strategies are based on parameters that are measured in biological fluids and, consequently, are more invasive than the ones that employ clinical variables. However, none of them are based on classic GDM risk factors, but explore the performance of new biomarkers for its prediction, which is relevant considering that 17‚Äì48 % of women that develop GDM do not have evident risk factors [7]. Due to the complexity of the procedures needed to obtain the variables involved, some of these models are more likely to be implemented in routine clinical practice in the short term. For example, Xiong et al. strategy is based on two coagulation variables. Since coagulation parameters are measured in blood, a sample that is commonly required at regular pregnancy controls, and clinical laboratories are usually equipped to measure them, the implementation of this model in medical settings is plausible. In contrast, Koos et al. approach is based on seven metabolites, which are measured in urine. The obtainment of this biological sample is less invasive than the obtainment of blood. However, metabolomics analysis implies the use of LC-MS and/or GC‚ÄìMS equipment that is not usually available in clinical laboratories. Thus, the immediate and wide clinical implementation of this model is unlikely. Likewise, Zhao et al. strategy is based on four serum proteins, which were originally measured by LC-MS. Nevertheless, these proteins may be measured by antibodies-based assays, which are often available in clinical laboratories. Therefore, the implementation of this model in medical settings is feasible. In consequence, both Xiong et al. and Zhao et al. strategies have a great potential to be implemented in clinical practice. However, none of them have had independent validation. In fact, while the first model was externally validated within its original article, the second one has never been validated. 4.3. Lack of validation is an opportunity 56.0 % of the GDM predictive models presented in this review were not validated in their original articles, nor have been validated in independent studies. In this context, we encourage researchers to validate their predictive models when developing a new one. Internal and external validation can be performed easily, since they do not necessarily require more than the already available subjects. Indeed, the working dataset can be split in two, i.e. a training one for calibration and internal validation, and a testing one for external validation. Although splitting-sampling is not the best form of external validation, as the testing population is quite similar to the training one, it is better than not carrying out any. Of course, a completely different cohort should be used for external validation, if available. In addition, we motivate researchers to report model validation as recommended in the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) statement, a 22-item checklist that aims to improve the reporting quality of studies developing, validating or updating a prediction model [140]. Furthermore, we encourage the scientific community to share their predictive models, so they can be available for independent validation, and to carry out studies to validate the models that are already published. Independent validation demands an important effort from researchers, since it requires to recruit and follow-up a large cohort of subjects, and both time and resources are spent; however, it is essential to achieve the goal of implementing any type of predictive model in medical practice. Importantly, validation is not the only requirement that predictive models must fulfill before their clinical implementation. Once validated, a model must go through a process called ‚Äúimpact analysis‚Äù, in which its effect on clinical behavior is assessed. Only the models that change physician behavior with beneficial consequences, i.e. improve patients outcomes and/or reduce costs without compromising the quality of care and patient satisfaction, are considered appropriate for clinical implementation [20]. Since only after independent validation predictive models are suitable for impact analysis and subsequent application in medical settings, the fact that most of the GDM predictive models reported in literature have never been validated is a great opportunity to continue their way towards clinical implementation. 4.4. Strengths of this review Our search strategy was not restricted to a specific type of variable. Moreover, we considered several synonyms of the terms of interest to comprise as many models as possible. This allowed us to include 109 original research articles and their best predictive models in this review, models that were based on a wide variety of variables, i.e. medical, alternative or mixed. This is the first review to assess this amount and diversity of ML-based models for GDM prediction before 24‚Äì28 WP. 4.5. Limitations of this review Our review was limited to PubMed English-written articles. In addition, we only included studies that reported the predictive power of their models by AUC, accuracy, specificity, sensitivity or Q2. In other words, we excluded manuscripts that stated their models performance by other parameters, i.e. likelihood ratios, positive and negative predictive values or odds ratio. Hence, we may have missed some highly accurate and potentially promising models for GDM early prediction."
2022,Machine Learning Models for Data-Driven Prediction of Diabetes by Lifestyle Type,"The prevalence of diabetes has been increasing in recent years, and previous research has found that machine-learning models are good diabetes prediction tools. The purpose of this study was to compare the efficacy of five different machine-learning models for diabetes prediction using lifestyle data from the National Health and Nutrition Examination Survey (NHANES) database. The 1999‚Äì2020 NHANES database yielded data on 17,833 individuals data based on demographic characteristics and lifestyle-related variables. To screen training data for machine models, the Akaike Information Criterion (AIC) forward propagation algorithm was utilized. For predicting diabetes, five machine-learning models (CATBoost, XGBoost, Random Forest (RF), Logistic Regression (LR), and Support Vector Machine (SVM)) were developed. Model performance was evaluated using accuracy, sensitivity, specificity, precision, F1 score, and receiver operating characteristic (ROC) curve. Among the five machine-learning models, the dietary intake levels of energy, carbohydrate, and fat, contributed the most to the prediction of diabetes patients. In terms of model performance, CATBoost ranks higher than RF, LG, XGBoost, and SVM. The best-performing machine-learning model among the five is CATBoost, which achieves an accuracy of 82.1% and an AUC of 0.83. Machine-learning models based on NHANES data can assist medical institutions in identifying diabetes patients.","4.1. Main Findings Using five machine-learning models (CATBoost, XGBoost, RF, LR, and SVM), we attempted to predict diabetes based on lifestyle-related variables. We preprocessed the input data before training the model and used the mean to impute data with <5% missing values. In addition, we used SMOTE-NC to class-balance the data (the number of negative samples was much larger than the number of positive samples) to prevent the machine-learning model from outputting a single negative conclusion when making predictions when our dataset is class-imbalanced. Ultimately, we found that the performance ranking of the five machine-learning models was CATBoost > RF > LR > XGBoost > SVM. CATBoost has the best performance indicators among the five machine-learning models, with an AUC of 0.83 and an accuracy rate of 82.1%. Therefore, CATBoost may be employed as the best model for diabetes prediction for individuals in the prediction of machine-learning models based on or even modality variables. 4.2. Model Performance Previous studies have attempted to build machine-learning models for predicting diabetes. However, most previous studies employed random forests, logistic regression, k-nearest neighbors, and other machine learning models based on bagging algorithms to predict diabetes [45,46,47,48]. For example, Hu et al. [47] built a diabetes prediction model for adolescents using logistic regression and Gradient Boosted Tree and finally obtained a machine-learning model with an RUC of 71%. Krishnamoorthi [49] et al. An intelligent framework for diabetes prediction was constructed by applying four machine learning methods, with an RUC of 0.8 and final prediction accuracy of 83%. Although previous researchers have achieved good model results, few machine learning models for diabetes prediction based on the Boosting algorithm are still few. For example, Kumar et al. used CatBoost, logistic regression, support vector machines, and artificial neural networks to predict the probability of diabetes in gestational women and finally got an AUC of 0.86. Zhang et al. used logistic regression, support vector machines, random forests, and Catboost and Xgboost to predict childhood insulin resistance and obtained an AUC of 0.85. Using the Boosting algorithm to develop a model can better solve the problem of gradient bias and prediction offset, thereby reducing the occurrence of overfitting and improving the accuracy and generalization ability of the algorithm [45,46,47,48]. Compared with previous studies, our study optimized the previous researchers‚Äô diabetes prediction model, which achieved higher AUC and accuracy rates on easy access to characteristic variables. 4.3. Model Features As characteristic factors in our study, we selected demographics data and 18 lifestyle data from NHANES. Gender, age, race, country of birth, education level, poverty ratio, BMI, energy, protein, carbohydrates, sugar, total fat, cholesterol, smoking status, sleep duration, alcohol consumption, and systolic and diastolic blood pressure were among them. Most previous researchers [50,51,52] included biochemical indicators as an essential variable in their diabetes-prediction models. Lifestyle-related indicators have better collectability and de-aggression than biomarkers. Therefore, the model we established is independent of biochemical indicators, and our goal is to construct a practical and user-friendly screening model. Figure 2 depicts the relative importance of various variables, which is consistent with past reports [53], with sleep duration, daily nutrient intake (such as energy, carbohydrates, fat, etc.), and age being the most important variables influencing model design. Furthermore, according to Civeira‚Äôs research [54], age ranks third in feature importance as an essential demographic variable. 4.4. Model Advantage In the diabetes domain, diabetes datasets are often class-imbalanced datasets (a large number of people without diabetes and a small number of people with diabetes). Therefore, in contrast to earlier studies [46], we employed the SMOTE-NC method to deal with imbalanced class data. In contrast to prior research that did not use class imbalanced data, our machine-learning model could reduce missing and misdiagnosis rates. In addition, having too many variables in the model makes it heavy and slow. The significant increase in the data dimension will in-crease the complexity of the classification model, as well as the phenomenon of overfitting [32]. Feature selection plays an important role in traditional [55,56] and deep machine learning [57]. Thus we utilized the quantifiable AIC forward [33] propagation metric to filter the variables and eliminate the variables that contributed the least to the model. 4.5. Prospective to the Future In the future, our research will be more inclined to the field of deep learning, combining big data samples with deep learning models. In addition, we will further increase the sample size and strive to optimize the model further to have better model prediction performance."
2022,Accuracy of Machine Learning Classification Models for the Prediction of Type 2 Diabetes Mellitus: A Systematic Survey and Meta-Analysis Approach,"Soft-computing and statistical learning models have gained substantial momentum in predicting type 2 diabetes mellitus (T2DM) disease. This paper reviews recent soft-computing and statistical learning models in T2DM using a meta-analysis approach. We searched for papers using soft-computing and statistical learning models focused on T2DM published between 2010 and 2021 on three different search engines. Of 1215 studies identified, 34 with 136952 patients met our inclusion criteria. The pooled algorithm‚Äôs performance was able to predict T2DM with an overall accuracy of 0.86 (95% confidence interval [CI] of [0.82, 0.89]). The classification of diabetes prediction was significantly greater in models with a screening and diagnosis (pooled proportion [95% CI] = 0.91 [0.74, 0.97]) when compared to models with nephropathy (pooled proportion = 0.48 [0.76, 0.89] to 0.88 [0.83, 0.91]). For the prediction of T2DM, the decision trees (DT) models had a pooled accuracy of 0.88 [95% CI: 0.82, 0.92], and the neural network (NN) models had a pooled accuracy of 0.85 [95% CI: 0.79, 0.89]. Meta-regression did not provide any statistically significant findings for the heterogeneous accuracy in studies with different diabetes predictions, sample sizes, and impact factors. Additionally, ML models showed high accuracy for the prediction of T2DM. The predictive accuracy of ML algorithms in T2DM is promising, mainly through DT and NN models. However, there is heterogeneity among ML models. We compared the results and models and concluded that this evidence might help clinicians interpret data and implement optimum models for their dataset for T2DM prediction.","4.1. Synopsis of Evidence In recent years, information technologies such as ML models have become essential in predicting T2DM in patients and assigning management to healthcare providers. A significant research focus has been on developing intelligent digital health interventions. To our knowledge, this is the foremost and largest innovative systematic meta-analytic approach in ML model research at a global level, which drew from a wide-ranging number of articles that included over one thousand participants reporting the ML model‚Äôs prediction in T2DM disease. In this study, we evaluated the predictive performances of studies using ML prediction models for T2DM. Primary articles were chosen from the Web of Science, Scopus, and PubMed research databases. ML techniques, mixed with other perceptions presented in the learning healthcare systems method, tend to bring better care and management of T2DM to the well-being of society. Nevertheless, when presenting novel prediction models, one should consider the predictive performance, where the strengths and weaknesses of the ML approaches need to be considered. Recently, numerous modeling methods have been used to predict T2DM and manage T2DM; thus, selecting the most appropriate ML approaches for a specific problem one is trying to solve is always challenging. In this study, we pooled various ML approaches used in previous studies related to T2DM and compared their performance in terms of accuracy. However, the publication year and impact factor did not moderate the aggregate estimates of overall classification accuracy in the meta-regression analyses. However, it is essential to note that our research was limited to the English language. The pooled models‚Äô performance predicted T2DM with an overall accuracy of 86% (95% CI: 82%, 89%), similar to the 82% pooled therapeutic outcomes in depression reported recently [44]. The current pool is slightly higher than the overall c-index of 81.2% reported from a meta-analysis study of use and performance for diabetes prediction in a local setting [45]. This disparity could be attributed to differences in the burden of the disease across study settings, the sensitivity of the diagnostic assays used during these two different periods, and the choice and characteristics of study subjects. High predictive performance was achieved by all models, with accuracy ranging from 0.58 to 0.98. Compared to other models, the DT model performed the best, with an accuracy value of 0.88 (95% CI 0.82‚Äì0.92). However, this finding is not surprising because previous studies have revealed that the same ML model can produce diverse accuracy outcomes for the same dataset by selecting various values for the underlying hyperparameters [46,47]. Previous studies have demonstrated the significant role of the DT approach in other medical fields, such as therapeutic outcomes in depression [44] and cardiovascular diseases [48] and predicting diabetes mellitus [49]. Our results confirmed the outstanding performance of the DT method in the risk assessment of T2DM. Additionally, we grouped the various ML models into three categories: linear, non-linear, and ensemble. The models that used non-linear algorithms to predict T2DM performed better (0.88, 95% CI 0.84‚Äì0.91) than the linear model and ensemble modeling approach. This finding is consistent with the previous comparison between linear and non-linear models for classifying thyroid modules [50]. In addition, we also observed that the models based on ML for prediction in T2DM had been mainly focused on screening and diagnostics (0.91, 95% CI [0.74, 0.97]). This observation is also supported by the previous meta-analysis that utilized the ML model for therapeutic outcomes in depression [44]. A possible reason for this finding could be the variation in the year of publication. Our results show a broad spectrum of applications of ML models dominated by predictive approaches. 4.2. Policy Implications Since the discovery of non-infectious diseases, many scientific publications have been produced globally. The current T2DM offers a wide-ranging analysis of the research trends linked to T2DM through documents indexed in academic databases. At the same time, the findings from this systematic survey and meta-analysis have significant policy implications for evaluation and monitoring. These are adequate resources for clinicians to determine if an individual will develop type 2 diabetes mellitus in the coming time. Additionally, synthesizing individuals with T2DM is essential in assisting clinicians in designing an appropriate mechanism to protect vulnerable individuals and reduce pressure on health systems. The current ML techniques have outclassed conventional risk models in predicting T2DM. Still, individuals should be careful about changing their attitude regarding future diabetes risk after having the outcomes of a diabetes prediction test through ML techniques. In addition, ML techniques are vital to improving the predictive capacity of T2DM. Ongoing work should be carried out to build additional precise ML techniques other than the existing ones, supposing that the practicability of utilizing ML in a clinical situation would be improved compared to regular costly and time-consuming blood tests. Finally, the pooling of independent studies gives policymakers the information needed to make informed decisions in uncertain circumstances. 4.3. Limitations of the Overview Study A wide-ranging literature search and watchful data extraction were conducted to avoid bias. However, limitations exist in our study. This systematic meta-analysis was limited to articles written in the English language. In addition, only articles written between 2010 and 2021 were included in the study. Secondly, the authors may have overlooked some valuable keywords and bibliographic sources that may contain relevant articles. Furthermore, due to the scarcity of primary studies, very few preliminary studies have been included to aggregate the accuracy of predictive models at the global level. As a result, in the future, the scope of the study may be broadened to reflect such limitations. 4.4. Concluding Remarks and Recommendations This paper provided an in-depth study of automated T2DM prediction models. It reveals how the data mining and meta-analysis approach can be efficiently implemented in clinical medicine to obtain models that use patient-specific information to predict the end product. Critical articles were compiled from the Web of Science, Scopus, and PubMed scientific repositories. The classification models predicted outcomes for patients diagnosed with T2DM in previously published documents (p = 34, n = 136, 952), with an overall accuracy of 86%. The pooled estimates of classification accuracy differed significantly from model to model based on applying the algorithm to T2DM (p < 0.01). Predictive models with screening and diagnostics had the most significant overall classification accuracy (pooled proportion = 0.91) compared to models with other algorithms for T2DM (proportion = 0.84 to 0.88). In summary, our results on the aggregate estimates of model performance can help researchers and decision-makers undertake health technology assessments for various T2DM screening strategies. Hopefully, this analysis will benefit researchers involved in DM therapy‚Äôs detection, diagnosis, self-management, and personalization. Additionally, the findings can provide an exhaustive overview of the relative performance of diverse variants of ML models for disease prediction. The implication is that it can aid researchers in selecting appropriate ML models for their studies. Finally, we recommend comparing different ML models to develop a predictive model based on our meta-analysis."
2022,Development of Various Diabetes Prediction Models Using Machine Learning Techniques,"Background There are many models for predicting diabetes mellitus (DM), but their clinical implication remains vague. Therefore, we aimed to create various DM prediction models using easily accessible health screening test parameters. Methods Two sets of variables were used to develop eight DM prediction models. One set comprised 62 easily accessible examination results of commonly used variables from a tertiary university hospital. The second set comprised 27 of the 62 variables included in the national routine health checkups. Gradient boosting and random forest algorithms were used to develop the models. Internal validation was performed using the stratified 10-fold cross-validation method. Results The area under the receiver operating characteristic curve (ROC-AUC) for the 62-variable DM model making 12-month predictions for subjects without diabetes was the largest (0.928) among those of the eight DM prediction models. The ROC-AUC dropped by more than 0.04 when training with the simplified 27-variable set but still showed fairly good performance with ROC-AUCs between 0.842 and 0.880. The accuracy was up to 11.5% higher (from 0.807 to 0.714) when fasting glucose was included. Conclusion We created easily applicable diabetes prediction models that deliver good performance using parameters commonly assessed during tertiary university hospital and national routine health checkups. We plan to perform prospective external validation, hoping that the developed DM prediction models will be widely used in clinical practice.","In this study, we developed 1- and 2-year diabetes prediction models using electronic medical records from general health checkups at Seoul St. Mary‚Äôs Hospital. All models showed good performance with AUCs of approximately 0.9. Silva et al. [17] suggested an AUC of 0.812 for machine learning prediction models in their systematic review and meta-analysis. In comparison, the results of this study are satisfactory. There are several possible reasons for the outstanding performance of our predictive models despite using a relatively small sample size. We used diverse variables including self-reported information, physical examinations, and laboratory tests. A previous study with only the information from a questionnaire showed an AUC of 0.766 despite using a larger sample size of 18,301 subjects [18]. Our models with 62 variables included pulmonary function test results. It was suggested that some of them were independent risk factors for developing diabetes, where forced vital capacity and forced expiratory volume in one-second correlated significantly with the incidence of diabetes [19]. However, to the best of our knowledge, this is the first study to present a machine learning diabetes predictive model, particularly using pulmonary function test results. Unfortunately, some meaningful variables, such as high-sensitivity C-reactive protein and adiponectin, were not included because we obtained less than 20,000 measurements/data points for these. Other meaningful variables, such as stress, occupation, and education, were not included as they were not routinely checked or recorded [20]. We also did not include information from imaging studies as they cannot be automatically entered into the computed dataset because standardized description, definite categorization, and data processing were not yet established. We included fasting glucose and HbA1c levels in our model. We decided to include them because of their clinical importance. The importance of the two parameters was well proven by evaluating the performance of the 2-year prediction model with and without these variables. Our results are consistent with those of a Japanese study in which the AUC increased from 0.717 to 0.893 and from 0.734 to 0.882 by adding fasting glucose and HbA1c levels, respectively [21]. Other studies also showed similar degrees of improvement when fasting glucose and HbA1c levels were included [22-27]. The prediction time was limited to 1 or 2 years. A previous study developed a prediction model with a lower AUC of 0.820 after analyzing 93 parameters of 3,363 individuals; however, they made an eight-year prediction [20]. Generally, a longer prediction time is known to be more difficult. The performances of the 1-year prediction were well maintained with a similarly small sample size when extended to the 2-year prediction in our study. Our 2-year prediction model had a performance accuracy of over 80% when fasting blood glucose levels exceeded a certain threshold. Furthermore, the diabetic and non-diabetic groups had distinct distributions according to fasting blood glucose levels (Supplementary Fig. 2). In this context, our models could have an even better performance in predicting diabetes over a longer period such as 5 years. One of the study strengths was data management [28,29]. We decided to perform simple median imputation and hyperparameter tuning because little had changed in the performance with the exponential smoothing model, last observation carried forward method, Holt-Winters method, and more. The study population was limited to those who underwent general checkups in one center, sharing common characteristics such as homogeneous Korean ethnicity and similar socioeconomic statuses. Diabetes pathophysiology differs between ethnic groups and socioeconomic environments. For instance, the Framingham Diabetes Risk Scoring model [30], a well-known diabetes predictor based on a middle-aged United States population with an AUC of 0.850, showed different performance when applied to a Canadian population, with an AUC of 0.78 [31]. Our goal was to reduce the economic burden on society by preventing diabetes rather than treating it. We developed models that deliver outstanding performance using 62 easily obtainable and commonly measured variables. Simplified models with 27 variables present in the national health checkups were inferior to our models with 62 variables, but their performance parameters were still similar or better than those in previous reports. As the Korean National Health Insurance Service (NHIS) provides for medical checkups every 2 years for all Koreans [15], our models could be readily applied to anyone who underwent the simple free national checkups. Individuals could recognize their risk of developing diabetes in the near future, within 1 or 2 years in this study, and individualized medical advice could be applied to prevent diabetes. Facing the specified risk could motivate people at risk to take action and emphasize a healthy lifestyle, especially for those at high-risk of diabetes. Physicians could encourage strong intervention and short-term follow-up, and politicians could devise strategies for a stratified approach to slow down the progress of DM (a society program). In this study, the model with the two most powerful variables, fasting blood glucose and HbA1c, outperformed the model with 27 variables included in NHIS checkups. Rhee et al. [32] developed a diabetes prediction model using the NHIS cohort of Korea, which outperformed the conventional model. If they can add HbA1c to their model, they might achieve outstanding performance. Therefore, we could ask the national health policymakers to add HbA1c in the routine examination for nationwide general checkups after making cost-effectiveness calculations. This will help prevent high-risk individuals from proceeding to develop diabetes as well as find undiagnosed diabetic patients, so that they can be treated. It should be worthwhile because the model with only fasting plasma glucose and HbA1c outperformed the model with the 27 national general checkup variables. We hope to determine the effectiveness of detection, followed by intervention. Fasting glucose level is important in both the diagnosis and prediction of diabetes. Kim et al. [33] suggested that higher fasting glucose levels, even within the normal range, lead to a risk of diabetes. We expect to predict the risk of diabetes in populations with normal fasting glucose levels in another study. This study has some limitations. Our dataset was obtained from a tertiary institution. Typically, patients with more serious and multiple diseases tend to visit higher level hospitals. However, this tendency is not expected to be too high as the data were from a screening service for diseases as general checkups and not an examination of patients, and we included a large number of examinees, especially those who underwent at least two examinations approximately 2 years apart. The examinees visited according to their own desire to be screened. They were not selected by searching for the international classification of disease codes. The model was validated internally and not externally. As we have no information except that of 62 variables, we cannot confirm that our study subjects are representative of the general population. Therefore, it would need to be validated before being applied to other situations. Typically, machine learning prediction models require validation when conditions change. It is preferable to create a specific prediction model for each location and regularly check its performance. Non-diabetic groups were randomly selected from those who met our conditions. We neither focused on the characteristics of each group nor used matching techniques to specify the weights of importance of specific variables. Instead, we put all variables together, including age and sex, and evaluated the effects of all these as real-world data. In conclusion, we developed a high-performance model to predict diabetes within 1 and 2 years. We expect the risk predictions suggested by the model to help health providers and clinicians provide more specific advice and encourage the examinees to lead a healthy lifestyle. We hope that this study will become a foundation for further clinical trials to elucidate the application of diabetes risk calculators, early interventions, and their diabetes prevention effects."
2022,Diabetes mellitus risk prediction in the presence of class imbalance using flexible machine learning methods,"Background Early detection and prediction of type two diabetes mellitus incidence by baseline measurements could reduce associated complications in the future. The low incidence rate of diabetes in comparison with non-diabetes makes accurate prediction of minority diabetes class more challenging. Methods Deep neural network (DNN), extremely gradient boosting (XGBoost), and random forest (RF) performance is compared in predicting minority diabetes class in Tehran Lipid and Glucose Study (TLGS) cohort data. The impact of changing threshold, cost-sensitive learning, over and under-sampling strategies as solutions to class imbalance have been compared in improving algorithms performance. Results DNN with the highest accuracy in predicting diabetes, 54.8%, outperformed XGBoost and RF in terms of AUROC, g-mean, and f1-measure in original imbalanced data. Changing threshold based on the maximum of f1-measure improved performance in g-mean, and f1-measure in three algorithms. Repeated edited nearest neighbors (RENN) under-sampling in DNN and cost-sensitive learning in tree-based algorithms were the best solutions to tackle the imbalance issue. RENN increased ROC and Precision-Recall AUCs, g-mean and f1-measure from 0.857, 0.603, 0.713, 0.575 to 0.862, 0.608, 0.773, 0.583, respectively in DNN. Weighing improved g-mean and f1-measure from 0.667, 0.554 to 0.776, 0.588 in XGBoost, and from 0.659, 0.543 to 0.775, 0.566 in RF, respectively. Also, ROC and Precision-Recall AUCs in RF increased from 0.840, 0.578 to 0.846, 0.591, respectively. Conclusion G-mean experienced the most increase by all imbalance solutions. Weighing and changing threshold as efficient strategies, in comparison with resampling methods are faster solutions to handle class imbalance. Among sampling strategies, under-sampling methods had better performance than others.","We studied three powerful machine learning algorithms to predict diabetes incidence in the future based on some demographic, biochemical, and anthropometric measures. To tackle minority diabetes class imbalance, we used three strategies. Changing threshold as a simple strategy, cost-sensitive learning and sampling which involve more searching to fit optimal algorithm, are applied. We evaluated the performance of algorithms before and after providing a solution to the imbalance issue by examining various metrics. Each metric focuses on a special aspect of performance. Except ROC and P-R AUCs, all metrics are constructed based on confusion matrix. Accuracy is consistently decreased after applying imbalance solutions, while g-mean as unbiased metric in imbalanced data [29] is raised substantially. Other metrics had variable behavior. Our results show that changing threshold based on value that maximizes f1-measure, improved f1-measure, g-mean, and MCC (except for random forest) in three investigated algorithms. In changing threshold approach, the algorithm is not refitted. As a consequence, training time is reduced in comparison with other strategies which imply new hyper-parameters. This effortless solution could have comparable results with other solutions [34]. Our study also demonstrates its efficiency. Although, ROC and P-R AUCs remain constant, for a powerful trained algorithm changing threshold could be a first solution to enhance overall performance and to increase prediction accuracy in minority diabetes class. For tree-based algorithms, XGBoost and random forest, cost-sensitive learning was the best approach based on f1-measure and g-mean. Besides, it had good results in DNN. In comparison with sampling strategies, weighing only has one hyper-parameter which should be tuned. As a result, the complexity of the training procedure and run-time are lower than sampling methods. By increasing the weight of minority diabetes class, sensitivity is consistently increased but on the other hand, specificity is decreased [39, 40]. Usually, to address the imbalance problem, sampling strategies are applied [41‚Äì43]. We studied five sampling methods. Among sampling strategies, one of the under-sampling methods outperformed over-sampling and hybrid procedures based on f1-measure and g-mean in all algorithms. Although in comparison with original data, sampling resulted in better performance, they were not the best solution to solve imbalance distribution between diabetic and healthy classes. Only for DNN, sampling method outperformed other approaches. Sampling strategies have multiple hyper-parameters that should be tuned precisely. Overall, in original imbalanced data, DNN had highest accuracy for minority diabetes class and outperformed other classifiers based on mean of metrics. After giving solution to class imbalance, in terms of AUROC and AUPRC, under-sampled DNN and weighted XGBoost were better performers, respectively, among combination of algorithms and solving imbalance problem approaches. One of the applied advantages of XGBoost is its ability to model data with missing values which is a common case in medical data [27]. In addition, it is trained very fast and as a powerful algorithm, it has attracted attention in modeling challenging data [44, 45]. One limitation of our work is the low number of investigated sampling methods. SMOTE oversampling is frequently applied to handle class imbalance [12], but in our study, it was not the best performer. A possible explanation for this could be the high overlap between two classes in our data. Applying SMOTE could result in more ambiguous borderline between diabetes and non-diabetes classes. To explore the efficiency of sampling strategies, we will study a larger number of methods in the future with other datasets."
2022,Nonalcoholic fatty liver disease and early prediction of gestational diabetes mellitus using machine learning methods,"Background/Aims To develop an early prediction model for gestational diabetes mellitus (GDM) using machine learning and to evaluate whether the inclusion of nonalcoholic fatty liver disease (NAFLD)-associated variables increases the performance of model. Methods This prospective cohort study evaluated pregnant women for NAFLD using ultrasound at 10‚Äì14 weeks and screened them for GDM at 24‚Äì28 weeks of gestation. The clinical variables before 14 weeks were used to develop prediction models for GDM (setting 1, conventional risk factors; setting 2, addition of new risk factors in recent guidelines; setting 3, addition of routine clinical variables; setting 4, addition of NALFD-associated variables, including the presence of NAFLD and laboratory results; and setting 5, top 11 variables identified from a stepwise variable selection method). The predictive models were constructed using machine learning methods, including logistic regression, random forest, support vector machine, and deep neural networks. Results Among 1,443 women, 86 (6.0%) were diagnosed with GDM. The highest performing prediction model among settings 1‚Äì4 was setting 4, which included both clinical and NAFLD-associated variables (area under the receiver operating characteristic curve [AUC] 0.563‚Äì0.697 in settings 1‚Äì3 vs. 0.740‚Äì0.781 in setting 4). Setting 5, with top 11 variables (which included NAFLD and hepatic steatosis index), showed similar predictive power to setting 4 (AUC 0.719‚Äì0.819 in setting 5, P=not significant between settings 4 and 5). Conclusions We developed an early prediction model for GDM using machine learning. The inclusion of NAFLD-associated variables significantly improved the performance of GDM prediction. (ClinicalTrials.gov Identifier: NCT02276144)","This study demonstrated that the addition of NAFLD-associated variables significantly improved the prediction model performance for GDM in early pregnancy. In addition, the model with selected important variables [Setting 5] showed similar predictive power as the model derived from all clinical variables, including NAFLD-associated variables [Setting 4]. Overall, we suggest a final model with 11 important variables [Setting 5]. The model showed the highest predictive power for the AUC among the five settings. The predictive performance of the final model was much higher than that of settings 1‚Äì3 with a small number of variables. Setting 5 also showed similar predictive performance as setting 4, which used all available clinical variables and NAFLD-associated variables. We confirmed that these trends were not data-split-dependent results through statistical analysis. Based on the ultimate goal of developing a parsimonious model with high predictive power, we suggest a prediction model in setting 5 as the final model. NAFLD is strongly associated with the development of type 2 diabetes, hypertension, metabolic syndrome, and other cardiovascular complications [12-14,34]. Several recent studies have reported that NAFLD is also a risk factor for GDM, which is consistent with the observation that pregnancy can unmask subclinical metabolic disorders in patients at risk of metabolic diseases later in life [15,16,35,36]. The molecular mechanisms underlying the relationship between NAFLD and metabolic complications in later life appear to be related to hepatic insulin resistance and lipotoxicity in the setting of excessive free fatty acids, hepatokines, or cytokines, and peripheral adiposity, which leads to oxidative stress, activation of proinflammatory cytokines, and fibrosis [16,37-39]. In previous studies, NAFLD identified in early pregnancy was shown to increase the risk of GDM, with the odds ratios ranging from 2.2 to 6.5 [40]. Moreover, several biomarkers related to NAFLD, such as ALT, triglycerides (TG), and gamma-glutamyl transferase, have been independently reported as risk factors for GDM [19,41,42]. However, whether we should evaluate NAFLD-associated factors in early pregnancy for GDM prediction has not been evaluated to date. In this study, we showed that the addition of NAFLD-associated variables [Setting 4] significantly improved the prediction model performance for GDM by both traditional machine learning algorithms and DNN. In addition, NAFLD, HSI, TG, and ALT in the first trimester were identified among the top 11 important selected variables for GDM prediction [Setting 5]. Several recent studies have used machine learning algorithms to develop prediction models for GDM, although most of the included clinical variables were retrieved in the second trimester. Ye et al. [19] failed to show better performance of machine learning algorithms for GDM prediction compared to traditional LR analysis, although other studies have reported improved performance. For example, Xiong et al. [20] reported higher accuracy with gradient boosting and SVM with clinical variables up to 19 weeks; however, they used a case-control study design, which did not accurately represent the real-world context in which we see GDM. Artzi et al. [21] used real-world data from retrospective electronic health records retrieved up to 20 weeks of gestation and developed a prediction model for GDM with a gradient boosting model, with variable success. Theoretically, machine learning should improve the performance of predictive models due to its ability to learn from non-linear and complex relationships among risk factors in realworld datasets [43]. In addition, machine learning can also identify important variables that may not have been identified in other analyses. In the current study, we showed that the machine learning algorithm performed better than the conventional LR analysis, and identified important variables in the prediction model. Interventions such as lifestyle modification, weight gain optimization, and regular exercise starting early in pregnancy may prevent some cases of GDM [44-46]. As such, there is an increasing demand for early prediction of GDM. Both the ACOG and ADA have developed guidelines to identify high-risk women in early pregnancy [2-4]. However, predictive modeling using both original and revised criteria has poor accuracy in identifying women at risk, and there is a high demand for a more accurate model in early pregnancy [5]. In the current study, we developed a prediction model using clinical/demographic variables collected prior to 14 weeks, enabling accurate prediction of GDM in the first trimester. After acute prediction of GDM in early pregnancy, we can modify our screening strategies for GDM or intervention in high-risk women with lifestyle modification or regular exercise. To establish a prediction model that could be implemented more easily in routine clinical practice, we tried to limit the number of variables in this study [47]. The model with the 11 most important variables [Setting 5] showed similar or better performances than settings 1‚Äì4 (Supplementary Fig. 1), making this probably the most useful of the five models. However, whether the suggested model can be used in clinical practice requires further larger randomized studies. The strengths of this study are that it used data that were collected prospectively, and included data on both NAFLD and HSI. In the current study, NAFLD was defined by liver ultrasound and not by histologic examination, although sonographic evaluation of the fatty liver is subjective and may not be able to detect small amounts of fat accumulation [48]. However, histological confirmation of the liver was not possible in asymptomatic pregnant women. Instead, we evaluated HSI, a metric derived from laboratory results, which is a more objective marker of hepatic dysfunction than ultrasound alone [49]. One of the limitations of the current study is that all study subjects were of Korean ethnicity. Whether these findings can be generalized to other racial/ethnic groups is not clear. In addition, we enrolled pregnant women only when they denied a history of chronic liver disease and agreed to enroll in a prospective cohort study. Given that there could be differences between women who agreed to participate in the study and those who refused, there is a possibility of selection bias at enrollment. Moreover, we did not include a cost-effective analysis. For this prediction model, participants should undergo further examinations, such as liver ultrasound and laboratory tests, at 10‚Äì14 weeks in addition to routine laboratory tests in early pregnancy. Whether the suggested model with additional evaluation can be used in practice also requires a cost-effective analysis. In addition, we did not use an external validation dataset to evaluate the prediction model. However, the evaluation of liver ultrasound and sampling of fasting blood in early pregnancy has not been a routine practice in obstetrics, and we failed to find another pregnancy population dataset for external validation that had similar data regarding NAFLD as ours. Instead, 1) we split the study population into a development and test dataset before performing any analysis, and showed the performance of the final prediction model in a test dataset; and 2) we repeated this data split process 10 times to avoid split-dependent results, and showed that the predictive model with the top 11 variables had the highest predictive performance regardless of the data split. Nevertheless, the study population was based on a single cohort. Further studies with external datasets are needed to confirm the usefulness of the proposed prediction model. Lastly, we could not evaluate the influence of mild or significant fibrosis in the liver, although fibrosis itself might be more problematic in terms of metabolic outcomes. Moreover, fibrosis has been reported to be associated with adverse outcomes in non-pregnant patients with NAFLD [50]. In conclusion, we developed early prediction models for GDM using machine learning, which performed better than the models using only clinical/demographic variables recognized by the ACOG and ADA. The inclusion of NAFLD-associated variables significantly improved the performance of early GDM prediction. However, further evaluation in large prospective studies is needed before these models can be incorporated into routine practice."
2022,Population-centric risk prediction modeling for gestational diabetes mellitus: A machine learning approach,"Aims The heterogeneity in Gestational Diabetes Mellitus (GDM) risk factors among different populations impose challenges in developing a generic prediction model. This study evaluates the predictive ability of existing UK NICE guidelines for assessing GDM risk in Singaporean women, and used machine learning to develop a non-invasive predictive model. Methods Data from 909 pregnancies in Singapore‚Äôs most deeply phenotyped mother-offspring cohort study, Growing Up in Singapore Towards healthy Outcomes (GUSTO), was used for predictive modeling. We used a CatBoost gradient boosting algorithm, and the Shapley feature attribution framework for model building and interpretation of GDM risk attributes. Results UK NICE guidelines showed poor predictability in Singaporean women [AUC:0.60 (95% CI 0.51, 0.70)]. The non-invasive predictive model comprising of 4 non-invasive factors: mean arterial blood pressure in first trimester, age, ethnicity and previous history of GDM, greatly outperformed [AUC:0.82 (95% CI 0.71, 0.93)] the UK NICE guidelines. Conclusions The UK NICE guidelines may be insufficient to assess GDM risk in Asian women. Our non-invasive predictive model outperforms the current state-of-the-art machine learning models to predict GDM, is easily accessible and can be an effective approach to minimize the economic burden of universal testing & GDM associated healthcare in Asian populations.","Our findings using the UK NICE model established the need for an improved GDM predictor in an Asian population, such as in Singapore. We observed that the risk factors in UK NICE guidelines had poor GDM predictive ability for the Singapore population (AUC:0.60). The lowering of the obesity BMI thresholds applicable to Asian women did not significantly improve the UK NICE model. We subsequently developed a two-tier GDM prediction panel that significantly outperformed the UK NICE guidelines. The first-tier GDM prediction panel is non-invasive and requires no fasting (AUC:0.82). The 4 features used in the non-invasive model can be easily measured and assessed during first trimester (mean arterial blood pressure at booking appointment, maternal age, previous history of GDM and ethnicity). Elevated mean arterial blood pressure at booking can be an early pregnancy sign of vulnerability to the metabolic syndrome of which insulin resistance and impaired glucose metabolism are prominent components. The case-control study by Savvidou et al provides further support to our finding, where GDM women had higher systolic blood pressure in early pregnancy [21]. Hedderson et al reported similar findings, where high blood pressure in pregravid and early pregnancy states were associated with an increased risk of GDM [22]. As blood pressure is a vital sign measured routinely at antenatal visits, mean arterial blood pressure is an easy and inexpensive clinical characteristic which can be used for GDM screening. Despite the evidence that GDM risk increases with age [23], higher maternal age is not included as one of the risk factors in UK NICE screening guidelines. This is particularly important keeping in mind that insulin resistance increases with age. With increasing age at pregnancy becoming more common in developed and developing countries, higher maternal age is an important attribute to be considered in GDM assessment. Previous history of GDM serves as an early approach to GDM surveillance. The importance of GDM history is supported by substantial epidemiologic evidence. In a recent meta-analysis by Lee et al, women with a previous history of GDM had an 8.42-fold increased risk of developing GDM when compared with women without a previous history of GDM [24]. Studies on racial-ethnic differences in GDM risk have shown that Asians are a heterogeneous group by genetic background, culture, diet and other lifestyle factors [25]. The UK NICE guidelines classify Indian ethnic women to be at high risk for GDM in Singapore‚Äôs population. In our study, we have shown that Chinese women are also at similar risk for GDM. With these findings, ethnicity-tailored preventive local programmes can be developed to improve the health literacies of GDM in high risk Chinese/Indian communities. In our non-invasive GDM prediction panel, the addition of mean arterial blood pressure, maternal age, previous history of GDM and ethnicity resulted in a significant performance improvement (ŒîAUC=+0.26) when compared with the risk stratification model on previous GDM history. The 4 features in our non-invasive ‚ÄòNI4‚Äô model have demonstrated stronger GDM predictive ability than the UK NICE model, suggesting that further improvements can be made in current risk assessment guidelines for GDM. The machine learning algorithm (LightGBM gradient boosting classifier) trained by Artzi et al achieved an impressive AUC of 0.80 with 9 questionnaire features for GDM detection [13]. However, questionnaire features may introduce recall bias in predictive modelling (e.g. highest value of HbA1c% measured from previous pregnancy, results of OGTT from previous pregnancy). In another study by Wu et al [14], the machine learning algorithm (logistic regression classifier) achieved an AUC of 0.77 with 7 clinical features for early GDM prediction. The invasive model developed by Wu et al requires the measurement of fasting glucose, HbA1c and triglycerides. Our first-tier, non-invasive GDM prediction model has an improved performance (CatBoost model AUC:0.82) with 4 non-invasive features collected at first trimester, outperforming the current state-of-the-art machine learning models. The first-tier, non-invasive GDM prediction model can thus be an effective approach to screen and intervene early in women at risk, and also minimize the economic burden of universal testing and GDM associated healthcare in Asian populations. The second-tier panel is invasive and requires more advanced laboratory testing, which may not be routinely available in all standard clinical laboratories. Adiponectin contributed to a better performance improvement than IGF1. With adiponectin included, the predictive performance of the non-invasive panel can only be marginally enhanced [CatBoost ‚ÄòNI4_ADI‚Äô model AUC:0.84 (95% CI 0.75, 0.93)]. Lower adiponectin concentrations are associated with visceral adiposity, insulin resistance, atherosclerosis, and plays a critical role in metabolism [26]. Visceral fat accumulation is one possible pathophysiological mechanism in GDM development. Although pre-pregnancy obesity is the second most important feature in UK NICE model, pre-pregnancy obesity (BMI>=30 kg/m2) was of low global importance in CatBoost feature selection model (Fig. 2). As further evidenced by the stronger predictive ability of adiponectin, visceral fat accumulation (intra-abdominal fat) may be a better marker of adiposity in Asians. Increased dairy consumption in mid-gestation added minimal predictive value to second-tier panel [CatBoost ‚ÄòNI4_ADI_DI‚Äô model AUC:0.85 (95% CI 0.79, 0.92)]. Dairy consumption in GUSTO cohort study was derived from milk, yoghurt, cheese, milk-based malt drinks and cultured yoghurt drinks. Our dietary finding can be explained by general food consumption patterns during pregnancy, where dairy and dairy product consumption is greatest during mid-pregnancy. In the study by Tucker et al, high dairy intake was a strong predictor of insulin resistance in women without diabetes [27]. As mid-pregnancy is a critical window period for GDM development, dairy intake during pregnancy might be a modifiable GDM risk factor. With the two-tier GDM prediction panel, we have shown that model prediction can be slightly enhanced by incorporating features gathered during the course of gestation. We also have a well-defined validation framework in the study as the two-tier GDM prediction panel was compared against UK NICE guidelines. An added strength of the study is the utilization of SHAP framework to interpret machine learning model outputs and design a GDM prediction panel. This study has several limitations. Firstly, unlike large sample sizes in EHR databases, our prediction models were trained on a limited cohort of 909 pregnancies. However, EHR databases have inherent biases and are influenced by the individual‚Äôs interaction with local healthcare systems. With the prospective cohort study design, GUSTO data captures the dynamic nature of complex clinical pathways and is less prone to differential measurement errors. Secondly, the WHO 1999 GDM diagnostic criteria was in effect during two-point OGTT assessment in GUSTO study (fasting, 2-hour glucose measures). International Association of Diabetes Study Groups (IADPSG) 2018 has a less stringent criterion than WHO 1999, requiring just one abnormal glucose measure during a 2-hour 75g OGTT (fasting, 1-hour, 2-hour glucose measures). Tan et al reported that about one-third of GDM cases in KKH were diagnosed based on 1-hour glucose value [28]. The lack of 1-hour glucose measure for full three-point IADPSG 2018 criteria in GUSTO study may underestimate GDM prevalence and affect model training (AUC metric of 0.71 for modified two-point IADPSG 2018 criteria is still indicative of predictive power). As supervised machine learning models are limited by the quality of ground truth to learn underlying patterns in data, the WHO 1999 criteria was a better ground truth labeler for training GDM algorithms using GUSTO cohort data. Thirdly, there may be biases in the predictive value of dairy-intake in GDM risk assessment, as this measure was derived from 24-hour dietary recall. Single day intake of dietary measure is subject to recall bias and day-to-day variation. A more accurate assessment of long term dietary patterns is required in the future to build strength in the predictive value of this measure. There is also a limitation of sample size on population genomic analyses (with < 1000 samples in GUSTO study). However, key variants and iOmics analyses in GUSTO cohort have identified IGF locus and blood measures of IGF to be associated with GDM. We hence used direct measures of plasma IGF in the current analysis. Lastly, the GUSTO cohort does not contain information of preconception parameters. With preconception data, we can possibly predict the risk of GDM during pregnancy initiation and intervene with early-stage nutritional & lifestyle changes. The longitudinal research in Singapore‚Äôs PREconception study of Long-Term Maternal and Child Outcomes (S-PRESTO) birth cohort study [29], may become the basis for preconception-based GDM prediction panels to be built in the future. Our first-tier, non-invasive predictive model would enable earlier interventions for GDM prevention and institution of earlier screening. Our machine learning tool can also be offered to pregnant women who are unwilling to have glucose challenge test taken. The trained GDM classifier can be deployed using a web application, where clinicians can enter patient information and obtain GDM risk prediction. The AI prediction model needs to be validated further using data from external cohorts or electronic health records in Singapore/Asia before deploying in local healthcare systems. A robust clinical evaluation via a randomized controlled trial is required to investigate the associations of the AI prediction tool with maternal and fetal outcomes."
2022,Harnessing machine learning models for non-invasive pre-diabetes screening in children and adolescents,"Background and objectives Pre-diabetes has been identified as an intermediate diagnosis and a sign of a relatively high chance of developing diabetes in the future. Diabetes has become one of the most frequent chronic disorders in children and adolescents around the world; therefore, predicting the onset of pre-diabetes allows a person at risk to make efforts to avoid or restrict disease progression. This research aims to create and implement a cross-validated machine learning model that can predict pre-diabetes using non-invasive methods. Methods We have analysed the national representative dataset of children and adolescents (5‚Äì19 years) to develop a machine learning model for non-invasive pre-diabetes screening. Based on HbA1c levels the data (n = 26,567) was segregated into normal (n = 23,777) and pre-diabetes (n = 2790). We have considered eight features, six hyper-tuned machine learning models and different metrics for model evaluation. The final model was selected based on the area under the receiver operator curve (AUC), Cohen's kappa and cross-validation score. The selected model was integrated into the screening tool for automated pre-diabetes prediction. Results The XG boost classifier was the best model, including all eight features. The 10-fold cross-validation score was highest for the XG boost model (90.13%) and least for the support vector machine (61.17%). The AUC was highest for RF (0.970), followed by GB (0.968), XGB (0.959), ETC (0.918), DT (0.908), and SVM (0.574) models. The XGB model was used to develop the screening tool. Conclusion We have developed and deployed a machine learning model for automated real-time pre-diabetes screening. The screening tool can be used over computers and can be transformed into software for easy usage. The detection of pre-diabetes in the pediatric age may help avoid its enhancement. Machine learning can also show great competence in determining important features in pre-diabetes.","Diabetes is a major lifestyle disease requiring a population-based screening and treatment approach. The present study proposed a machine learning model for pre-diabetes screening for children and adolescents (5‚Äì19 years) in India. We have used a novel method for predicting pre-diabetes which can be applied in community settings. Initial screening for pre-diabetes without consideration of any biomarkers with 90.13% 10-fold cross-validation accuracy (XGB model) implies public health benefits. It can prevent the development of diabetes on a large scale. India is the second most populated country, with 9.2% of children and 9.5% of adolescents suffering from pre-diabetes [19]; therefore, it might not be economically feasible to set up labs for non-invasive screening in communities. But existing PHCs (public health centres) & AWCs (anganwadi centres) can be trained for somatometric measurements for occasional pre-diabetes screening through a non-invasive ML tool. Diabetes is a multifactorial disorder, but determining the top contributing features may assist us in focusing initially on important features. TSFT, MUAC, WC, age and height were the top five features determining the model accuracy in our four models. A study among children (8 years) in India has calculated the sum of skinfolds to represent the combined result of different skinfold thickness measurements, showing an evolving risk of diabetes with greater skinfold measurements [27]. Further, a study among type 1 diabetes children in India reported inconsistent growth patterns [28]. The prevalence of diabetes increases among adolescents and young adults (21), depending on various lifestyle changes with age [29]. In the diabetes prediction studies using AI, ML and DL techniques, the deployment and external validation of the dataset were missing in most of the studies [30,31]. Although, a study developed a smart web application based on the SVM model [32]. We also deployed the best model through the web portal to provide an applicative benefit in real-time screening. Predicting pre-diabetes in early life stages can be an insightful approach for diabetes prevention and lifestyle modification. In the last decade, AI has shown promising results in transforming the healthcare sector. Various aspects of diabetes can be predicted using AI & ML models [33]. Real-time screening tools for diabetes complications and data mining from repositories can facilitate the early detection of disease and smoothen the treatments. An approach for pre-diabetes screening using the support vector machine has achieved an accuracy of 64.9% on internal validation and 66.1% on external validation [34]. Another study based on the k-means clustering algorithm has classified diabetes, pre-diabetes and controls [35]. A study conducted in rural India (n = 5655) based on nutritional intake and demographic cohort dataset for pre-diabetes prediction implemented the generalised linear mixed model and achieved the AUC of 72% with eight features [36]. Our study achieved the comparatively highest model evaluation score due to the consideration of associated risk factors such as features, large data size and hyperparameter tuning of ML models. However, due to the lack of studies classifying pre-diabetes using AI & ML methods, it becomes difficult to assess the feasibility of AI & ML in pre-diabetes prediction worldwide. The complication of diabetes has been studied widely, using multiple ML algorithms [30] based on cohort or follow-up data sets, which were analysed in the context of diabetes prediction in the near future. Several ML modellings were done over Pima Indian Diabetes Dataset (PIDD) to classify diabetes. The PIDD consists of eight features, and ML models have shown reliable accuracy in classifying outcomes [37,38]. The highest accuracy using PIDD was 98% achieved using deep learning architecture [39]. Our study has obtained the highest AUC with the XGB model. In another study, the XGB model-based study has shown 80.2% accuracy in diabetes prediction [40]. A modelling study combining different features has reported the highest AUC of 0.86 for the GB model using non-invasive parameters [41]. A comparative study of four ML models on a diabetes dataset (n = 13,309), including biomarkers, has shown GB model AUC (83.9%) was slightly higher than the RF model (83%). Random forest modelling on a Chinese dataset with 11 non-biomarker features obtained 71% accuracy [42]. In another study, the RF classifier, combined with SVM-SMOTE and the least absolute shrinkage and selection operator (LASSO) feature reduction approach, produced the highest accuracy in classifying people at high risk of diabetes from healthy controls [43]. The least accuracy and AUC in the present study were obtained with the SVM model (57.33%). The support vector machine algorithm aims to determine the optimal highest-margin separation hyperplane between two classes given a two-class training sample [44]. Studies based on the support vector machine algorithm (SVM) have obtained 99.2% and 65.6% in Columbian and other patients, respectively [45]. Another SVM study mentioning diagnosed diabetes vs pre-diabetes or no diabetes showed an AUC of 83.5% [46]. A study also used a heart rate variability signal from ECG to predict diabetes via classifying diabetes and normal signals using deep learning and SVM as classification algorithms [47]. However, the evaluation metrics of different ML models may vary according to the datasets, feature selection techniques, software/programming language used and parameters applied during the model training. The hyperparameter tuning should be considered during model training because it may significantly impact model performance [48]. The present study provides a novel idea for pre-diabetes screening which can be implemented in any part of the world with an algorithm developed from a representable dataset. Further, we have performed all the necessary steps required to reduce the biasness in the dataset. The key strength of our work was the data pre-processing and automated feature selection based on hyperparameter tuning for achieving the best classification accuracy and model deployment for real-time applications. The limitation of the present work includes data balancing (augmentation), which was representative data but not raw data. Data augmentation was done to remove the representation biasness from both the groups (normal and pre-diabetes). We have also not performed any external validation of the model, which may differ from the given cross-validation accuracy. However, considering this as a prototype, we can increase the number of non-invasive features based on external validation results."
2023,Prediction of diabetes disease using an ensemble of machine learning multi-classifier models,"Background and objective Diabetes is a life-threatening chronic disease with a growing global prevalence, necessitating early diagnosis and treatment to prevent severe complications. Machine learning has emerged as a promising approach for diabetes diagnosis, but challenges such as limited labeled data, frequent missing values, and dataset imbalance hinder the development of accurate prediction models. Therefore, a novel framework is required to address these challenges and improve performance. Methods In this study, we propose an innovative pipeline-based multi-classification framework to predict diabetes in three classes: diabetic, non-diabetic, and prediabetes, using the imbalanced Iraqi Patient Dataset of Diabetes. Our framework incorporates various pre-processing techniques, including duplicate sample removal, attribute conversion, missing value imputation, data normalization and standardization, feature selection, and k-fold cross-validation. Furthermore, we implement multiple machine learning models, such as k-NN, SVM, DT, RF, AdaBoost, and GNB, and introduce a weighted ensemble approach based on the Area Under the Receiver Operating Characteristic Curve (AUC) to address dataset imbalance. Performance optimization is achieved through grid search and Bayesian optimization for hyper-parameter tuning. Results Our proposed model outperforms other machine learning models, including k-NN, SVM, DT, RF, AdaBoost, and GNB, in predicting diabetes. The model achieves high average accuracy, precision, recall, F1-score, and AUC values of 0.9887, 0.9861, 0.9792, 0.9851, and 0.999, respectively. Conclusion Our pipeline-based multi-classification framework demonstrates promising results in accurately predicting diabetes using an imbalanced dataset of Iraqi diabetic patients. The proposed framework addresses the challenges associated with limited labeled data, missing values, and dataset imbalance, leading to improved prediction performance. This study highlights the potential of machine learning techniques in diabetes diagnosis and management, and the proposed framework can serve as a valuable tool for accurate prediction and improved patient care. Further research can build upon our work to refine and optimize the framework and explore its applicability in diverse datasets and populations.","Diabetes is a chronic condition that significantly impacts individuals' quality of life, underscoring the critical need for accurate prediction methods in its management and prevention. In our study, we delve into the analysis and interpretation of results obtained from our ensemble machine learning models, which were designed to predict diabetes using the IPDD dataset. We also explore the implications of our findings, discuss the limitations of our study, and provide recommendations for future research. The primary contribution of this research lies in introducing a introduces, pipeline-based framework of multi-class machine learning models for diabetes prediction. The framework utilizes the IPDD dataset, which encompasses three distinct groups: diabetic subjects (Y), non-diabetic subjects (N), and predicted diabetic subjects (P). The innovative nature of this framework lies in its ability to effectively classify individuals into these categories, thereby enhancing our understanding of diabetes prediction. This approach addresses the multi-class classification problem and ensures a comprehensive evaluation of performance by employing various evaluation metrics to assess the effectiveness of our proposed models. Data pre-processing plays a vital role in enhancing the accuracy and efficiency of predictive models. In our proposed model, we utilized several pre-processing techniques, such as filling missing values, standardization, normalization, feature selection, and dimensionality reduction. These techniques were implemented to meticulously prepare the data, improve model performance, and mitigate the impact of incomplete or inconsistent data. The results of our study emphasize the significance of data pre-processing in achieving accurate predictions for diabetes. By leveraging the collective intelligence of multiple individual classifiers, our ensemble approach demonstrates its effectiveness through improved overall performance and accuracy in diabetes prediction. This approach addresses biases and errors inherent in individual classifiers, which is particularly important given the challenges posed by imbalanced data and missing attribute values in diabetes prediction. Our experiments consistently showed that the random forest model, in combination with the MRMR and I‚Äâ+‚ÄâN stages of data pre-processing, outperformed other models. This highlights the importance of feature selection and dimensionality reduction techniques in enhancing diabetes prediction accuracy. The utilization of MRMR feature selection and PCA/ICA dimensionality reduction methods enables the identification of key features that significantly impact class determination. Furthermore, combining K-NN, AB, DT, and RF models with 11 features and I pre-processing exhibited superior performance in predicting diabetes in the IPDD dataset. This underscores the significance of employing a diverse set of machine learning models in an ensemble approach to enhance prediction accuracy. By harnessing the strengths of these models, we achieve more robust and reliable predictions. It is important to note that the evaluation of our models was not solely based on accuracy due to the imbalanced nature of the dataset. Instead, we employed multiple evaluation measures, including the Area Under the ROC Curve (AUC), to provide a comprehensive assessment of model performance. AUC is particularly suitable for imbalanced datasets as it considers the trade-off between true positive rate and false positive rate, offering a more accurate representation of the model's predictive power. Despite yielding promising results, our study has certain limitations. Firstly, the IPDD dataset used in our research may possess inherent biases and limitations that could affect the generalizability of our findings to other populations. Future studies should consider incorporating datasets from diverse patient populations to validate the effectiveness of our proposed models. Secondly, while we employed various data pre-processing techniques, there may be alternative approaches that could further optimize the performance of our models. Exploring alternative pre-processing techniques and comparing their efficacy could be a valuable avenue for future research. Ensemble models have their limitations, including increased model complexity, longer training and testing times, and the requirement of comprehensive data for model construction and configuration. Additionally, the interpretation of results from these models can be challenging due to their complexity across different datasets, potentially leading to inconclusive outcomes. Therefore, prior to utilizing these models, a meticulous examination and in-depth analysis of their features, data size, and other aspects are imperative. In conclusion, our research demonstrates the potential of ensemble machine learning models, along with comprehensive data pre-processing techniques, in accurately predicting diabetes using the IPDD dataset. The results highlight the importance of feature selection and dimensionality reduction in improving prediction accuracy. Our proposed models offer a promising approach to diabetes prediction by addressing challenges posed by imbalanced data and missing attribute values. The findings of this study contribute to the field of diabetes diagnosis and treatment, providing valuable insights for researchers and practitioners. Our future research will focus on validating our models with larger and more diverse datasets, investigating additional preprocessing techniques to enhance the performance of diabetes prediction models, as well as exploring novel methods for early detection of COVID-19 disease and applications in mobile computing and manufacturing for comprehensive early disease diagnosis."
2023,Comparison of machine learning and conventional logistic regression-based prediction models for gestational diabetes in an ethnically diverse population; the Monash GDM Machine learning model,"Background Early identification of pregnant women at high risk of developing gestational diabetes (GDM) is desirable as effective lifestyle interventions are available to prevent GDM and to reduce associated adverse outcomes. Personalised probability of developing GDM during pregnancy can be determined using a risk prediction model. These models extend from traditional statistics to machine learning methods; however, accuracy remains sub-optimal. Objective We aimed to compare multiple machine learning algorithms to develop GDM risk prediction models, then to determine the optimal model for predicting GDM. Methods A supervised machine learning predictive analysis was performed on data from routine antenatal care at a large health service network from January 2016 to June 2021. Predictor set 1 were sourced from the existing, internationally validated Monash GDM model: GDM history, body mass index, ethnicity, age, family history of diabetes, and past poor obstetric history. New models with different predictors were developed, considering statistical principles with inclusion of more robust continuous and derivative variables. A randomly selected 80% dataset was used for model development, with 20% for validation. Performance measures, including calibration and discrimination metrics, were assessed. Decision curve analysis was performed. Results Upon internal validation, the machine learning and logistic regression model‚Äôs area under the curve (AUC) ranged from 71% to 93% across the different algorithms, with the best being the CatBoost Classifier (CBC). Based on the default cut-off point of 0.32, the performance of CBC on predictor set 4 was: Accuracy (85%), Precision (90%), Recall (78%), F1-score (84%), Sensitivity (81%), Specificity (90%), positive predictive value (92%), negative predictive value (78%), and Brier Score (0.39). Conclusions In this study, machine learning approaches achieved the best predictive performance over traditional statistical methods, increasing from 75 to 93%. The CatBoost classifier method achieved the best with the model including continuous variables.","We explored multiple ML-based techniques across a range of predictor sets (48 models) and compared their predictive performance to classical regression models, using a large dataset of routinely collected data from an ethnically diverse population. Building on validated traditional statistical models, we have demonstrated that overall, ML techniques achieved the best predictive performance. Applying these ML techniques across various predictor sets, informed by feature importance analysis, the best predictive performance was achieved by ML boosting algorithms (CBC and XGB). ML-based prediction approaches for GDM are frequently published, but they often suffer from methodological limitations that compromise their quality and reliability. Some of these are developed using a small sample size, contrary to the requirements of ML techniques. In addition, there are issues with inappropriate inclusion and exclusion criteria, a lack of discrimination and calibration assessment reports, and most importantly, a failure to evaluate the clinical utility of the resultant prediction models [17], [43]. Considering the limitation of available ML based GDM prediction models, here the best prediction technique was determined and its performance is assessed comprehensively utilizing multiple ML techniques, across various combinations of predictors selected by available evidence, clinical judgment, and ML-based feature importance analysis. The net benefit of the optimal model was also assessed by decision curve analysis across various probability thresholds. To our knowledge, this approach of comparing multiple models including ML derived models in this way is novel. Here, we have shown that boosting algorithms, tree-based algorithms, and neural network classification-based ML techniques led to better discrimination performance in predicting GDM. Boosting ML techniques led to the best accuracy. Other ensemble techniques also led to good predictive abilities, due to the capability to learn from complex and non-linear associations of predictors in a real-world dataset [44]. The predictive performance of GNB ML techniques was the poorest. This could be attributed to its strong assumption of predictor independence, which is often challenging to meet with real-world data [45]. The transportability of the developed optimal techniques and model now needs to be assessed in different geographical populations. In terms of predictor sets, although categorizing continuous variables are common in clinical practice, this practice is not recommended statistically, due to the limitation on predictive power [42], [46]. However, the added predictive value of using continuous variables has not been commonly assessed for GDM prediction. Building on the original Monash GDM Model (with categorical variables; predictor set 1), predictor set 2 included BMI and age as continuous variables, improving the predictive performance of almost all generated models. Feature importance and correlation analyses, identified parity and was added into predictor set 3, which further improved predictive performance. Although using BMI as a derived variable in predictive models can offer simplicity, normalization, and some clinical relevance, it can also result in loss of information, lack of accuracy, and bias [47], [48]. Feature importance and correlation analyses, identified both height and weight as important predictors. Additionally, instead of BMI both weight and height were also identified as important predictors; therefore, a fourth predictor set was developed by including height and weight as predictors instead of BMI, which has also been done in other GDM prediction model studies [49], [50], [51], [52]. Utilizing these source derivative variables as continuous variables, further improved prediction model performance. Of four developed predictor sets, the fourth was identified as the optimal set with dramatic enhancement in predictive performances. Decision curve analysis showed the optimal model identified a threshold probability over which the prediction models are recommended. For transportability purpose, it is vital to test the applicability of the developed optimal models in different healthcare setup by other researchers. After external validation, it can help to stratify high risk women allowing for early intervention deterring possible obstetric complications. By identifying women at high risk of developing GDM, healthcare resources can also be targeted to those who are most likely to benefit from early intervention. With additional external validation, the Monash GDM ML Model will be incorporated into our online risk prediction tools for future use."
2023,Discovery of senolytics using machine learning,"Cellular senescence is a stress response involved in ageing and diverse disease processes including cancer, type-2 diabetes, osteoarthritis and viral infection. Despite growing interest in targeted elimination of senescent cells, only few senolytics are known due to the lack of well-characterised molecular targets. Here, we report the discovery of three senolytics using cost-effective machine learning algorithms trained solely on published data. We computationally screened various chemical libraries and validated the senolytic action of ginkgetin, periplocin and oleandrin in human cell lines under various modalities of senescence. The compounds have potency comparable to known senolytics, and we show that oleandrin has improved potency over its target as compared to best-in-class alternatives. Our approach led to several hundred-fold reduction in drug screening costs and demonstrates that artificial intelligence can take maximum advantage of small and heterogeneous drug screening data, paving the way for new open science approaches to early-stage drug discovery.","Current approaches to drug discovery suffer from notoriously high attrition rates in late-stage preclinical and clinical development. Due to their ability to parse and detect patterns in large volumes of data, AI has found applications across every stage of the drug discovery pipeline70. In this paper, we described a successful machine learning approach designed to identify novel drug candidates in early phases of the discovery process. We focused on targeted elimination of senescent cells, a phenotype that has attracted substantial interest for adjuvant cancer therapy2, but for which few molecular targets have been identified. Our strategy revealed three compounds (ginkgetin, oleandrin and periplocin) that selectively eliminate cells displaying oncogene- and therapy-induced senescence. We showed that these compounds have a potency comparable or higher to senolytics previously described in the literature and, crucially, our method led to large gains in efficiency by reducing the number of compounds for experimental screening by more than 200-fold. Our approach offers several innovations that depart from current practice in AI for drug discovery. First, it relies solely on published data for model training, and thus avoids the extra costs for in-house experimental characterisation of training compounds. Second, our machine learning models were trained on just 58 chemical structures with proven senolytic action, which is much smaller data than typically considered in the field; the small number of senolytics in the training data is a consequence of senolysis being a rare molecular property and the limited number of senolytics reported in the literature so far. The success of our approach demonstrates that machine learning can take maximum advantage of literature data, even when such data is heterogeneous and of much smaller scale than typically expected71. Third, our models were trained in a target-agnostic manner using phenotypic signatures of drug action. Target specificity is of key importance for drug efficacy and safety in later stages of the discovery pipeline, but there are numerous conditions of high economic and societal burden with few or no known targets53; for such conditions, there is an opportunity for phenotypic drug discovery to increase the number of chemical starting points that can be carried through the discovery pipeline52. A key challenge in computational drug screening is the construction of numerical representations of chemical structures that are predictive of drug efficacy72. With the advent of deep learning as the leading paradigm in the field73, many recent works have developed such representations with e.g. transformer models for prediction of chemical reactions74, graph neural networks to describe molecular structures39,47, morphology-based convolutional neural networks for activity prediction48 and generative models for de novo compound design75. In the ageing-related literature, previous studies have built pipelines to predict compounds that increase the life span of model organisms utilising chemical descriptors and gene ontology terms as features to train random forests49, feature selection pre-processing to train RF, SVM and neural networks51, and molecular fingerprints to train RF models50. In our approach, we found that classic physicochemical descriptors57 calculated from SMILES strings were sufficient to train useful models. We observed limited benefits in the use of deep learning for compound featurisation, possibly because of the small size of our training data. We found that careful data assembly, curation, and quality control were key for success. Since negative assays are rarely reported in the literature, we built the training data by pairing the known senolytics with a background of compounds assumed to lack senolytic action, but with an appropriate chemical diversity and a size deliberately chosen to reflect the paucity of senolytic compounds. These design choices produced a strong imbalance between the number of senolytic and non-senolytic compounds, which introduced additional challenges for model training. Several checks were needed to ensure that the training data was diverse enough and avoided bias toward specific chemical classes. Moreover, our models generally displayed poor performance as quantified by common classification metrics, producing large numbers of false positives and false negatives in cross-validation. We mitigated the impact of class imbalance by prioritising models with a lower number of false positives, and thus reduce the downstream costs for experimental validation. We carefully designed the screening library to balance similarity with the training data against exploration of novel chemical spaces (Fig. 2f). This led to an exceptionally selective distribution of prediction scores (Fig. 2d), which allowed us to select a cutoff for experimental validation with a reasonable number of hits and prediction scores far away from the bulk of the screening compounds. Although cutoff selection is highly problem-dependent, the robustness of results can be assessed with randomised repeats of model training and screening (Supplementary Fig. 10). Our results thus show that seemingly poor models can be employed effectively with adequate checks and balances on the structure of the data, plus a careful interpretation of misclassification errors. Importantly, our approach identified oleandrin, a cardiac glycoside with stronger potency than the benchmark senolytic cardiac glycoside ouabain. Oleandrin has improved senolytic performance over ouabain, functioning at a low nanomolar range, inhibiting its canonical target and activating its senolytic pathway with higher efficacy. Moreover, we saw that oleandrin does not affect the proliferative capacity and viability of normal cells at that nanomolar concentration, indicating promising senolytic potential. Our work thus demonstrates that artificial intelligence and machine learning can help discover new and better-performing active compounds for a given pharmacological group. Further validation on animal models may strengthen the evidence for oleandrin as a promising new senolytic. A caveat, however, is that cardiac glycosides that have been employed in heart conditions have severe limitations due to toxicity76, and our results suggest that oleandrin is not an exception because of its narrow therapeutic range and cardiotoxicity, and hence its use as systemic senolytic should be considered cautiously. The high potency of oleandrin could potentially benefit senolytic therapies administered locally on the site of damage; clinical trials are currently assessing such local administration of senolytics for osteoarthritis10,77. Moreover, in a separate work we have shown that ex-vivo senolytics perfusion of transplant discarded human livers preserves tissue architecture and its regenerative capacity during cold storage78. It is plausible that local oleandrin administration and perfusion in donor livers during the cold storage period before transplantation could overcome toxicity concerns from systemic administration and facilitate its use in the clinic. From a translational point of view, we highlight that the three senolytics identified in this study are natural products found in traditional herbal medicines: Ginkgo biloba (ginkgetin)79 Nerium oleander (oleandrin)76 and Periploca sepium (periplocin)80. Oleandrin and periplocin belong to the group of cardenolide glycosides, which are highly potent cardioactive agents, while ginkgetin is a biflavone with a broad pharmacological spectrum. Although they are not exempt of toxicological concerns, their already established ADME-Tox profiles in different models can help to reduce pharmacokinetics and tolerability issues during preclinical and clinical development. In principle, we do not rule out the senolytic potential of a low-toxicity compound like ginkgetin, but the exceptional activity and potency of oleandrin, together with its relatively low molecular weight (576.7‚Äâg/mol) and favourable cLogP (2.4), make it a promising lead candidate as compared to periplocin and ginkgetin (Supplementary Fig. 11). Oleandrin shares key structural features with other cardiac glycosides, including the presence of a sugar attached to the steroid core (at the C3Œ≤-OH group), a 2-furanone ring at C17Œ≤ and an OH group at the C14Œ≤ position of the steroid ring. Unlike most cardiac glycosides, oleandrin has an acetyloxy group attached at position C16Œ≤. In contrast to more structurally complex cardiac glycosides that display senolytic activity (e.g. ouabain, periplocin or lanatoside C), oleandrin features a monosaccharide and a simple central steroid system, which makes it closer to a potentially non-cardiotoxic pharmacophore and, consequently, an attractive starting point for future senolytic medicinal chemistry campaigns. Our approach led to a significant reduction in experimental screening costs, largely because all models were trained solely on published data and, unlike other recent successes in the field39, there was no need to screen compounds purposely for model training. The approach thus offers exciting prospects for new open science approaches to drug discovery. The COVID-19 pandemic spurred a multitude of such initiatives across the globe with the goal of finding new antivirals from the troves of published data81. Our work provides a concrete example of a simple yet effective machine learning pipeline that can be readily built from published screening data. We hope this approach will catalyse more open science approaches to discover treatments for conditions of unmet need, particularly those for which there is a limited grasp of the biological pathways involved in disease onset and progression."
2023,Precision subclassification of type 2 diabetes: a systematic review,"Background Heterogeneity in type 2 diabetes presentation and progression suggests that precision medicine interventions could improve clinical outcomes. We undertook a systematic review to determine whether strategies to subclassify type 2 diabetes were associated with high quality evidence, reproducible results and improved outcomes for patients. Methods We searched PubMed and Embase for publications that used ‚Äòsimple subclassification‚Äô approaches using simple categorisation of clinical characteristics, or ‚Äòcomplex subclassification‚Äô approaches which used machine learning or ‚Äòomics approaches in people with established type 2 diabetes. We excluded other diabetes subtypes and those predicting incident type 2 diabetes. We assessed quality, reproducibility and clinical relevance of extracted full-text articles and qualitatively synthesised a summary of subclassification approaches. Results Here we show data from 51 studies that demonstrate many simple stratification approaches, but none have been replicated and many are not associated with meaningful clinical outcomes. Complex stratification was reviewed in 62 studies and produced reproducible subtypes of type 2 diabetes that are associated with outcomes. Both approaches require a higher grade of evidence but support the premise that type 2 diabetes can be subclassified into clinically meaningful subtypes. Conclusion Critical next steps toward clinical implementation are to test whether subtypes exist in more diverse ancestries and whether tailoring interventions to subtypes will improve outcomes.","Summary of findings This systematic review analysed two broad approaches to the subclassification of type 2 diabetes to identify clinically meaningful subtypes that may advance precision diagnostics. We found many simple stratification approaches using, for example, clinical features such as BMI, age at diagnosis, and lipid levels, but none had been replicated and many lacked associations with clinical outcomes. Complex stratification models using ML approaches with and without genetic data showed reproducible subtypes of type 2 diabetes associated with outcomes. Both approaches require a higher grade of evidence but support the premise that type 2 diabetes can be subclassified into clinically meaningful subtypes. Simple approaches to subclassification included urine and blood biomarkers, anthropometric measures, clinical data such as age at diagnosis, surrogate beta-cell metrics derived from blood C-peptide or insulin along with other less diabetes-related biomarkers such as bilirubin levels or pulse wave velocity. Approaches to subclassification were diverse. Some studies dichotomised continuous variables based on clinical cut-points. Other studies used a composite exposure (two or more criteria each with cut-points) or analysed changes in continuous variables over time e.g. change in eGFR over time. The study designs, specific cut-offs and outcomes were heterogenous, and no studies met high-quality GRADE certainty. No study evaluating a simple approach to type 2 diabetes subtyping has been adequately reproduced, although some studies identified biologically plausible subgroups. For example, subclassifications derived using BMI, beta-cell function, lipid profiles and age appeared to be associated with some outcomes which could be helpful in clinical practice. These potential subclassifications need to be replicated in better-designed studies (see section on additional supporting literature). Other evidence not included in our systematic review (either due to the study population including people without diabetes or the analysis was only performed in people with the exposure without a comparison group), support the role of simple variables in stratifying diabetes; for example, younger age at diagnosis is reproducibly associated with worse cardiorenal outcomes in a number of studies39. Machine learning approaches yielded some reproducible subtypes of type 2 diabetes using a variety of clinical and genetic variables. The best-replicated subtypes were the clusters first described by Ahlqvist et al.8, which were replicated in 22 studies, including ~88,000 individuals of diverse ancestry. There also was replication of genetic subtypes of type 2 diabetes from Udler et al.10 with associations with clinical features seen in multiple cohorts across almost 454,000 individuals36. However, the latter associations involved small absolute effects with unclear clinical utility for individual patient management, and studies were restricted to individuals of European ancestry. While there was replication of the clusters from Ahlqvist et al. across studies, the generated clusters appeared to be dependent on the characteristics of the underlying populations, especially factors such as distribution of ancestry, age, duration of diabetes, anthropometric trait variability as in BMI, and the variety of variable terms included in learning models. Nevertheless, at least some of the resulting subtypes appeared to be robust to differences in specific ML method, input variables, and populations (Fig. 3). Many of the input variables for the complex ML subtyping approaches were also used in studies involving simple approaches to subclassification, recapitulating the biological plausibility of specific clustering variables in defining type 2 diabetes subtypes. One study directly compared a simple clinical approach to the clustering approach from Ahlqvist et al.8 and found that simple single clinical measures analysed in a quantitative (rather than categorical) framework could better predict relevant clinical outcomes, such as incidence of chronic kidney disease and glycaemic response to medications40. Thus, further research is needed to determine whether assigning a patient to one of the clusters from Ahlqvist et al.8 offers additional clinical benefit beyond evaluation of simple clinical measures and also beyond current standard of care. For example, high quality randomised controlled trial evidence is needed to demonstrate that knowledge of a patient‚Äôs clinical or genetic cluster membership could meaningfully guide treatment and/or clinical care and improve outcomes. Study quality No studies included in our systematic review had above moderate certainty of evidence. Some strengths of included studies were the large sample sizes, the diversity of variables considered, and inclusion of both prevalent and new-onset cases of type 2 diabetes. However, the varied study designs and lack of replication limits our ability to draw firm conclusions about the most effective approaches to subclassification. Most variables used for subclassification capture momentary metabolic states, which limits their long-term utility as cluster assignment is likely to change over time41,42. Most studies were retrospective analyses of established cohorts, and there were, at the time of the search, no data available involving subtype-stratified clinical trials or real world implementation of approaches. Finally, most studies focused on European-ancestry populations, and the clinical value of these approaches may vary across different ancestries. While East Asian ancestries had representation in some studies, research in Black, South Asian and Hispanic populations remains sparse. This is particularly important, as four out of five people with type 2 diabetes come from marginalised groups or live in low- or middle-income countries. Future precision diagnostic interventions should address and narrow inequalities. Additional supporting literature Since our literature search was conducted, four new publications have advanced our understanding of type 2 diabetes subclassification. Two recent studies applied ML approaches to stratify diabetes heterogeneity, both considering continuous approaches rather than with discrete clusters43,44. Nair et al. used a non-linear transformation and visualisation of nine variables onto a tree-like structure44 and with replication in two large datasets. This approach linked underlying disease heterogeneity to risk of complications; those at risk of cardiovascular disease had a different phenotype to those with microvascular complications and to drug response and demonstrated associations of gradients across the tree using genetic process-specific scores from Udler et al.10 Wesolowska-Andersen et al. performed soft-clustering from 32 clinical variables which yielded 4 diabetes archetypes comprising a third of the study population. The remaining study population was deemed as mixed-phenotype. This study has not been replicated43. A third study re-identified the genetic subtypes and their clinical associations from Udler et al.45. Additionally, one of the first clinical trials to assess precision medicine approaches for diabetes management was published after our literature search. The TriMaster Study tested dichotomised BMI and eGFR strata in a three-period crossover trial using three pharmacologic interventions with the primary hypothesis being stratum-specific differences in HbA1c46. Participants with obesity (BMI‚Äâ>‚Äâ30‚Äâkg/m2) showed a glycaemic benefit on pioglitazone versus sitagliptin and participants with lower eGFR (60‚Äì90‚Äâml/min/1.73‚Äâm2) responded with lower HbA1c to sitagliptin as compared to canagliflozin. In a secondary analysis, drug-choice corresponding to patient preferences yielded lower glycemia than a random allocation, suggesting that listening to patients is critical in informing therapeutic decisions47. Ramifications of this study are limited by the non-comparable pharmacologic doses used, and the primary focus on glycaemia which may not be indicative of long-term therapeutic success and/or prevention of complications. Yet these studies have generated higher quality evidence linking type 2 diabetes heterogeneity to treatment and disease outcomes. It remains to be seen if these can be replicated in other ancestries and translated into ‚Äòusable products‚Äô for healthcare professionals. It is worth noting that ketosis-prone type 2 diabetes, an established type 2 diabetes subtype, was not captured adequately in our systematic review: only one study included ketosis-prone type 2 diabetes as an exposure48. Study designs for ketosis-prone type 2 diabetes were usually analyses of cohorts with diabetic ketoacidosis at presentation with type 1 diabetes as the outcome, rather than as an exposure in people with type 2 diabetes. Since our search was designed to identify studies stratifying type 2 diabetes, this literature was not captured. Like many other ‚Äòsimple‚Äô criteria for classification, the characteristics of people with diabetic ketoacidosis at presentation of type 2 diabetes have been studied, but with few prospective studies that have been replicated49. Age at diagnosis as a simple approach to stratification also did not feature strongly in our search results. The body of literature that outlines higher risk of microvascular or macrovascular complications in early-onset type 2 diabetes has focussed on comparing people with type 2 diabetes to those without diabetes in different age groups39,50 or studied cohorts of early-onset cases in isolation51 and, thus, would not have been captured in our search strategy. Recent epidemiological studies have compared outcomes between early and late age onset strata52,53 showcasing higher risks of cardiorenal outcomes with early age at onset, but these were retrospective analyses of health record databases, potentially confounded by age-related risk of complications and duration of diabetes. To move forward, prospective studies stratifying different interventions (e.g., tighter treatment targets or better cardiovascular risk reduction) in those diagnosed at younger age, are needed. Findings in context We found that simple features have not been precisely and reproducibly evaluated to a high enough standard to subclassify type 2 diabetes into subtypes. This is not surprising, as many studies were not necessarily conducted for the purpose of ‚Äòprecision diagnosis‚Äô, but rather as studies of clinical phenotypes spanning a time period that preceded the current research focus on precision medicine. It is important to re-emphasise that many of the simple clinical criteria studied, do have other bodies of evidence supporting associations with outcomes, like age -at -diagnosis. While these studies have set the scene, the field needs more robust evidence. ‚ÄòComplex‚Äô methods for diabetes subclassification have shown better reproducibility, have been linked to a variety of meaningful clinical outcomes more consistently, and more recently have been able to demonstrate differential treatment responses related to stratification. What do these findings mean for a precision medicine approach to type 2 diabetes diagnosis? Ideally, subclassification strategies should be deployed at diagnosis of type 2 diabetes on the basis of measured clinical characteristics such that people in different subgroups of type 2 diabetes could be treated differently. One key question is whether such efforts would cost-effectively improve clinical outcomes, compared to the current standard of care. However, another more fundamental question is whether subclassification approaches at diagnosis alone are enough? For example, another approach may be to iteratively subclassify longitudinal disease trajectories. Such an approach is supported by studies that have shown cluster-based assignments of type 2 diabetes at diagnosis are not robust and may change over time54. It may be argued that subclassification at one-time point is overly simplistic and should be regularly reviewed based on trajectory. Irrespective of the subclassification approach studied, they need replication in independent datasets, assessment in diverse populations, in people with both new-onset and prevalent diabetes, and investigation using prospective data, ideally in the form of randomised clinical trials. Clinical trials of treatment approaches tailored to diabetes subtypes will be necessary to understand the clinical benefits of clinical subtyping. Ideally, sub-phenotyping should lead to benefits for patients in real-world clinical settings. Conducting these studies will be challenging due to the necessity for extensive follow-up, large sample sizes, and substantial resource requirements. There is a pressing need for innovative strategies to generate high-quality evidence on treatment options tailored to specific diabetes subtypes in diverse populations. These data will be critical to determine generalisability of findings and amenability for clinical translation including in resource-constrained settings. Clinical applicability The current evidence supports distinguishable subtypes of type 2 diabetes and that these subtypes are associated with variation in clinical outcomes. However, the very low to moderate quality of existing studies and the need for replication in ancestry-diverse studies make it difficult to identify a strongly evidence-based, universally applicable approach. The most clinically valuable methods are likely to be those that are easy and inexpensive to implement. For more complex approaches, computer decision support tools will need to be developed and assessed for feasibility and utility. Although the evidence supporting complex approaches has leap-frogged the evidence in favour of more simplified approaches, there is still likely a place for simple approaches that can be more accessible at diverse clinical interfaces. Meanwhile how cluster assignment could be translated into actionable data for the individual remains unclear; will for example, a given person with type 2 diabetes exist in a distinct subgroup with associated outcomes or will the subtype of type 2 diabetes have associated probabilities or risks of certain outcomes? While stratifying people with type 2 diabetes into discrete subtypes might result in information loss, compared to continuous risk modelling40, discrete clusters might inform clinical decisions42."
2023,Understanding Type 2 Diabetes Mellitus Risk Parameters through Intermittent Fasting: A Machine Learning Approach,"Type 2 diabetes mellitus (T2DM) is a chronic metabolic disorder characterized by elevated blood glucose levels. Despite the availability of pharmacological treatments, dietary plans, and exercise regimens, T2DM remains a significant global cause of mortality. As a result, there is an increasing interest in exploring lifestyle interventions, such as intermittent fasting (IF). This study aims to identify underlying patterns and principles for effectively improving T2DM risk parameters through IF. By analyzing data from multiple randomized clinical trials investigating various IF interventions in humans, a machine learning algorithm was employed to develop a personalized recommendation system. This system offers guidance tailored to pre-diabetic and diabetic individuals, suggesting the most suitable IF interventions to improve T2DM risk parameters. With a success rate of 95%, this recommendation system provides highly individualized advice, optimizing the benefits of IF for diverse population subgroups. The outcomes of this study lead us to conclude that weight is a crucial feature for females, while age plays a determining role for males in reducing glucose levels in blood. By revealing patterns in diabetes risk parameters among individuals, this study not only offers practical guidance but also sheds light on the underlying mechanisms of T2DM, contributing to a deeper understanding of this complex metabolic disorder.","Over the past decade, the landscape of T2DM care has witnessed remarkable progress, ushering in a new era of personalized and holistic approaches. Utilizing cutting-edge methods, treating T2DM has taken innovative paths that hold promising potential. Stem cell therapy, for instance, represents a forward-looking approach that aims to harness the regenerative capabilities of stem cells to address the underlying factors of T2DM [47,48,49]. This method targets the restoration of damaged pancreatic beta cells responsible for insulin production, thereby enhancing the body‚Äôs glucose regulation. Stem cells sourced from various origins, such as adipose tissue or bone marrow, offer a way to replenish beta cell populations and mitigate the inflammatory response associated with T2DM. While stem cell therapy is in its early stages, preliminary clinical trials and preclinical studies have shown encouraging results, with improved glycemic control noted in certain patients. However, challenges like selecting optimal cell sources and ensuring long-term efficacy remain [50]. In addition to stem cell therapy, another emerging approach gaining traction is the use of CRISPR-Cas9 gene editing technology to modify genes related to T2DM [51]. This innovative method aims to target the root causes of the disorder by directly manipulating key genes involved in insulin production and glucose regulation. Although still in its infancy, precision gene editing offers the potential for more focused and durable interventions. This strategy directly tackles genetic factors contributing to T2DM and has the potential not only to manage but also to potentially reverse the condition‚Äôs progression. However, thorough research and clinical trials are essential to fully understand its safety, efficacy, and long-term impacts [52]. Among the various avenues explored, IF has garnered considerable attention as an alternative approach to conventional T2DM treatments [10,18,19,21,22,53]. IF entails cyclic patterns of controlled eating and fasting, demonstrating the potential to enhance insulin sensitivity, enhance glucose metabolism, and reduce inflammation. Unlike strict diets or exercise regimens, IF is adaptable to individuals‚Äô lifestyles and embraces a natural, holistic methodology without significant side effects. IF primary mechanisms to improve T2DM risk parameters involve metabolic changes that enhance overall metabolism and trigger tissue-specific metabolic adaptations. These adaptations include modifications in the gut microbiota, remodeling of adipose tissue, restoration of circadian rhythm balance, and increased autophagy in peripheral tissues [19,53]. IF offers a promising approach for treating T2DM, though individual responses can vary based on factors such as age, metabolic profile, and overall health. While some experience significant improvements, others may observe minimal changes, highlighting the need for personalized diabetes management. To address this, a recommendation system powered by machine learning analyzes individual characteristics to tailor IF guidance, maximizing its benefits. Age, weight, and BMI also play crucial roles, influencing outcomes as metabolic conditions differ. Recognizing these factors is vital for understanding conflicting study results and comprehensively evaluating IF‚Äôs potential benefits and limitations for T2DM intervention. IF, however, does not exist in isolation. Rather, it complements and enriches the existing arsenal of treatments. Traditional approaches continue to hold value in managing T2DM, especially when tailored to each patient‚Äôs needs. Combining IF with pharmacological interventions and exercise can create a comprehensive regimen that addresses the multifaceted nature of T2DM. Moreover, the synergy of IF with advancements in precision medicine further refines treatment strategies. Utilizing machine learning algorithms to recommend personalized IF plans [54] aligns with the broader trend of precision medicine, where interventions are customized to individuals based on genetic, metabolic, and lifestyle factors. The results of this study allow us to conclude that weight is the crucial feature for females, while age is the determining factor for males to reduce glucose levels in blood. Furthermore, the results reveal the substantial role of BMI in determining the appropriateness of IF for reducing HOMA-IR in individuals below 59 years old. In contrast, for individuals aged 59 and above, gender, specifically for women, appears to have a higher likelihood of benefiting from the IF approach in reducing HOMA-IR. Leveraging advanced machine learning techniques, such a recommendation system holds the potential to provide highly personalized and customized recommendations, thereby optimizing the advantages of intermittent fasting for various subgroups within the population. Moreover, the development of such a recommendation system will contribute to our understanding of the underlying mechanisms behind T2DM and explore potential clinical applications of intermittent fasting in a more precise and individualized manner."
2023,Diabetes Detection Models in Mexican Patients by Combining Machine Learning Algorithms and Feature Selection Techniques for Clinical and Paraclinical Attributes: A Comparative Evaluation,"The development of medical diagnostic models to support healthcare professionals has witnessed remarkable growth in recent years. Among the prevalent health conditions affecting the global population, diabetes stands out as a significant concern. In the domain of diabetes diagnosis, machine learning algorithms have been widely explored for generating disease detection models, leveraging diverse datasets primarily derived from clinical studies. The performance of these models heavily relies on the selection of the classifier algorithm and the quality of the dataset. Therefore, optimizing the input data by selecting relevant features becomes essential for accurate classification. This research presents a comprehensive investigation into diabetes detection models by integrating two feature selection techniques: the Akaike information criterion and genetic algorithms. These techniques are combined with six prominent classifier algorithms, including support vector machine, random forest, k-nearest neighbor, gradient boosting, extra trees, and naive Bayes. By leveraging clinical and paraclinical features, the generated models are evaluated and compared to existing approaches. The results demonstrate superior performance, surpassing accuracies of 94%. Furthermore, the use of feature selection techniques allows for working with a reduced dataset. The significance of feature selection is underscored in this study, showcasing its pivotal role in enhancing the performance of diabetes detection models. By judiciously selecting relevant features, this approach contributes to the advancement of medical diagnostic capabilities and empowers healthcare professionals in making informed decisions regarding diabetes diagnosis and treatment.","The objective of this study is to compare the performance of six machine learning algorithms in combination with two feature selection techniques for generating classification models of diabetic and nondiabetic patients using clinical and paraclinical features. The implemented classifier algorithms include SVM, RF, kNN, GB, ET, and NB, while the feature selection techniques utilized are the Akaike information criterion and genetic algorithms. Initially, classification models were created using the complete feature set of the dataset and subsequently compared with models generated using feature subsets obtained through the feature selection techniques. A total of 18 classification models were generated, and their performance was compared. Based on the results obtained from the feature selection methods, the following can be concluded: By using the Akaike criterion as a feature selection technique, a reduction of 27% in the dataset size was achieved, keeping only 14 features out of the original 19. The selected features, which efficiently describe whether a patient has diabetes or not according to this method, are shown in Table 5 By applying genetic algorithms as a feature selection technique, a reduction of 73% in the number of features from the original dataset was achieved, resulting in only 5 selected features out of the initial 19. The frequency and rank of the genes (features) in the models determined by the genetic algorithm implementation are shown in Figures ‚ÄãFigures22 and ‚Äãand3,3, respectively. The features selected using this approach are presented in Table 7 The reduction achieved in the number of features through the implementation of the described feature selection methods is significant, particularly in the case of genetic algorithms. This reduction in the dataset size has a generally positive impact on the performance of the systems. By working with a smaller amount of data, several advantages can be obtained, including reduced processing time and lower energy consumption Although the implementation of feature selection techniques on the original dataset resulted in a reduction of 27% and 73% using the Akaike information criterion and genetic algorithms, respectively, it is important to note that in certain applications of the classification model, maximizing classification accuracy is often preferred over minimizing the amount of processed data. This is particularly relevant in the medical field, as is the case here. Therefore, for the generation of the classification models, the complete set of features was also considered a reference. This approach allows for finding a balance between the model's performance and the amount of data used for analysis Based on the findings derived from the exploration of classification models for distinguishing between diabetic and nondiabetic patients, utilizing six distinct classification algorithms, and employing the entire dataset encompassing 19 features, the subsequent conclusions can be established: The random forest (RF), gradient boosting (GB), and extra trees (ET) models consistently perform well across multiple metrics, including high AUC, specificity, sensitivity, accuracy, F1 score, and precision. These models demonstrate a strong ability to accurately classify both positive and negative instances The SVM model also performs well, achieving high scores in AUC, specificity, sensitivity, accuracy, F1 score, and precision. It shows a balanced performance in correctly classifying both positive and negative instances The naive Bayes (NB) model achieves moderate performance with relatively lower scores in specificity, accuracy, F1 score, and precision compared to the other models. It may have higher rates of false positives and lower overall accuracy compared to the top-performing models The k-nearest neighbor (kNN) model shows relatively lower performance in terms of specificity, accuracy, and F1 score. It may have higher rates of false positives and lower overall accuracy compared to the other models In summary, the random forest (RF), gradient boosting (GB), and extra trees (ET) models exhibit strong overall performance across multiple metrics, while the SVM model also performs well. The naive Bayes (NB) model achieves moderate performance, and the k-nearest neighbor (kNN) model shows relatively lower performance For the classification models that use the subset of features obtained through the Akaike criterion (14 features), the following can be concluded: The random forest (RF), gradient boosting (GB), and extra trees (ET) models maintain their high performance across multiple metrics, including AUC, specificity, sensitivity, accuracy, F1 score, and precision, even when using the reduced 14-feature subset. These models demonstrate the advantage of feature selection, as they maintain their strong classification abilities with a smaller set of features The SVM model also maintains a high level of performance, with consistently high scores in AUC, specificity, sensitivity, accuracy, F1 score, and precision when using the reduced feature subset The naive Bayes (NB) model shows a slight decrease in performance compared to the other models, particularly in specificity, accuracy, F1 score, and precision. However, it still achieves moderate performance overall The k-nearest neighbor (kNN) model exhibits the lowest performance among the models, with lower scores in specificity, sensitivity, accuracy, F1 score, and precision when using the reduced feature subset In summary, the random forest (RF), gradient boosting (GB), and extra trees (ET) models maintain their strong classification performance even with a reduced feature subset. The SVM model also demonstrates robust performance, while the naive Bayes (NB) model shows a slight decrease in performance. The k-nearest neighbor (kNN) model performs relatively weaker compared to the other models. These findings highlight the effectiveness of feature selection in reducing the dimensionality of the dataset while maintaining good classifier performance For the classification models that use the subset of features obtained through genetic algorithms (5 features), the following can be concluded: The random forest (RF), gradient boosting (GB), and extra trees (ET) models maintain their strong classification performance even with the significantly reduced 5-feature subset. These models consistently achieve high scores in various metrics, including AUC, specificity, sensitivity, accuracy, F1 score, and precision. This highlights the advantage of feature selection in reducing the dimensionality of the dataset while preserving good classifier performance The SVM model also maintains a relatively high level of performance, with consistently good scores in AUC, specificity, sensitivity, accuracy, F1 score, and precision when using the reduced 5-feature subset The naive Bayes (NB) model performs slightly lower in terms of specificity, accuracy, F1 score, and precision compared to the other models. However, it still achieves moderate performance overall The k-nearest neighbor (kNN) model exhibits the lowest performance among the models, with lower scores in specificity, sensitivity, accuracy, F1 score, and precision when using the reduced 5-feature subset In summary, the random forest (RF), gradient boosting (GB), and extra trees (ET) models demonstrate their robustness by maintaining their strong classification performance even with a highly reduced feature subset. The SVM model also maintains good performance, while the naive Bayes (NB) model shows slightly lower performance. The k-nearest neighbor (kNN) model performs relatively weaker compared to the other models. These findings emphasize the effectiveness of feature selection in reducing the dimensionality of the dataset while preserving or even improving classifier performance From the Wilcoxon statistical test performed on the complete dataset, the following can be concluded: The results of the Wilcoxon test reveal significant differences between the case group (diabetic patients) and the control group (nondiabetic patients) concerning the dataset features. This indicates that the selected features play a relevant role in distinguishing between the two groups. Selecting appropriate features is essential for generating accurate and effective classification models for diabetes detection The statistical significance obtained through the Wilcoxon test provides robust validation for our classification models. The results support the effectiveness of the models in distinguishing between diabetic and nondiabetic patients using the selected features. This reinforces confidence in the utility and applicability of our models in diabetes detection for future clinical scenarios The inclusion of the Wilcoxon test in our study has enabled a comprehensive assessment of statistical significance and validity of the results obtained. This test has been instrumental in ruling out random chance as the cause of observed differences between the groups and supporting the robustness of our findings. The incorporation of this statistical test strengthens the quality and reliability of our study and its conclusions"
2023,Using Machine Learning Algorithms to Predict Patient Portal Use Among Emergency Department Patients With Diabetes Mellitus,"Background Different machine learning (ML) technologies have been applied in healthcare systems with diverse applications. We aimed to determine the model feasibility and accuracy of predicting patient portal use among diabetic patients by using six different ML algorithms. In addition, we also compared model performance accuracy with the use of only essential variables. Methods This was a single-center retrospective observational study. From March 1, 2019 to February 28, 2020, we included all diabetic patients from the study emergency department (ED). The primary outcome was the status of patient portal use. A total of 18 variables consisting of patient sociodemographic characteristics, ED and clinic information, and patient medical conditions were included to predict patient portal use. Six ML algorithms (logistic regression, random forest (RF), deep forest, decision tree, multilayer perception, and support vector machine) were used for such predictions. During the initial step, ML predictions were performed with all variables. Then, the essential variables were chosen via feature selection. Patient portal use predictions were repeated with only essential variables. The performance accuracies (overall accuracy, sensitivity, specificity, and area under receiver operating characteristic curve (AUC)) of patient portal predictions were compared. Results A total of 77,977 unique patients were placed in our final analysis. Among them, 23.4% (18,223) patients were diabetic mellitus (DM). Patient portal use was found in 26.9% of DM patients. Overall, the accuracy of predicting patient portal use was above 80% among five out of six ML algorithms. The RF outperformed the others when all variables were used for patient portal predictions (accuracy 0.9876, sensitivity 0.9454, specificity 0.9969, and AUC 0.9712). When only eight essential variables were chosen, RF still outperformed the others (accuracy 0.9876, sensitivity 0.9374, specificity 0.9932, and AUC 0.9769). Conclusion It is possible to predict patient portal use outcomes when different ML algorithms are used with fair performance accuracy. However, with similar prediction accuracies, the use of feature selection techniques can improve the interpretability of the model by addressing the most relevant features.","In this study, different ML algorithms were used to predict patient portal use among ED DM patients. We found overall good predictive accuracies from five out of six different ML models, which indicates the applicability of using ML technology for patient portal prediction among individuals with DM. However, special attention should be paid when using ML prediction since different ML models might result in different performance accuracies [29]. In our models, though using the same dataset, SVM prediction yielded the poorest performance when compared with the other prediction models. In addition, some ML predictions provide results via a ‚Äúblack-box‚Äù analysis [16] which might have less value for physicians/administrators when determining the weight of the variables. However, the step of ML analysis using identified variables in our study overcomes the difficulties of ‚Äúblack-box‚Äù analysis. Using different ML models to determine the prediction performance accuracy, not only did we compare the accuracy of each ML model and choose the best one for the predictions, but also identified important variables for outcome predictions. Determining these essential variables for outcome prediction can help develop effective interventions which yield improved outcomes. Moreover, when these essential variables were identified, subsequent ML predictions provide further validation about the value of these essential variables for future interventions. This study does not emphasize findings of which ML models best predict patient portal use among ED DM patients. Instead, the dataset is a resource for different ML prediction models and validates the value of stepwise ML prediction. This study explores the usefulness of our ‚Äúmethod‚Äù instead of being a healthcare prediction project. More importantly, this study shows the importance of choosing variables for ML predictions. More variables included in the ML prediction models seem to be less important than the ‚Äúessential‚Äù variables included in the model. The primary ML prediction models used 18 variables, whereas the secondary ML prediction models only used eight variables. However, both yielded similar performance accuracies. This result is consistent with the ‚ÄúGarbage in, garbage out‚Äù phenomenon, frequently noted when ML is used in the field of medicine [30]. With the development of electronic medical records, numerous variables can be easily retrieved. However, most variables might not play an important role in the ML model predictions [18]. We suggest that screening, expert opinion, and group discussions to carefully choose essential variables should be the critical steps before initiating ML predictions. Our study used a relatively large sample to predict patient portal use outcomes with the use of six different ML algorithms. We performed performance accuracy comparisons, one with 18 variables and the other, with only eight variables. We believe that these choices increase the validity of our results. Our study also has its limitations. First, we only studied six ML prediction models, excluding other ML models from study and comparisons. Second, our dataset was limited to a single hospital ED, so uncertainty remains as to whether our stepwise prediction model can be generalized to different datasets. Third, since the choice of variables for the initial ML predictions largely depends on expert opinions and discussion, our study does not have data to validate this determination. Therefore, future studies are warranted to validate the value of using ML prediction models to predict clinical outcomes and further apply models for real-time predictions in medicine."
2023,Cardiovascular complications in a diabetes prediction model using machine learning: a systematic review,"Prediction model has been the focus of studies since the last century in the diagnosis and prognosis of various diseases. With the advancement in computational technology, machine learning (ML) has become the widely used tool to develop a prediction model. This review is to investigate the current development of prediction model for the risk of cardiovascular disease (CVD) among type 2 diabetes (T2DM) patients using machine learning. A systematic search on Scopus and Web of Science (WoS) was conducted to look for relevant articles based on the research question. The risk of bias (ROB) for all articles were assessed based on the Prediction model Risk of Bias Assessment Tool (PROBAST) statement. Neural network with 76.6% precision, 88.06% sensitivity, and area under the curve (AUC) of 0.91 was found to be the most reliable algorithm in developing prediction model for cardiovascular disease among type 2 diabetes patients. The overall concern of applicability of all included studies is low. While two out of 10 studies were shown to have high ROB, another studies ROB are unknown due to the lack of information. The adherence to reporting standards was conducted based on the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) standard where the overall score is 53.75%. It is highly recommended that future model development should adhere to the PROBAST and TRIPOD assessment to reduce the risk of bias and ensure its applicability in clinical settings. Potential lipid peroxidation marker is also recommended in future cardiovascular disease prediction model to improve overall model applicability.","This review identified ten machine learning models that were developed for predicting cardiovascular disease among diabetic patients conducted mostly among European population. Even though the prevalence of cardiovascular diabetic was high in Asian countries, only two included studies were conducted among the Chinese population but none from the Malay or Indian population. In 2019, 44.2% of Malaysian patients presented with acute coronary syndrome had diabetes which is the second common cardiovascular risk factor (CVRF) after hypertension (61.9%) [37]. Thus, this highlighted the importance of conducting predictive model studies of diabetic cardiovascular disease for Malaysian since its population also pose a higher risk at younger age than the European population [38]. Furthermore, a sharp increase of T2DM treatment cost from USD 232 billion in 2007 to USD 966 billion in 2021 with the high prevalence of the disease worldwide is causing concerns on its burden in the lower-income nations [39]. It is known that most T2D patients do not require insulin for the rest of their life, but the complications developed from T2D eventually increase the economic burden on the patients and the healthcare system worldwide [1, 40]. Thus, it is essential to develop cardiovascular diabetes prediction model to effectively reduce the morbidity and further complication as well as the economic burden especially in Asian countries. The artificial neural network model (ANN) reported by Dalakleidia and Zarkogianni [13] showed that ANN performed better than other algorithms such as NB, decision tree, and logistic model when working with the imbalanced nature of medical datasets. Imbalanced dataset is when the distribution of classes is unequal that leads to the situation where one class out represent the other. This suggest that receiver operating curves, precision-recall curves, and cost curves are necessary when imbalanced datasets are involved [41]. This nature of medical datasets lead to prediction bias towards larger disjuncts and misclassification of the smaller disjuncts [42]. To avoid class imbalance, oversampling of the minority class such as the use of Synthetic Minority Oversampling Technique (SMOTE) can help improving the overall accuracy of a model [14]. In addition, three out of ten studies in this review have supported that neural network can be used to construct predictive models for diabetic cardiovascular disease. However, the three studies that involve neural network did not include the use of gradient boosting algorithm, thus, these models were not compared based on their accuracy, sensitivity, specificity, and precision. Before machine learning was introduced, prediction models were developed using classical statistics such as logistic regression. The Framingham Heart Studies (FHS) is one of the most famous examples of a prediction model for cardiovascular disease that applies logistics regression [43] and the focus on diabetes mellitus as a risk factor of CVD emerged after years of follow up studies [44, 45]. Other than logistic regression, a classic statistical model such as the cox regression model was also applied in the development of CVD prediction model for diabetic patients. For example, a study that incorporated the patient population and electronic medical record (EMR) data in US [46] developed a cox regression model with a c-statistic of 0.782 and the model reported in Ley et al. [47] achieved a c-statistic of 0.73 (0.72‚Äì0.74). While classical statistic has been applied in various medical disciplines from CVD to cancer studies [48‚Äì50], machine learning model is advantageous when working with pattern recognition other than just projection based on existing data [51]. Predictors in a predictive model are important as it affects the performance when dealing with new datasets. However, not all studies mention about the impact of the predictors involved in their models. Out of ten articles reviewed, only four studies summarized the most important factors for their model and BMI were reported as the top five key factors. BMI has been used as an obesity indicator, which is directly linked to cardiovascular disease and diabetes [52]. With the increasing availability of fast food and processed food, the general eating habit and diet of most people are known to become less healthy due to increasing carbohydrates and fat intake. This phenomenon worsens in recent years as part of the urbanization [53]. Body mass index reflects the diet of an individual which is also known to be a strong factor in causing cardiovascular complications among diabetic patients [54]. Although its contribution to the prediction models was not reported in all included studies, six out of ten articles used BMI as one of their predictors. Although family history is known to be a major risk factor in the development of the CVD, but none of the study included this predictor. This might be due that family history of CVD has been excluded in these studies [55, 56]. In the past few decades, the number of studies on lipid peroxidation is increasing due to its association with cardiovascular disease through lipid alteration [8, 57]. The earliest mention of lipid peroxidation with extensive discussion is in 1958 by Lundberg [58]. Since then, more studies about the autoxidation of lipid were published. Even though the relationship between increased lipid peroxidation level in diabetic patients and risk of CVD is well known [59], no studies included in this systematic review included any lipid peroxidation marker as a predictor in model development. Although this review is quite comprehensive that followed the guideline of PRISM-P, the selection framework by PICOTS and addressed all the risk assessment bias using PROBAST and TRIPOD, but the search of this study was only performed on Scopus and WoS only. Meta-analysis also could not be done due to the limited number of articles and recent studies. To address the imbalanced nature of clinical data, which is very common in life sciences, precision-recall curve (PRC) is the recommended metric to display the true performance of a prediction model [60]. The sample size varies significantly among the prediction models discussed in this review, ranging from 560 in the study by Nowak and Carlsson [34] to more than 200,000 subjects in the study by Dworzynski, Aasbrenn [32]. The best model has the sample size of 834 subjects where the study with second best models involved 124,000 subjects. For clinical practice, prediction models are required to be user friendly, and the presentation of the results also play a vital role in the communication between clinician and patients. Furthermore, to ensure the reliability and overall precision of a prediction model, external validation must be conducted using new datasets as the test data [61]. In the future, existing models can also be improved using newly collected data."
2023,Prediction of Diabetes Mellitus Progression Using Supervised Machine Learning,"Diabetic peripheral neuropathy (DN) is a serious complication of diabetes mellitus (DM) that can lead to foot ulceration and eventual amputation if not treated properly. Therefore, detecting DN early is important. This study presents an approach for diagnosing various stages of the progression of DM in lower extremities using machine learning to classify individuals with prediabetes (PD; n = 19), diabetes without (D; n = 62), and diabetes with peripheral neuropathy (DN; n = 29) based on dynamic pressure distribution collected using pressure-measuring insoles. Dynamic plantar pressure measurements were recorded bilaterally (60 Hz) for several steps during the support phase of walking while participants walked at self-selected speeds over a straight path. Pressure data were grouped and divided into three plantar regions: rearfoot, midfoot, and forefoot. For each region, peak plantar pressure, peak pressure gradient, and pressure‚Äìtime integral were calculated. A variety of supervised machine learning algorithms were used to assess the performance of models trained using different combinations of pressure and non-pressure features to predict diagnoses. The effects of choosing various subsets of these features on the model‚Äôs accuracy were also considered. The best performing models produced accuracies between 94‚Äì100%, showing the proposed approach can be used to augment current diagnostic methods.","The purpose of this study was to determine the feasibility of using supervised machine learning algorithms to accurately classify persons who are diagnosed with pre-diabetes, diabetes, or diabetes with peripheral neuropathy. The classification accuracies, as well as the false negative rates for DN in the test dataset, were used to determine which algorithms and features subsets performed best. The false negative rates for DN participants are especially important because of the difficulty in diagnosing DN using current techniques. Table 5 indicates that all datasets yielded reasonably accurate classifications. However, since false negative rates are important for this type of analysis, it is reasonable to consider dataset 1 and datasets 11 through 14; all had zero percent false negative rates. Of these five datasets, datasets 13 and 14 had the highest F1 score, of 100%. The results may indicate that a subset of the tested features can be more successful in classification than using all available features. A recent study that used biomechanical data to train and test machine learning algorithms for DN diagnosis also found that using a subset of features, rather than the entire dataset, yielded greater accuracies [32]. Thus, the identification and inclusion of significant features, rather than all available features, could produce more effective and less computationally costly algorithms. The only pressure features in datasets 13 and 14 were for PTI. This indicates that PTI may play a significant role in DN classification. A previous study indicated that rearfoot values of peak pressure are significant in classification [22]. PPP has also been reported to be a significant indicator for DN [17,22]. This was corroborated in this study by the high performance of datasets 9 and 10, which relied solely on PPP pressure features, and datasets 5 and 6, which used PPP and PTI features. For these specific datasets, ensemble bagged trees and ensemble subspace KNN classifiers produced the best classifications of the data. It is also of note that subspace KNN was the second-best performing algorithm for five of the seven datasets where it was not the best performing, excepting only datasets 3 and 7. Table 5 also indicates that the exclusion of HbA1c did not yield any significant difference in results. Testing only the non-pressure features, with and without HbA1c, resulted in 100% in all three measures. This may be because during data collection, while the pressure values would change for each trial, the non-pressure features for each participant would remain the same, since the measures were not variable during a single data collection session. As such, the current dataset did not produce any significant trends or results when looking only at the non-pressure features. No trends in the non-pressure features when plotted across the three classes were found, either. Since the non-pressure features did not have any discernable pattern in delineating the three classes, it could not be concluded that non-pressure features are all that is needed to classify individuals with PD, D, or DN, and further exploration into the impact of these features on classification was unfruitful. The non-pressure features alone were thus concluded to not have the ability to accurately classify the data. Analyzing solely the pressure features allowed the features that played a more significant role in accurate classification to become clearer. The results of analyzing only the pressure features (Table 6) indicate that datasets 1, 5, 7, and 13 had test accuracies of greater than 80% and false negative rates of less than 3%. It should be noted that dataset 1 included all pressure features; dataset 5 had PPP and PTI features; dataset 7 combined PPG and PTI features; and dataset 13 only contained PTI features. The recurrence of PTI indicated its significance in classifying the progression of diabetes. When considering only pressure features, the results indicated that including more features does produce a higher test accuracy, but only when PTI features are included. For example, dataset 3, which included PPP and PPG features, achieved a test accuracy of 65% and false negative rate of 39%. Similarly, dataset 9 included only PPP features, and dataset 11 only included PPG features. All of these datasets produced test accuracies of less than 70% and false negative rates of greater than 50%. Overall, the inclusion of PTI, even as the sole pressure feature, greatly enhanced all three measures. The results from Table 6 indicate that a variety of pressure features used alone can still provide adequately accurate classifications, as datasets 1 and 5 had precision, recall, and F1 scores of higher than 90%. By comparing the results from Table 5 and Table 6, however, it can be seen that if using only a limited number of pressure features, having non-pressure features will greatly enhance the feasibility of this method, exemplified best by the drastic performance difference in dataset 11. A study that used center of pressure data to train and test a deep clustering model found that individuals with DN tend to apply less force while walking and have longer stance times during gait [33]. As such, individuals who have DN might have values for PPG or PPP similar to those of the other classes, but their PTI values are more distinct, since the feature combines pressure, foot size (due to the increased number of sensors for larger insoles), and time. Additionally, since PTI represents the combined effect of these three factors, it can avoid the variability due to gait variation better than PPP or PPG. Given the high presence of PTI in the best performing algorithms, further study into the relationship between foot size, walking speed, and PTI is desirable. Table 7 shows that PCA achieved comparable results for the best datasets of Table 5: datasets 1 and 11 through 14. The results that were achieved using ensemble classifier with subspace KNN model produced the highest results in conjunction with PCA. Apart from datasets 8, 9, and 12‚Äì14, PCA also led to higher false negative rates. While dimensionality reduction was explored to see if the model performance could be enhanced, the results indicate that PCA was unsuccessful in this. While ensemble classifier with bagged trees was a high performing algorithm throughout the results, various forms of KNN also performed well for half of the datasets (Table 5). KNN performing well has been documented before in a previous study that also analyzed multiple algorithms in classifying DN using EMG and gait data [34]."
2023,A Machine Learning-Based Prediction of Diabetes Insipidus in Patients Undergoing Endoscopic Transsphenoidal Surgery for Pituitary Adenoma,"Background Diabetes insipidus (DI) is a common complication after endoscopic transsphenoidal surgery (TSS) for pituitary adenoma (PA), which affects the quality of life in patients. Therefore, there is a need to develop prediction models of postoperative DI specifically for patients who undergo endoscopic TSS. This study establishes and validates prediction models of DI after endoscopic TSS for patients with PA using machine learning algorithms. Methods We retrospectively collected information about patients with PA who underwent endoscopic TSS in otorhinolaryngology and neurosurgery departments between January 2018 and December 2020. The patients were randomly split into a training set (70%) and a test set (30%). The 4 machine learning algorithms (logistic regression, random forest, support vector machine, and decision tree) were used to establish the prediction models. Area under the receiver operating characteristic curves were calculated to compare the performance of the models. Results A total of 232 patients were included, and 78 patients (33.6%) developed transient DI after surgery. Data were randomly divided into a training set (n = 162) and a test set (n = 70) for development and validation of the model, respectively. The area under the receiver operating characteristic curve was highest in the random forest model (0.815) and lowest in the logistic regression model (0.601). Invasion of pituitary stalk was the most important feature for model performance, closely followed by macroadenomas, size classification of PA, tumor texture, and Hardy-Wilson suprasellar grade. Conclusions Machine learning algorithms identify preoperative features of importance and reliably predict DI after endoscopic TSS for patients with PA. Such a prediction model may enable clinicians to develop individualized treatment strategy and follow-up management.","As one of the factors influencing the postoperative quality of life in patients with PA, postoperative urine volume is a vital index. Early and adequate intervention can prevent the development of DI-related complications. For clinicians, an appropriate predictive tool to identify subgroups at high risk of DI after endoscopic TSS would improve patient safety and optimize the accuracy of the final recommendation. In this study, we included 232 patients with PA for endoscopic TSS, and 33.6% had DI, which was similar to the previous studies.1 whereas the incidence of DI after an open approach was 21.4%‚Äì33.3%.2 Although endoscopic TSS was a more minimally invasive method than the microscopic TSS approach and open approach, the incidence of DI did not decrease as anticipated. This finding suggested that the prevention of DI has great clinical value. Our study developed different ML prediction models for DI after endoscopic TSS. The 3 ML models had better performance than did the traditional LR model. Many studies have predicted DI after endoscopic TSS. The results of our study showed that the most important predictor was pituitary stalk invasion, followed by size of tumor, texture of tumor, and suprasellar grade. These factors reflected the invasiveness of PA, which indicated that the extent of junction between tumor and surrounding structures was directly related to the occurrence of postoperative DI. The predictive factors can usually be divided into 3 categories. The first category was the baseline characteristics of patients. Previous studies have shown that there was no significant correlation between gender and postoperative DI. However, the conclusions about the relationship between patients' age and postoperative DI were inconsistent. Oh et al.4 found that age was not a predictor of postoperative DI in patients with PA, and the study by Zhan et al.11 concluded that the incidence of DI in elderly patients with PA was higher than that in the young. However, Kinoshita et al.12 obtained the opposite findings by retrospectively analyzing 333 patients with PA. This finding may have several reasons, such as hormone level and operation condition. Young and elderly patients may have different operation objectives or extent of resections. The former tend to receive more active operations. No statistical difference in age between the DI group and non-DI group were observed by univariate analysis. However, it was considered to have a predictive effect and was included in the predictive model after LASSO regression. The reason for this difference may be that LASSO regression can screen out more predictive and generalizable variables than can univariate analysis. The mechanism of age on postoperative DI was still unclear. As speculated, vasospasm caused by the decline of vascular adaptability in elderly patients may incur hypothalamic dysfunction or ischemia, which makes patients prone to developing DI.11 Many studies have found that the body mass index (BMI, calculated as weight in kilograms divided by the square of height in meters) of patients with postoperative DI was higher than that of patients without postoperative DI. The BMI of patients with DI in the training cohorts was 26.26 kg/m2 (range, 22.95‚Äì27.93 kg/m2), which was higher than that of the non-DI group. Some studies have found that obesity in patients was usually accompanied by nasal stenosis, which may cause more damage to the hypothalamus or infundibulum during surgery, resulting in the increasing risk of postoperative DI.4 It was reported that obesity has influences in the regulation of antidiuretic hormone,13,14 which may be a potential mechanism. In addition, many studies have shown that the low BMI of patients with PA is a significant predictor of postoperative syndrome of abnormal antidiuretic hormone secretion and hyponatremia.15,16 Whether BMI is a predicting factor for DI has to be further investigated. In this study, the prediction model included tumor diameter and classification, invasion of the pituitary stalk, suprasellar extension, tumor texture, and tumor pathologic classification. Of the patients, 85.2% in the training cohort and 78.6% in the testing cohort had macroadenomas. Our univariate analysis showed significant differences in tumor size classification between the DI and the non-DI groups. The invasiveness of tumor was mainly reflected in the Knosp grade and the Hardy-Wilson grade. Some studies17,18 have proposed that Knosp grade and Hardy-Wilson grade was significantly correlated with postoperative DI. In our study, Knosp and Hardy-Wilson grade were also included in the prediction model according to the LASSO regression. Antidiuretic hormone was produced by the hypothalamus and stored in the neurohypophysis through the pituitary stalk. Therefore, surgical resection of tumors around the pituitary stalk may influence the secretion of antidiuretic hormone. Invasion of pituitary stalk was found in 69.6% of patients in the DI group and 46.2% in the non-DI group of the training cohort. In the testing cohort, 81% of patients in the DI group and 62% of patients in the non-DI group had invasion of the pituitary stalk. Univariate analysis showed a significant correlation between preoperative pituitary stalk invasion and postoperative DI, consistent with the previous studies.19,20 Theoretically, patients with oppression or invasion by tumor need more extensive resection. This finding raises the possibility of pituitary stalk injury, leading to an increased incidence of temporary DI.17 Consistent with the conclusions of Li,21 tumor texture was also included in the prediction model in our study. Soft tumors can easily be sucked by aspirators during operation, whereas tough tumors may cause serious traction on surrounding structures. Severe traction may destroy the pituitary stalk and supply of the posterior pituitary and cause DI. In addition, the pathologic features of PA were found to be related to postoperative DI. The risk of temporary DI in patients with prolactin adenoma and adrenocorticotropic hormone‚Äìsecreting PA was significantly increased.22,23 Some studies have suggested that cortisol may cause the decrease in urine concentration, which can be misdiagnosed as DI. Except for Cushing disease, there is no consistent conclusion regarding the influence of other pathologic types on postoperative DI. Burke et al.23 found that thyroid-stimulating hormone‚Äìsecreting and follicle-stimulating hormone/luteinizing hormone‚Äìsecreting adenoma have a higher incidence of DI. However, limitations in sample size and power make it difficult to draw such conclusions. Pathologic types and pituitary hormones were incorporated into the prediction model. In our study, the most common pathologic type was nonfunctional PA, and there were few patients with Cushing disease. Our results showed that pathologic features were not related to postoperative DI by univariate analysis. Previous retrospective studies have mainly focused on DI-related clinical variables, using traditional methods to output statistical results for the odds ratio and P value, which is easier to explain. However, most researchers believe that multifactor statistical analysis is more valuable compared with univariate analysis to determine DI. The inputs and outputs are known for the ML model, but the specific decision-making process is unclear. The ML model incorporated a wider range of potential risk factors and prediction variables in prediction analysis. Although the interpretability of the ML model was reduced, it can achieve higher prediction accuracy.13,24 ML can be used to predict various important prognoses of endoscopic TSS, such as total resection of the tumor,25 intraoperative cerebrospinal fluid leakage,26 postoperative hyponatremia,13,27 postoperative endocrine remission, and tumor recurrence.17,28, 29, 30 Our results showed that the ML models, especially the RF model, can provide more accurate prediction ability. Christodoulou et al.31 systematically reviewed 71 studies and compared the performance of LR with ML for clinical prediction modeling and found no evidence that ML is superior to LR. The reason may be that some ML models had not carried out proper feature selection and sufficient parameter tuning. This review also suggested that LR models need to be calibrated and clinical decision curves created to evaluate model performance. ML is not superior to LR when only the prespecified features are considered because the advantage of ML lies in the comprehensive processing of large amounts of data. After sufficient adjustment of ML parameters, our results showed that the prediction performance of the ML model was better than that of the LR model. Nevertheless, this study still has some limitations: 1) it is a retrospective study, and some information bias should be considered when interpreting the model and related results; 2) for the ML model, our sample size is limited, which may influence the prediction power; and 3) the RF, SVM, and DT used in this study are all ML models, and the causal relationship between predictors and results is invisible, resulting in less model interpretability."
2023,Evaluation of Machine Learning Methods Developed for Prediction of Diabetes Complications: A Systematic Review,"Background: With the rising prevalence of diabetes, machine learning (ML) models have been increasingly used for prediction of diabetes and its complications, due to their ability to handle large complex data sets. This study aims to evaluate the quality and performance of ML models developed to predict microvascular and macrovascular diabetes complications in an adult Type 2 diabetes population. Methods: A systematic review was conducted in MEDLINE¬Æ, Embase¬Æ, the Cochrane¬Æ Library, Web of Science¬Æ, and DBLP Computer Science Bibliography databases according to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) checklist. Studies that developed or validated ML prediction models for microvascular or macrovascular complications in people with Type 2 diabetes were included. Prediction performance was evaluated using area under the receiver operating characteristic curve (AUC). An AUC >0.75 indicates clearly useful discrimination performance, while a positive mean relative AUC difference indicates better comparative model performance. Results: Of 13‚Äâ606 articles screened, 32 studies comprising 87 ML models were included. Neural networks (n = 15) were the most frequently utilized. Age, duration of diabetes, and body mass index were common predictors in ML models. Across predicted outcomes, 36% of the models demonstrated clearly useful discrimination. Most ML models reported positive mean relative AUC compared with non-ML methods, with random forest showing the best overall performance for microvascular and macrovascular outcomes. Majority (n = 31) of studies had high risk of bias. Conclusions: Random forest was found to have the overall best prediction performance. Current ML prediction models remain largely exploratory, and external validation studies are required before their clinical implementation.","This review has evaluated the performance of 87 prognostic prediction ML models for diabetes complications in people with Type 2 diabetes. Most ML models reported an AUC between 0.6 and 0.75 (possibly helpful discrimination), while 36% achieved an AUC above 0.75 (clearly useful discrimination). 33 From 16 comparison studies, ML methods generally showed better performance than non-ML methods. It must be noted, however, that these studies were rated at high risk of bias. This was similar to a review by Christodoulou et al, which found that the performance of ML and non-ML methods for prediction of clinical outcomes in the general population using models with low risk of bias were comparable. However, they noted that comparisons among models with high risk of bias tended to favor ML methods. 30 Among ML methods, random forest showed an overall better discrimination ability for both microvascular and macrovascular outcomes. A possible explanation is that random forest combines multiple models to overcome the limitations of single models, thereby reducing variance and improving prediction accuracy. In terms of predictors used in ML models, common predictors for both microvascular and macrovascular outcomes include age, duration of diabetes, and body mass index. Prolonged hyperglycemia is known to cause vascular damage through nonenzymatic glycosylation of proteins, oxidative stress, and inflammation. 68 Likewise, the relationship between age and diabetic complications has been linked to age-related impaired vascular function such as arterial stiffening, increased insulin resistance, and obesity. 66 The relationship between body mass index and diabetes complications is less clear, with a previous study suggesting that it was positively correlated with diabetic kidney disease but not with diabetic retinopathy. 69 Given that age and duration of diabetes can be obtained from electronic health data sets and their clinical relevance in the development of diabetes complications, researchers should consider including them when developing future ML predictive models. In terms of model development, many studies were limited by small number of outcomes examined and sample sizes, often with events per variable below 10. In addition, internal validations with resampling and external validations were inconsistently performed. This raises concerns of model overfitting and optimism, as ML techniques have been found to require significantly larger events per variable (>200) to achieve a stable AUC and a small optimism compared with traditional statistical methods such as logistic regression. 32 The ML models in this review were considered largely exploratory, and future validation studies are required before clinical implementation. 16 For studies with externally validated models, further model-impact studies should also be considered. 70 For example, the random survival forest-based model developed by Segar et al, 67 which was validated in a diabetes population with high cardiovascular risk, require further validation in a general setting with lower-risk individuals with Type 2 diabetes. Likewise, support vector machine classifier developed by Good et al would benefit from further studies to determine the cost-effectiveness of utilizing urinary proteomics (which is more expensive than standard urine albumin tests) as predictors in clinical practice. The overall reporting quality was not standardized across studies, where details such as inclusion and exclusion criteria, method of measure of outcomes, and relevant performance measures were omitted in several studies. In view of the inconsistencies in reporting across studies, future developers of prediction models should consider adopting the reporting guidelines recommended by TRIPOD. 31 All development studies should also perform internal validation with resampling methods such as bootstrap, to quantify model overfitting and optimism. 34 Based on the findings from this review, future researchers may wish to consider the use of random forest algorithms either as the primary prediction model or as a comparison model during evaluation. Another ensemble method‚Äîextreme gradient boosting (XGBoost)‚Äîwhich was not covered in this review has also shown good prediction performance and can be explored in future studies. 71 It is important to recognize that the prediction performance of ML models is heavily dependent on the choice of data (for training and testing) and the tuning of model parameters. For example, class imbalance due to small minority class and poor-quality data sets can affect prediction accuracy. 72 Consequently, fair evaluation and comparisons can only be made through standardized benchmark testing with fixed data sets. We propose for data-sharing via open-access data sets to be made available to researchers for external validation of their prediction models. Future studies could also look at standardizing the various outcome definitions for diabetes complications to allow for more objective comparisons of prediction models across different studies. Finally, to facilitate the clinical translation of models, it is important to select predictors that can be readily obtained in clinical practice (eg, demographics and routine investigations such as fasting blood glucose) and to ensure that ML model predictions can be easily interpreted."
2023,Machine learning for post-acute pancreatitis diabetes mellitus prediction and personalized treatment recommendations,"Post-acute pancreatitis diabetes mellitus (PPDM-A) is the main component of pancreatic exocrine diabetes mellitus. Timely diagnosis of PPDM-A improves patient outcomes and the mitigation of burdens and costs. We aimed to determine risk factors prospectively and predictors of PPDM-A in China, focusing on giving personalized treatment recommendations. Here, we identify and evaluate the best set of predictors of PPDM-A prospectively using retrospective data from 820 patients with acute pancreatitis at four centers by machine learning approaches. We used the L1 regularized logistic regression model to diagnose early PPDM-A via nine clinical variables identified as the best predictors. The model performed well, obtaining the best AUC‚Äâ=‚Äâ0.819 and F1‚Äâ=‚Äâ0.357 in the test set. We interpreted and personalized the model through nomograms and Shapley values. Our model can accurately predict the occurrence of PPDM-A based on just nine clinical pieces of information and allows for early intervention in potential PPDM-A patients through personalized analysis. Future retrospective and prospective studies with multicentre, large sample populations are needed to assess the actual clinical value of the model.","PPDM-A is the most common sequela of pancreatitis11,17,18, and is characterized by poorer glycaemic control, a higher risk of developing cancer, and a higher risk of mortality10,19‚Äì21. However, the pathogenesis of diabetes secondary to acute pancreatitis is convoluted, which makes early clinical identification challenging. In addition, there is still no good classification model to predict PPDM-A in advance. Our feature contribution analysis prompted us to try to build a simpler predictive model based on a minimum number of the most influential features. To this end, we could fully evaluate the model‚Äôs performance using only nine pieces of information obtained about the patient. This study examined the ability to use nine clinical features to predict PPDM-A, leading to early intervention and effective PPDM-A screening. Our results suggest that clinical features can accurately predict the risk of PPDM-A after the onset of acute pancreatitis, although none of the nine clinical features we included directly reflected islet cell function. The findings reveal that indicators related to pancreatic injury (APFC, PPC, ANC, WON, amylase) affected the predicted outcome during the feature selection process, consistent with previous studies22,23. However, growing evidence compels a reconsideration of the dogma: ‚ÄúŒ≤-cell destruction is the only underlying mechanism of diabetes after acute pancreatitis‚Äù. Our study reveals that age, BMI, metabolic status, and comorbidities play different roles in individuals and may lead to opposite outcomes. It may be due to the mutual influence of organs on each other in the case of imbalanced glucose metabolism24‚Äì26. We assessed the characteristics that had the most profound impact on the model's predictions by Shapley value. We found that admission glucose, obesity (BMI‚Äâ>‚Äâ28 kg/m2), and HDL-C‚Äâ<‚Äâ1.03 mmol /l were the three factors that had the most significant impact on the outcome, and this result is consistent with the results of feature extraction. Prior studies also have demonstrated that hyperglycemia during hospitalization of acute critical illness is associated with emergent diabetes and identifying patients for subsequent diabetes screening. In a Scottish retrospective cohort study, 2.3% of patients with an emergency admission to a hospital without previously known diabetes were newly diagnosed with diabetes within 3-years27. In a nationwide national cohort of consecutive patients with acute myocardial infarction without known diabetes, hyperglycemia at admission was significantly associated with subsequent diabetes (odds ratio: 2.56; 95% CI 2.15‚Äì3.06)28. Furthermore, changes in lipid metabolism and abnormal distribution of abdominal adipose tissue are significantly associated with PPDM-A. Our work has several clinical applications. Firstly, it can facilitate early intervention in patients at high risk of diabetes. Early intervention for the development of diabetes is not currently studied. However, based on the health management knowledge of type 2 diabetes29‚Äì32, we can assume that a combination of diet and exercise can significantly decrease the incidence of diabetes. Due to the low prevalence of PPDM-A, early analysis of the effectiveness of prevention strategies can present some challenges. Our model can identify and recruit people at high risk of developing PPDM-A above 70%. Therefore, the current study paves the way for future randomized controlled trials to investigate further the effectiveness of using the model for early prediction of PPDM-A and possible prevention interventions. Another influential application is to help construct effective screening methods for PPDM-A. The prevalence of PPDM-A can already be confirmed considerably by admission glucose, BMI metrics, and HDL-C at the onset of acute pancreatitis. This staged risk assessment model can be used in subsequent studies to construct more rational design protocols for prospective studies of PPDM-A. Finally, by using the Sharpely Value, we can predict the likelihood of PPDM-A occurring in patients and identify key causative factors that can be targeted to give personalized treatment recommendations."
2023,Machine learning models for prediction of invasion Klebsiella pneumoniae liver abscess syndrome in diabetes mellitus: a singled centered retrospective study,"Objective This study aimed to develop and validate a machine learning algorithm-based model for predicting invasive Klebsiella pneumoniae liver abscess syndrome(IKPLAS) in diabetes mellitus and compare the performance of different models. Methods The clinical signs and data on the admission of 213 diabetic patients with Klebsiella pneumoniae liver abscesses were collected as variables. The optimal feature variables were screened out, and then Artificial Neural Network, Support Vector Machine, Logistic Regression, Random Forest, K-Nearest Neighbor, Decision Tree, and XGBoost models were established. Finally, the model's prediction performance was evaluated by the ROC curve, sensitivity (recall), specificity, accuracy, precision, F1-score, Average Precision, calibration curve, and DCA curve. Results Four features of hemoglobin, platelet, D-dimer, and SOFA score were screened by the recursive elimination method, and seven prediction models were established based on these variables. The AUC (0.969), F1-Score(0.737), Sensitivity(0.875) and AP(0.890) of the SVM model were the highest among the seven models. The KNN model showed the highest specificity (1.000). Except that the XGB and DT models over-estimates the occurrence of IKPLAS risk, the other models' calibration curves are a good fit with the actual observed results. Decision Curve Analysis showed that when the risk threshold was between 0.4 and 0.8, the net rate of intervention of the SVM model was significantly higher than that of other models. In the feature importance ranking, the SOFA score impacted the model significantly. Conclusion An effective prediction model of invasion Klebsiella pneumoniae liver abscess syndrome in diabetes mellitus could be established by a machine learning algorithm, which had potential application value.","The high incidence of IKPLAS is mainly in the Asian population, which may be related to the fact that the Asian population is more likely to colonize the intestine with K1/K2 serotype Klebsiella pneumoniae [29, 30]. Diabetes is considered a significant risk factor for IKPLAS, and up to 63% of patients with a bacterial liver abscess in Taiwan have diabetes. This may be related to the impaired phagocytosis of K1/K2 Klebsiella pneumoniae in diabetic patients [31] and the more excellent vascular permeability in diabetic patients, which is conducive to bacterial invasion [11]. The above two serotypes of Klebsiella pneumoniae are also highly virulent Klebsiella pneumoniae, which show high viscosity in the String test [9]. Although the highly virulent Klebsiella pneumoniae is sensitive to most antibiotics, patients often have a poor prognosis if they are not recognized and treated early [32]. This study screened four characteristic variables: hemoglobin, platelets, D-dimer, and SOFA score. We interpreted the importance of the model characteristic variables by using the SHAP package, in which the SOFA score ranked first among all four models. The SOFA score is a scoring system that measures the degree of impairment of significant organ function in patients with sepsis or suspected sepsis to determine prognosis [33]. Several studies have confirmed its predictive value in the prognosis of infected patients [34, 35]. This study also suggests that the SOFA score is a significant predictor of diabetes complicated by IKPLAS. As can be seen from the SHAP plot, the higher the SOFA score, the greater the risk of progression to IKPLAS. Although the pathogenesis of IKPLAS is currently unclear, the study by Chen-Guang Zhang et al. shows that most diabetic patients with IKPLAS are prone to sepsis [11]. Blood-borne transmission may be one of the more important ways. In the feature importance ranking, platelets' influence on SVM model ranked second.Jai Hoon Yoon et al. showed that thrombocytopenia is an independent risk factor for invasive syndrome in diabetic patients with Klebsiella pneumoniae liver abscess [10]. This is also consistent with the conclusions about platelets in the SVM model established in this study. The mechanism of platelet reduction in diabetes combined with IKPLAS may be that when the body is infected, platelets are stimulated and activated to participate in the body's inflammatory response by inducing the expression of membrane proteins and the production of mediators and play the role of anti-infection and pathogen removal. Activated platelets produce and release pro-inflammatory, anti-inflammatory, chemokines, antimicrobial, and other mediators to regulate the body's innate immune or adaptive immune response [36]. The interaction between platelets and pathogens or their products, endothelial cells, and immune cells promotes endothelial cell damage and leukocyte activation. As a result, the adhesion of platelets to it is enhanced, platelets are continuously activated in the circulation, and the body continuously produces anti-platelet antibodies and macrophage-colony stimulating factors, which accelerates the destruction and consumption of platelets [37]. The SHAP plot shows that hemoglobin is the third most important characteristic variable after the SOFA score, and the lower its value, the higher the risk of progression to IKPLAS. It has been shown that hemoglobin can be an indicator to assess the severity of the disease in infected patients, probably due to a systemic inflammatory response leading to decreased erythropoiesis, increased destruction of erythrocytes due to hemolysis, and hemorrhage, which leads to a reduced ability of blood to transport oxygen and carbon dioxide and insufficient oxygen supply to the body, resulting in multi-organ damage [38]. D-dimer is a specific molecular marker for secondary hyperfibrinolysis in vivo and is an effective indicator to reflect the coagulation state of the body. The coagulation and fibrinolytic systems are usually closely linked to the development of inflammation. Infection can lead to damage of vascular endothelial cells and alveolar epithelial cells, which stimulates the coagulation system, resulting in impairment of coagulation function and abnormal coagulation indexes in patients, further aggravated by elevated D-dimer along with infection [39, 40]. The above two promote each other, forming a vicious circle. The autoimmune function of diabetic patients is weakened, and the inflammatory response is enhanced after infection. Patients with diabetes complicated with IKPLAS can have noticeable D-dimer changes in the early stage. In the SVM model, D-dimer was positively associated with the risk of developing diabetes with IKPLAS, which is consistent with the above findings. In the field of IKPLAS, more studies are focused on the risk factors of IKPLAS.The study by Shixiao Li et al. [41] showed that patients with IKPLAS were more likely to develop chronic renal insufficiency, thrombocytopenia, and increased total bilirubin than patients with non-IKPLAS. Hairui Wang et al. [42]. A logistic regression prediction model was used to predict the incidence of IKPLAS by incorporating clinical and CT features, with an AUC value of 0.842 in the validation set, and did not compare other prediction models.Unlike many studies, we first used seven machine learning models for prediction. Through parameter adjustment and verification, the SVM model with the best performance was selected, with an AUC value of 0.969 and an AP value of 0.890, indicating that it was a reliable IKPLAS prediction model. At the same time, the variables included in this model are clinical indicators, which are easy to collect and can be used by clinicians to conveniently judge the possibility of IKPLAS in patients with diabetes mellitus complicated with Klebsiella pneumoniae liver abscess. Machine learning algorithms can build complex models that perform satisfactorily enough when the amount of data is sufficient. However, in specific applications, the amount of data is often insufficient, so it is essential to analyze these machine learning algorithms and obtain good results with relatively small sample sizes. In this study, the Power analysis was satisfied by calculating a power value of‚Äâ>‚Äâ0.80, although we only used a small data set of 213 patients. The main reason for the excellent performance of the SVM model in this study is that it is a nonlinear learner that is more suitable for small samples, can ideally separate samples, and has better generalization. There are still some limitations in this study. First, this is a single-center regression study, and some potential biases cannot be avoided. Secondly, for machine learning, the sample size of this study is insufficient. In order to further improve the accuracy of the model, we will collect more clinical data and further optimize the parameters."
2023,Prediction of gestational diabetes mellitus in Asian women using machine learning algorithms,"This study developed a machine learning algorithm to predict gestational diabetes mellitus (GDM) using retrospective data from 34,387 pregnancies in multi-centers of South Korea. Variables were collected at baseline, E0 (until 10 weeks‚Äô gestation), E1 (11‚Äì13 weeks‚Äô gestation) and M1 (14‚Äì24 weeks‚Äô gestation). The data set was randomly divided into training and test sets (7:3 ratio) to compare the performances of light gradient boosting machine (LGBM) and extreme gradient boosting (XGBoost) algorithms, with a full set of variables (original). A prediction model with the whole cohort achieved area under the receiver operating characteristics curve (AUC) and area under the precision-recall curve (AUPR) values of 0.711 and 0.246 at baseline, 0.720 and 0.256 at E0, 0.721 and 0.262 at E1, and 0.804 and 0.442 at M1, respectively. Then comparison of three models with different variable sets were performed: [a] variables from clinical guidelines; [b] selected variables from Shapley additive explanations (SHAP) values; and [c] Boruta algorithms. Based on model [c] with the least variables and similar or better performance than the other models, simple questionnaires were developed. The combined use of maternal factors and laboratory data could effectively predict individual risk of GDM using a machine learning model.","Principal findings In this study, we developed a machine learning algorithm for prediction of GDM in Asian women, especially Korean women, according to gestational period. The XGBoost algorithm displayed better performance than the LGBM algorithm in most cohorts and at most time points. After analyzing the performance of the machine learning model with original variables, we developed three models with simplified features for clinical application. At baseline, the model with GDM risk factors recommended by ACOG displayed the lowest performance for the whole cohort and subcohorts. Although the performance of the models employing SHAP values and the Boruta algorithm was similar at each time point, the model with variables determined by the Boruta algorithm was selected for clinical application, because the number of features was less than in the model using SHAP values. Finally, we developed questionnaires for clinical application at baseline, at E0, and at M1. Because the first trimester maternal serum aneuploidy screening markers, PAPP-A and HCG, which were added as variables in E1, did not improve the prediction performance for GDM, we set the three time points for prediction as baseline, E0, and M1. As expected, the prediction performance for GDM in the M1 period, which included the results of the 50-g OGTT and HbA1C levels, displayed significant improvement, with the highest SHAP importance of these two variables. Measurement of HbA1C is not included in routine screening tests during pregnancy. However, in South Korea abdominal obesity, assessed using waist circumference in women of 20‚Äì49 years old, has increased from 9% in 2013 to 12.2% in 202134. In 2020, the prevalence of diabetes and prediabetes was reported as 14.3% and 22.5% in women of 30‚Äì49 years old35. Although the high SHAP importance of HbA1C might be associated with its measurement in a limited number of women, routine screening and insurance cover of HbA1C measurements need to be considered in pregnant women and/or further studies of the criteria for pregnant women who require HbA1C measurement are required. Several studies have attempted to use traditional statistical methods to predict GDM, based on risk factors33,34, but such models have not yet been employed clinically. In recent years, there have been attempts to achieve the same goal using cutting-edge, machine learning technology22,36. Some studies, like this one, have focused on predicting GDM using early pregnancy information, and the predictive power has been reflected by an AUC of 0.7‚Äì0.937‚Äì41. Although these studies included subjects from various racial backgrounds, including Asians, there was a limited number of Asian participants, and specific studies focusing on Asian women, particularly Korean women, were scarce. Therefore, the current study is significant, as GDM varies greatly across ethnicities and geographical regions, and is particularly influenced by specific regional environments41. Some studies have evaluated additional biomarkers42,43 and genetics44‚Äì46, in addition to the routine data collected during antenatal care. In this study, only the basic information and laboratory tests collected during routine antenatal care were used as variables, yet the machine learning models still demonstrated moderate to high performance in early and mid-pregnancy, and have the advantage of being cost-effective. Strengths and limitations Since machine learning methods are continuously evolving, numerous types of new machine learning algorithms are being developed. In this study, we used two gradient boosting algorithms. The LGBM has demonstrated good performance with bioinformatics tasks47,48, and XGBoost is fast to run and scalable, allows parallel computing, and solves many scientific problems accurately27,28,49. Following the development of a prediction model using the XGBoost algorithm with all variables included, we extracted the variables with high SHAP values or identified by the Boruta algorithm. The final simplified prediction model, which utilizes the key variables identified by the Boruta algorithm, may be more clinically practical. One limitation is that this is a retrospective study and we conducted internal validation only, in the test set. For this reason, some data are missing and there may be bias because some tests were not performed in all populations. However, this study is based on data collected from seven centers that use the same electronic health record system and that are located in various geographical locations in Korea. Thus, our study has the strength of including various regional characteristics. In order to overcome any limitations of retrospective data, prospective cohorts for validation are currently being registered. In particular, prospective data are also being collected for the top 40 variables with high importance in SHAP value, in addition to the abbreviated variables adopted from the Boruta algorithm in this analysis. Lastly, this study evaluated the model performance not only in the whole cohort, but also in subcohorts of nulliparous and multiparous women, to improve the precision in each cohort. Our findings are predicted to be a cornerstone for developing a better algorithm and identify possible future research to validate the algorithm developed in the current study."
2023,Machine Learning as a Support for the Diagnosis of Type 2 Diabetes,"Diabetes is a chronic, metabolic disease characterized by high blood sugar levels. Among the main types of diabetes, type 2 is the most common. Early diagnosis and treatment can prevent or delay the onset of complications. Previous studies examined the application of machine learning techniques for prediction of the pathology, and here an artificial neural network shows very promising results as a possible valuable aid in the management and prevention of diabetes. Additionally, its superior ability for long-term predictions makes it an ideal choice for this field of study. We utilized machine learning methods to uncover previously undiscovered associations between an individual‚Äôs health status and the development of type 2 diabetes, with the goal of accurately predicting its onset or determining the individual‚Äôs risk level. Our study employed a binary classifier, trained on scratch, to identify potential nonlinear relationships between the onset of type 2 diabetes and a set of parameters obtained from patient measurements. Three datasets were utilized, i.e., the National Center for Health Statistics‚Äô (NHANES) biennial survey, MIMIC-III and MIMIC-IV. These datasets were then combined to create a single dataset with the same number of individuals with and without type 2 diabetes. Since the dataset was balanced, the primary evaluation metric for the model was accuracy. The outcomes of this study were encouraging, with the model achieving accuracy levels of up to 86% and a ROC AUC value of 0.934. Further investigation is needed to improve the reliability of the model by considering multiple measurements from the same patient over time.","Many efforts are oriented towards improvements in diabetes prevention, diagnosis, and care. Applications of AI methods are the most advanced approach based on computational resources. Data obtained by clinical studies should be opportunely integrated within AI approaches, as well as information from investigations at the molecular and cellular levels. As an example, the role of parameters used in our work as features is the object of studies reported in the literature [30,31,32,33,34,35], and novel biomarkers for the evaluation of diabetes and diabetes-related complications could be added in the future, as evidenced by studies on the role of erythrocytes [36]. Since the numerousness of the data is a crucial point in representing a given phenomenon, our work has focused on being able to construct a dataset with large, high-quality data. A well-designed dataset is essential for the success of training and evaluating neural networks, as the quality and representativeness of the data will significantly impact the performance of the network. We used three public datasets to extract data, to introduce heterogeneity into the data. Data extracted were preprocessed to remove data with missing values for the features of interest, obtaining a final dataset of 13,687 individuals, i.e., with a similar number of individuals with and without T2DM. In this way, we obtained a balanced dataset with suitable numerousness. The features were selected for the evidence of relationships to T2DM and for the ease of obtaining them, being measurements of common practice. We decided not to apply any data augmentation techniques, to preserve the quality of the information, which is fundamental for machine learning algorithms as they search for correlations within the data; all rows with implausible or missing values for at least one characteristic were eliminated. The use of a dataset of at least 13,000 samples represents the first step towards models with performances that increasingly represent their true capabilities on unknown data. The use of a neural network as a machine learning model was chosen due to its ability to approximate any function with a high degree of precision [37]. These models have been extensively used in the diagnosis of various diseases such as tuberculosis [38], malignant melanomas [39], and neuroblastomas [40]. Furthermore, neural networks have shown the potential in enhancing predictive accuracy when the connections between variables are nonlinear or unknown. Studies have demonstrated that neural networks exhibit superior long-term predictive capabilities in bariatric surgery patients [41] when compared to linear [42] and logistic regression models [43]. Our study suggests that the model applied to the dataset generated can predict the T2DM state with very high performances, based on features chosen by the scientific literature [30,31,32,33,34,35]. The most significant features were blood glucose level, HDL level in the blood, diastolic blood pressure, gender, and weight, while triglycerides, age, BMI, and systolic blood pressure resulted less significant. The ROC curve is a commonly used method for evaluating the performance of (binary) classification models. It uses a combination of the true positive rate (the percentage of correctly predicted positive examples, defined as recall) and the false positive rate (the percentage of incorrectly predicted negative examples) to obtain a snapshot of classification performance. By analyzing ROC curves, one assesses the classifier‚Äôs ability to discern between, for example, a healthy and a sick population, by calculating the area under the ROC curve (Area Under Curve (AUC)). The AUC value, between 0 and 1, is equivalent to the probability that the result of the classifier applied to an individual randomly drawn from the sick group is higher than that obtained by applying it to an individual randomly drawn from the healthy group. The higher the area under the ROC curve (AUC), the better the classifier. A classifier with an AUC higher than 0.5 is better than a random classifier. If the AUC is less than 0.5, then there is something wrong with the model. A perfect model would have an AUC of 1. ROC curves are widely used because they are relatively simple to understand, capture more than one aspect of classification (taking into account both false positives and false negatives), and allow for visual and low-effort comparisons of the performance of different types of models. In our study, the calculated ROC AUC value is 0.934. This value suggests a high predictive value for the method developed. To verify that the heterogeneity of ethnicity does not bias the final results, we performed an analysis for each ethnic group, obtaining very similar results (see Supplementary Material). As can be seen from Figure 4, the best single neural network (SGD) and the ensemble predictions appear to be calibrated, thus interpretable as probabilities of membership in one class or the other. This is also confirmed by the Brier score, whose extremely low values give us confidence about the accuracy of the predictions in probabilistic terms. The calibration of the models must be checked carefully because faulty calibration might result in bad decisions, and reporting both is crucial for prediction models [44]."
2009,A semi-supervised learning based method: Laplacian support vector machine used in diabetes disease diagnosis,"Pattern recognition methods could be of great help to disease diagnosis. In this study, a semi-supervised learning based method, Laplacian support vector machine (LapSVM), was used in diabetes diseases prediction. The diabetes disease dataset used in this article is Pima Indians diabetes dataset obtained from the UCI Repository of Machine Learning Databases and all patients in the dataset are females at least 21 years old of Pima Indian heritage. Firstly, LapSVM was trained as a fully-supervised learning classifier to predict diabetes dataset and 79.17% accuracy was obtained. Then, it was trained as a semi-supervised learning classifier and we got the prediction accuracy 82.29%. The obtained accuracy 82.29% is higher than other previous reports. The experiments led to the finding that LapSVM offers a very promising application, i.e., LapSVM can be used to solve a fully-supervised learning problem by solving a semi-supervised learning problem. The result suggests that LapSVM can be of great help to physicians in the process of diagnosing diabetes disease and it could be a very promising method in the situations where a lot of data are not class-labeled.","To evaluate the performance of LapSVM used in di- abetes diseases diagnosis, some experiments were done on Pima Indians diabetes dataset. All the results of the following experiments were obtained from the dataset mentioned above. In the experiments 384 samples were used in the training set (250 negative samples and 134 positive samples), and the remaining 384 samples were used in the testing set. LapSVM was trained as a fully supervised learning classifier to predict the test- ing set and 79.17% accuracy was obtained. A labeled sample xi has its label yi = {1,_1}. Just change its label yi = {0}, and then it can be used as an unla- beled sample. We respectively and randomly changed 30, 50, 80, 100, 130, 160, 190, 210, 240, 270, 310 sam- ples into unlabeled samples in the training set. Then we built the LapSVMs on the new training sets contain- ing different numbers of unlabeled samples and got the best Acc accuracy 82.29%. Table 2 gives the values of total accuracy, Specificity and Sensitivity by training LapSVM as semi-supervised classifier to predict dia- betes dataset with different numbers of unlabeled sam- ples in the training set. on Pima Indians diabetes dataset. All the results of the following experiments were obtained from the dataset mentioned above. In the experiments 384 samples were used in the training set (250 negative samples and 134 positive samples), and the remaining 384 samples were used in the testing set. LapSVM was trained as a fully-supervised learning classifier to predict the test- ing set and 79.17% accuracy was obtained. A labeled sample xi has its label yi = {1,_1}. Just change its label yi = {0}, and then it can be used as an unla- beled sample. We respectively and randomly changed 30, 50, 80, 100, 130, 160, 190, 210, 240, 270, 310 sam- ples into unlabeled samples in the training set. Then we built the LapSVMs on the new training sets contain- ing different numbers of unlabeled samples and got the best Acc accuracy 82.29%. Table 2 gives the values of total accuracy, Specificity and Sensitivity by training LapSVM as semi-supervised classifier to predict dia- betes dataset with different numbers of unlabeled sam- ples in the training set. Comparisons are made with the results cited and re- ported in (Polat et al., 2008) and given in Table 4. From the above we can see this study using LapSVM for diabetes disease diagnosis obtained the highest pre- diction accuracy 82.29%. The appearance of Fig. 1 led to a very useful finding is that the promising predic- tion results could be also obtained by the LapSVMs which were trained on the dataset with a larger part of unlabeled samples. When more than 310 sample in training set were treated as unlabeled samples, the prediction performance went decreasing. The results suggested that the prediction performance is concerned with the samples which could contribute more effects to the final classification decisions and it is not concerned with the number of unlabeled samples in the training set. In fact, just a few parts of samples in training set could contribute effects to the final classification deci- sion in many machine learning methods."
2008,Application of irregular and unbalanced data to predict diabetic nephropathy using visualization and feature selection methods,"Diabetic nephropathy is damage to the kidney caused by diabetes mellitus. It is a common complication and a leading cause of death in people with diabetes. However, the decline in kidney function varies considerably between patients and the determinants of diabetic nephropathy have not been clearly identified. Therefore, it is very difficult to predict the onset of diabetic nephropathy accurately with simple statistical approaches such as t-test or _2-test. To accurately predict the onset of diabetic nephropathy, we applied various machine learning techniques to irregular and unbalanced diabetes dataset, such as support vector machine (SVM) classification and feature selection methods. Visualization of the risk factors was another important objective to give physicians intuitive information on each patient's clinical pattern.","7.1. Data preparation and feature extraction It was difficult to acquire such a large electronic medical dataset, with 4321 patient follow-up records aged up to 10 years. Moreover, the original data were irregular and incomplete sequences, which made this study challenging. Therefore, we extracted 184 meta features for preprocessing, shrinking the number of records to 292; this step was essential for the machine learning application. To represent a record for each physical and laboratory examination (20 items), we employed the qualitative TA approach that calculates several fundamental statistical features such as minimum, maximum, mean and variance; we also estimated the trend of each item. These extracted features sufficed to describe the data and to distinguish the two groups of patients who did or did not develop diabetic nephropathy, because the classification performance with several feature selection methods showed promising results. However, our future work will compare the simple statistical abstraction with more complex abstraction with the knowledge-based TA procedure. Despite this reduction in data, there was unlikely to be any bias in sampling. In the preprocessing step, we selected all data records under the same conditions. Thus, they all needed the full 184 features, which means that the patients should have had at least two examinations for all 20 items before the final diagnosis. Moreover, there were no significant differences in age, sex, age at the onset of diabetes, or the duration of diabetes between the two groups. 7.2. Feature selection methods There were too many features to be trained compared with the number of records; this raises the issue of “curse of dimensionality”, which refers to the exponential growth of hypervolume as a function of dimensionality. To deal with this, we adopted several feature selection methods; some of which showed better results than the classifier using all 184 features. This fulfils the dictum of Occam's razor in that the fewer assumptions are made to explain a phenomenon, the better it is. Using statistical analysis, we clarified that some features differed significantly different between the two groups. However, those features were not sufficient to distinguish the two groups because the classification performance using those features was poor compared with those with other feature selection methods. Statistical methods, such as Student's t-test, compare the means of groups and indicate if there is any probable difference between them. However, such statistical differences could not always guarantee linear or non-linear separable values for each group of patients, so it was hard to predict diabetic nephropathy using a statistical feature selection. Filter methods such ReliefF have advantages in computation because they do not interact with classifiers, which is why they have been used for simple approaches. By contrast, the wrapper and embedded methods consider classifier design and are thus computationally expensive. However, these tactics – sensitivity analysis, SVM–RFE and nomogram-RFE – showed better performances than ReliefF. 7.3. Classification methods The failure of conventional LR here could have arisen from the large number of features. The preprocessing step might be another source of this failure, as we extracted these features from irregular sequential datasets and they must have had high correlations with each other (i.e., multicolinearity). With every feature selection method used in this study, SVM classification was superior to ridge LR in terms of the AUC. However, SVM classification using cost-sensitive learning gave almost the same results as the equal cost learning method. Cost-sensitive learning moves the separating hyperplane away to the minority class data; this is very similar to the bias variation scheme, in which the user can alter the decision threshold using bias. Moreover, threshold variation does not related with the AUC of the ROC curve. Therefore, the AUC may depend mostly on the tuning of other parameters, rather than the penalty to the error of the minority class data. 7.4. Considerations of the VRIFA system LR is used widely in medicine because it is able to describe feature ranking by an odds ratio and it can give intuitive information to medical practitioners. However, it is very difficult to interpret the results using odds ratio when independent variables (input features) have continuous values. Therefore, ridge LR made little use of this advantage, because the features used in this study all had continuous values except for one feature: sex. VRIFA, a visualization system using a nomogram in SVM, has been developed as a prototype. It gives intuitive visualization of the effect of each feature and a probabilistic output. Physicians can benefit from it for predicting diabetic nephropathy and can analyze the effects of the features. Therefore, it may be very useful to help develop effective treatment strategies and guide patients in choosing a life style. In addition to its graphical output, we took advantage of VRIFA for a feature selection method (nomogram-RFE) using the dynamic ranges of features. In this application, nomogram-RFE produced a value of 0.969 of the AUC using 39 features, as did the other wrapper and embedded methods. 7.5. Clinical considerations The features selected by our feature selection methods were not always concordant with statistically significant features. Some of the selected features in the VRIFA showed unexpected tendencies that are contrary to common medical thoughts: for example, that high blood pressure and a high BMI might be associated with diabetic nephropathy. However, these features were not significantly different between the two groups of patients. A possible explanation of the phenomenon is that the best classifiers used linear functions and thus there exist linear relationships among the features. For example, feature A could be important only if it is used with feature B in a linear SVM classifier. These relationships cannot be identified by t-test, as it does not take into account of the linear relationship. On the other hand, the statistically significant features showed the same tendencies as the visualization output. The patients with diabetic nephropathy already had higher values than the unaffected patients in WBC counts and microalbumin values, which is consistent with previous researches that are described in Section 1. In particular, frequent high microalbumin values before the outbreak of diabetic nephropathy suggests a possible demand for lowering of the diagnostic threshold for microalbumin for such patients. The start of diabetic nephropathy does not depend on some particular features, but on a complex interrelationship involving many. However, physicians could use this VRIFA system to estimate a patient's overall probability of having diabetic nephropathy and easily find the most important risk factors. Early stage of diabetic nephropathy is reversible, meaning that a patient who does not develop overt albuminuria (over 200 _g/min) could revert to normal kidney function if treated appropriately. Therefore, early diagnosis of this disease is very important and this study could be an immediate option for this purpose. When analyzing the time interval of prediction, our proposed method used average 5-year follow-up data and predicted diabetic nephropathy about 2–3 months before the actual diagnosis. The limitation of this study is that it did not deal with medication information, for example the use of insulin, oral agents, or antihypertensive drugs. There are still difficulties in including such information. Therefore, the concept of prediction is becoming increasingly difficult to pursue because many patients are treated with anti-hypertensive drugs and other types of interventions when microalbuminuria is diagnosed; such measures often return the patient's albumin excretion to normal [35], [36]. This problem may require another challenging data mining task, for example ontology and text mining. Future work will include the medication information and more data records to support the existing models."
2013,"Predictive models to assess risk of type 2 diabetes, hypertension and comorbidity: machine-learning algorithms and validation using national health data from Kuwait—a cohort study","Objective We build classification models and risk assessment tools for diabetes, hypertension and comorbidity using machine-learning algorithms on data from Kuwait. We model the increased proneness in diabetic patients to develop hypertension and vice versa. We ascertain the importance of ethnicity (and natives vs expatriate migrants) and of using regional data in risk assessment. Design Retrospective cohort study. Four machine-learning techniques were used: logistic regression, k-nearest neighbours (k-NN), multifactor dimensionality reduction and support vector machines. The study uses fivefold cross validation to obtain generalisation accuracies and errors. Setting Kuwait Health Network (KHN) that integrates data from primary health centres and hospitals in Kuwait. Participants 270_172 hospital visitors (of which, 89_858 are diabetic, 58_745 hypertensive and 30_522 comorbid) comprising Kuwaiti natives, Asian and Arab expatriates. Outcome measures Incident type 2 diabetes, hypertension and comorbidity. Results Classification accuracies of >85% (for diabetes) and >90% (for hypertension) are achieved using only simple non-laboratory-based parameters. Risk assessment tools based on k-NN classification models are able to assign ‘high’ risk to 75% of diabetic patients and to 94% of hypertensive patients. Only 5% of diabetic patients are seen assigned ‘low’ risk. Asian-specific models and assessments perform even better. Pathological conditions of diabetes in the general population or in hypertensive population and those of hypertension are modelled. Two-stage aggregate classification models and risk assessment tools, built combining both the component models on diabetes (or on hypertension), perform better than individual models. Conclusions Data on diabetes, hypertension and comorbidity from the cosmopolitan State of Kuwait are available for the first time. This enabled us to apply four different case–control models to assess risks. These tools aid in the preliminary non-intrusive assessment of the population. Ethnicity is seen significant to the predictive models. Risk assessments need to be developed using regional data as we demonstrate the applicability of the American Diabetes Association online calculator on data from Kuwait. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits use, distribution, and reproduction in any medium, provided the original work is properly cited, the use is non commercial and is otherwise in compliance with the license.","The applicability of machine-learning techniques to differentiate type 2 diabetics from non-diabetic population and hypertensive patients from non-hypertensive ones is examined. The models are trained with data on non-intrusive basic parameters from the nationwide Kuwait Health Network on diabetes and hypertension. Classification accuracy, which measures the proportion of true results, is used as measure of the performance of each of the models. Accuracy values of >85% for correctly classifying diabetics from non-diabetics, and of >90% for correctly classifying hypertensive from non-hypertensive population are possible with the classification models built using the SVM and k-NN. The developed k-NN classification models are adapted to build risk assessment tools that output ‘low’ risk, ‘borderline’ risk and ‘high’ risk. Up to 75% of diabetics are being grouped into ‘high’ risk, and as few as 5% of non-diabetic patients are grouped into ‘high’ risk category. With the Asian ethnicity-specific tool, it is even better with 88.4% of the diabetic patients grouped as ‘high’ risk. Up to 94% of the hypertensive patients are grouped into ‘high’ risk by the ethnicity-independent tools; with the Asian ethnicity-specific tool, it is even better with 97% of hypertensive patients being grouped as ‘high’ risk. Different pathology situations are modelled, namely diabetes in the general population (irrespective of the diagnosis for hypertension), diabetes in the hypertensive population, hypertension in the general population (irrespective of the diagnosis for diabetes) and hypertension in the diabetic population. Two-stage aggregate classification models, built combining both the models on diabetes or both the models on hypertension, perform far better than the individual models. Ethnicity-specific models and risk assessment tools are built using either Kuwaiti natives or Asian expatriates; the models that are specific to Asian expatriates are doing better than those specific to Kuwaiti natives. An examination of the performance of the ADA online risk assessment tool on data from Kuwait (natives and Asian expatriates) indicates that the ADA tool performs almost in a random manner in distinguishing diabetics from non-diabetics in Kuwait. This implies that it is important to build ‘local’ or ‘regional’ assessment tools using local data. LR models for diabetes identify hypertension diagnosis and family history of hypertension as significant predictors; in a similar fashion, the models for hypertension pick diabetes diagnosis and family history of diabetes as significant predictors. This is in agreement with the notion that disposition to diabetes increases the proneness to hypertension and vice versa. Implications of using the developed prediction models in medical practice In this paper, we show that predictive models built using basic non-intrusive data are able to identify patients at high risk for diabetes and hypertension. This becomes useful when applied in a public health setting. It would be advantageous to use the tool as a preliminary step to identify patients at high risk and to direct them for treatment (and research) purposes. These models can also be made available online, where concerned individuals can check their risk at home by answering simple questions such as their ethnicity, BMI and family history of diabetes. Those with higher risk can be advised to contact a medical professional, while lower risk patients can be advised of simple lifestyle changes. Up to 20–24% of Kuwaiti non-diabetic patients are identified as ‘borderline’ risk with our model. Without publicly available risk assessment tools, these patients would go unnoticed. In the future, should more robust biochemical data be available, more advanced models can be built as a second step in our study. Those identified as high risk from the basic models could be invited to enter biomarker values for a more detailed assessment. Comparisons with other studies Most of the available classification models and risk assessment tools for diabetes are based on LR.7 The presented study reports on the applicability of machine-learning approaches. Models based on SVMs and k-NN give consistently high classification accuracies. Prognostic measures (in terms of calibration and discrimination) help to evaluate validity of predictive models and to compare different published models. Discrimination describes the ability of the prediction model to distinguish patients at high risk of developing diabetes from those at low risk. We use the C-statistic to measure discrimination, and since continuous outputs are required to plot the ROC, we show discrimination values for LR and SVM only. On the other hand, calibration measures the ability of the model to correctly estimate the absolute risks,7 and we calculate it using the Hosmer-Lemeshow goodness of fit statistic25 for the LR (since calibration calculations require the output to be a probability). The discrimination C-statistic for the LR and SVM models (that we developed for diabetes in general population) are seen as 0.820 and 0.831, respectively. These values are in good comparison with those reported for similar published models (using basic non-intrusive parameters similar to the ones used by models presented in this study) that range from 0.74 to 0.84.7 The calibration p value for the presented LR model for diabetes in general population is evaluated as 0.135. A calibration p value of >0.05 means that the model is well calibrated, and a smaller value implies a poorly calibrated model. Strengths and limitations of the study The major strengths of this study are as follows: (1) for the first time in Kuwait, large amounts of health and medical data are available for research. Because of this, we have plenty of data to model the disorders of diabetes, hypertension and comorbidity. This translates into robust classification models and risk assessment tools that have little uncertainty. (2) Most of the classification models and risk assessment tools for diabetes are based on LR.7 The presented study reports on the applicability of machine-learning approaches. Models based on SVMs and k-NN give consistently high classification accuracies. The limitations of the study are as mentioned earlier under Data section. We further add that we considered only those patients with complete data for the predictors used in the models; it is possible that patients with missing data have different risk profiles as compared with patients included. However, the missing data are most often due to the reason that the integration of data by Kuwait Health Network is partial and ongoing."
2017,Machine Learning and Data Mining Methods in Diabetes Research,"The remarkable advances in biotechnology and health sciences have led to a significant production of data, such as high throughput genetic data and clinical information, generated from large Electronic Health Records (EHRs). To this end, application of machine learning and data mining methods in biosciences is presently, more than ever before, vital and indispensable in efforts to transform intelligently all available information into valuable knowledge. Diabetes mellitus (DM) is defined as a group of metabolic disorders exerting significant pressure on human health worldwide. Extensive research in all aspects of diabetes (diagnosis, etiopathophysiology, therapy, etc.) has led to the generation of huge amounts of data. The aim of the present study is to conduct a systematic review of the applications of machine learning, data mining techniques and tools in the field of diabetes research with respect to a) Prediction and Diagnosis, b) Diabetic Complications, c) Genetic Background and Environment, and e) Health Care and Management with the first category appearing to be the most popular. A wide range of machine learning algorithms were employed. In general, 85% of those used were characterized by supervised learning approaches and 15% by unsupervised ones, and more specifically, association rules. Support vector machines (SVM) arise as the most successful and widely used algorithm. Concerning the type of data, clinical datasets were mainly used. The title applications in the selected articles project the usefulness of extracting valuable knowledge leading to new hypotheses targeting deeper understanding and further investigation in DM.","In the present study, the recent literature was reviewed with respect to applications of machine learning and data mining methods in Diabetes research. The first sections describe briefly the two main research fields involved (machine learning, knowledge discovery in databases and Diabetes), pointing out the necessity of intelligent applications in improving the quality and effectiveness of decision making in DM. Following creation of the assembled article collection (for methodology details vide supra), each article was categorized accordingly in one of the title groups (descending number of papers), thus covering to a great extent significant diabetes research fields, i.e. Biomarker Prediction and Diagnosis in DM, Diabetic Complications, Drugs and Therapies, Genetic Background and Environment, and Health Care Management. The current articles were published in several scientific journals that deal with distinct and wide fields of interest, including bioinformatics, biomedical engineering and diabetes. In Fig. 4, the scientific journals are presented in line with their appearance in the present collection, whereas Fig. 3 depicts the number of articles published per year. The specific article categorization was carried out based on the content of the retrieved articles. The most popular category was the Biomarker Prediction and Diagnosis of DM, thematically revolving around efforts to discover and suggest novel biomarkers and finally predict key aspects of the disease, such as its onset. Since the undertaken research reflects a data-driven process, the arising gaps and limitations in machine learning research in DM are closely related to the availability of data. Clinical, diagnostic data and EHR are plentiful due to low cost of their retrieval, in contrast to other types of data, such as biological, which are more difficult and expensive to generate and therefore less available to the scientific community. That partially justifies the extensive research effort on specific topics, such as retinopathy. Moreover, there is complete lack of data concerning a) lifestyle and behavior, b) inheritance, and c) linkage with other pathophysiological conditions e.g. Alzheimer's disease. 6.1. Computational Insight Into Diabetes Research When it comes to machine learning and data mining, significant conclusions are drawn through the present detailed account. It is worth mentioning that the vast majority of the reported articles enhanced classification accuracy, above 80%, in the prediction of DM. With regard to the prediction task itself, almost all of the common known classification algorithms have been employed. However, the most commonly used ones are SVM, ANN, and DT. It should be mentioned that SVM rises as the most successful algorithm in both biological and clinical datasets in DM. A great deal of articles (~ 85%) used the supervised learning approaches, i.e. in classification and regression tasks. In the remaining 15%, association rules were employed mainly to study associations between biomarkers. More specifically, concerning the part dealing with the evaluation task, in all reported research reports, the identified subsets of biomarkers (features) were evaluated through appropriate procedures, such as splitting the dataset into train and test set or via cross-validation. By analogy, the same approaches have been followed in DM prediction. Worth emphasizing is the fact that in many studies, after the feature/biomarker selection, researchers have performed comparative analysis on different machine learning algorithms in order to assess their predictive performance and finally choose the most efficient one(s). To this end, this should be the baseline of practice in every study to be carried out, taking into account that several characteristics of the dataset, such as dimensionality, low number of instances compared to number of features or even the type of the dataset itself (genetic or clinical), can affect significantly the performance of the algorithm. Hence, an algorithm with the best performance in one dataset could easily have lower prediction accuracy compared to other algorithms in different datasets. Table 1 represents studies that compare more than five machine learning algorithms in various biological and clinical datasets. SVM exhibited the best performance with regard to classification accuracy or the Area Under the Curve (AUC). Moreover, many times in KDD, algorithms that produce interpretable results, are preferably used, although they are not necessarily state-of-the-art. The aforementioned fact explains, at least partially, the wide use of decision trees in the literature. The overall results project that a wide variety of algorithms and techniques are used in DM research. Obviously, different machine learning tasks are used in different scientific questions, such as prediction on DM or association among biomarkers. To this end, classification and regression techniques are used for prediction tasks, such as prediction of glucose levels and association rules in the case of dependencies between biomarkers. Interestingly, for each machine learning task, a variety of algorithms have been used in the literature. The reason behind that is likely the fact that the accuracy of an algorithm depends heavily on the type of data (dimensionality, origin and kind). Accordingly, a great effort in research relies on the preprocessing of data, such as feature selection and then various algorithms are applied to the processed data in order to identify the most successful one for the particular dataset. Furthermore, it is imperative for machine learning studies that a dataset be sufficiently large for the algorithm to be trained appropriately. Although biomedical sciences have entered the era of big data for several reasons, such as low cost of next generation sequencing or unified EHRs, datasets with great variability in size are very common in DM research. In that respect, what should be stressed out is the danger of a) producing low quality results, and b) concomitantly having the entire KDD process finally extract low quality of knowledge, when a small amount of data is employed. 6.2. Computational Interfacing With Diabetes Mellitus Potential gains of early detection of a disease, in this case DM, in addition to the assessment of possible risk factors, include a) significant prolongation and quality of life, pertaining to the reduction of severity and frequency of a disease state and/or prevention and delay of its complications, and b) reduction of health care cost, as a consequence of reduced care linked to hospitalization of patients. In this context, data mining and machine learning arise as a key process providing insight into possible relationships among molecules and conditions such as gene–gene, protein–protein, drug–drug, drug–disease or gene–disease, etc. From the perspective of DM, although there are several types of diabetes, the overall results suggest that the articles reviewed refer to T1D and T2D, with T2D representing the majority of the articles. A few articles refer to prediabetes and only one pertains to the metabolic syndrome, which is a term for metabolism-related pathophysiology. The types of data used in each case of the present collection were either clinical, genetic, electrochemical, chemical or medical. Only a few articles used clinical data in combination with genetic data. In addition, it is worth mentioning that the vast majority of the articles reviewed handled only clinical datasets. When it comes to prediction, the main biomarkers used involve anthropometric parameters, demographic characteristics, known risk factors, medical and drug history data, laboratory measurements, and epidemiological data. The most common biomarker seems to be blood glucose levels (HbA1c), as expected, since its detection is the basic step toward diagnosis and classification of a candidate diabetic patient. With regard to DM treatment, the articles associated with drugs and therapy cover several fields of interest that include a) medication prescriptions, b) dosage planning with emphasis on insulin administration, c) potential side-effects of medications non-related to the disease (e.g. statins), and d) prediction of personalized glycemic response following anti-diabetic medication. Only Shoombautong et al., in [119], deal with the discovery of novel anti-diabetic agents. Therefore, to our knowledge there is much work ahead to be done on drug and therapeutic protocol design as far as evaluation and data mining on already known blood glucose lowering factors, such as metformin. Concerning the genetic background in DM and environmental factors affecting the onset and progression of the disease, it is worth noting that the present account presents an evident gap in research on diabetes with respect to data mining and machine learning. The articles reviewed employ the HLA gene complex, in relation to T1D, whereas the rest of them attempt to predict associations of pleiotropic genes with DM. Interestingly, Lopes et al. tried to associate two known genes with DM, following wet lab validation of the extracted information [132]. Finally, although SNPs are one of the most common genetic markers in various research fields, in the present study only two articles utilized SNPs to predict DM. As more genes involved in the pathogenesis of diabetes are gradually identified, it will become easier to gain deeper understanding of the mechanisms responsible for the disease development and progression. That can lead to new insights into the genetic epidemiology of diabetes and nature of gene–gene and gene–environment interactions. Finally, Diabetic complications covered in the present study include nephropathy, Alzheimer's disease, diabetic foot, liver cancer, hypoglycemic events, heart disease, depression, and retinopathy. The majority of the articles deal with retinopathy. One plausible explanation, apart from the impact of the disease, could be the availability of data resources from routine clinical practice that allow information extraction."
2018,Machine Learning Methods to Predict Diabetes Complications,"One of the areas where Artificial Intelligence is having more impact is machine learning, which develops algorithms able to learn patterns and decision rules from data. Machine learning algorithms have been embedded into data mining pipelines, which can combine them with classical statistical strategies, to extract knowledge from data. Within the EU-funded MOSAIC project, a data mining pipeline has been used to derive a set of predictive models of type 2 diabetes mellitus (T2DM) complications based on electronic health record data of nearly one thousand patients. Such pipeline comprises clinical center profiling, predictive model targeting, predictive model construction and model validation. After having dealt with missing data by means of random forest (RF) and having applied suitable strategies to handle class imbalance, we have used Logistic Regression with stepwise feature selection to predict the onset of retinopathy, neuropathy, or nephropathy, at different time scenarios, at 3, 5, and 7 years from the first visit at the Hospital Center for Diabetes (not from the diagnosis). Considered variables are gender, age, time from diagnosis, body mass index (BMI), glycated hemoglobin (HbA1c), hypertension, and smoking habit. Final models, tailored in accordance with the complications, provided an accuracy up to 0.838. Different variables were selected for each complication and time scenario, leading to specialized models easy to translate to the clinical practice.","This work describes the application of a modern data mining pipeline, combining a variety of approaches to exploit clinical data to extract a risk calculator of microvascular T2DM complication. It provides a multivariate index of the patients’ conditions. AI-based strategies were used to handle missing data and to address class imbalance. Models were created considering different prediction horizons and validated by state-of-art data science principles. Finally, LR and nomograms was selected as the instrument to deliver the predictive models to the users. The developed pipeline allowed developing models tailored on the population characteristics, which are specific of the T2DM patients treated by the ICSM hospital. The LR model on the entire dataset, after RF imputation, identified individual risk factors for the onset of the three microvascular complications and their relative odds ratios. Hba1c, as the standard measure for blood glucose monitoring in diabetic patients, was found to be a risk factor for all complications. As the developed models take into account measurements at the first visit near the hospital, HbA1c might be affected by some bias due to poor metabolic control at the referral. However, this bias is mitigated by the very nature of the measure, which takes into account a 3-month period before the visit. In fact, HbA1c values mean (SD) of 62.42 (21.05) mmol/mol are comparable to the average values of the Italian T2DM patients.21,22 Duration of diabetes (T2DM) and BMI were found to be important risk factors for both retinopathy and neuropathy, while hypertension was found as a risk factor for both retinopathy and nephropathy. As regards of retinopathy, these results can be supported by other studies and literature reviews,23 where is shown that the main risk factors for retinopathy prevalence increasing are HbA1c and diabetes duration. Regarding nephropathy, a recent study24 applied a data mining framework to predict renal failure in T2DM on a time horizon of 5 years. The described models are based on a larger cohort and include albuminuria and creatinine values, which were not available in our analysis. The results in terms of metabolic control are comparable. Although AUC values are higher for nephropathy on a 5-year horizon, they are not significantly different from the 3-year ones, which we choose to deliver for clinical practice (as shown in table 3). the missed opportunity to include albumin-creatinine ratio indicators, which have been demonstrated to be cardiovascular risk factors,25-27 is one of the main limitations of the presented work. Models performances were evaluated in terms of MCC, which is instead dependent on the decisional threshold, which relates to how close the predicted outcome is to the actual outcome. MCC values were more informative when evaluating the impact of strategies to address the class imbalance problem: if no such strategy was adopted, the models assigned almost all examples to the majority class, leading to poor MCC results. While small differences are noticeable among resampling approaches, in general none of the proposed strategies contributed to significantly improve the AUC performances with respect to the baseline model nor achieved better MCC."
2017,Predicting diabetes mellitus using SMOTE and ensemble machine learning approach: The Henry Ford ExercIse Testing (FIT) project,"Machine learning is becoming a popular and important approach in the field of medical research. In this study, we investigate the relative performance of various machine learning methods such as Decision Tree, Naïve Bayes, Logistic Regression, Logistic Model Tree and Random Forests for predicting incident diabetes using medical records of cardiorespiratory fitness. In addition, we apply different techniques to uncover potential predictors of diabetes. This FIT project study used data of 32,555 patients who are free of any known coronary artery disease or heart failure who underwent clinician-referred exercise treadmill stress testing at Henry Ford Health Systems between 1991 and 2009 and had a complete 5-year follow-up. At the completion of the fifth year, 5,099 of those patients have developed diabetes. The dataset contained 62 attributes classified into four categories: demographic characteristics, disease history, medication use history, and stress test vital signs. We developed an Ensembling-based predictive model using 13 attributes that were selected based on their clinical importance, Multiple Linear Regression, and Information Gain Ranking methods. The negative effect of the imbalance class of the constructed model was handled by Synthetic Minority Oversampling Technique (SMOTE). The overall performance of the predictive model classifier was improved by the Ensemble machine learning approach using the Vote method with three Decision Trees (Naïve Bayes Tree, Random Forest, and Logistic Model Tree) and achieved high accuracy of prediction (AUC = 0.92). The study shows the potential of ensembling and SMOTE approaches for predicting incident diabetes using cardiorespiratory fitness data.","To the best of our knowledge, this is the first study for predicting incident diabetes using machine learning methods based on cardiorespiratory fitness data. This study take advantage of the unique opportunity provided by our access to a large and rich clinical research dataset of the FIT project. In this study, a combination of three decision tree models (Random Forest, NB Tree, and LMT) in the Ensembling “Vote” approach achieved a high accuracy prediction (AUC = 0.92) using 13 features. The features are age, resting heart rate, metabolic equivalent level, resting systolic blood pressure, resting diastolic blood pressure, sedentary lifestyle, black, obesity, hypertension, percentage of heart rate achieved, history of hyperlipidemia, use of aspirin medication and family history of premature coronary artery disease. With accelerating economic growth and changing lifestyles worldwide, it is important to evaluate and build predictive models for diabetes using common risk factors. Recently, machine learning methods have become of great interest and have been used by many scholars to build and compare models for predicting diseases including diabetes [20, 45]. For example, decision tree models have been widely used to predict diabetes [18] and experimental results showed that the weighted voting method not only improves the classification accuracy, but also has a strong generalization ability and universality [51, 52]. The prediction model developed by Habibi et. al. [4] used decision tree for screening T2DM which did not require laboratory tests for T2DM diagnosis. The prediction model is designed to identify T2DM patients and healthy people (AUC = 0.717) using 22,398 records. The model was built based on diagnosis variables defined by other studies as main predictor variables (age, Body Mass Index (BMI)) while sex, systolic and diastolic blood pressure, and family history of diabetes were found to be the highest risk factors. Three machine learning models (logistic regression, artificial neural network, and decision tree) were used by Meng et. al. [18] for predicting diabetes and pre-diabetes based on 12 risk factors and a dataset of 1,487 patients. The results obtained from the comparison among these three models was in terms of their accuracy, sensitivity, and specificity; the best accuracy achieved was by using the decision tree model (77.87%) followed by the logistic regression model (76.13%), and finally the ANN (73.23%). The increase of age, family history of diabetes, BMI, and preference for salty food increases a person’s risk of developing diabetes while education level and drinking coffee showed a negative relationship with the disease. Farran et al. [53] built a model to predict the incidents of diabetes, hypertension, and comorbidity through applying machine-learning algorithms on a dataset of 13,647,408 medical records for various ethnicities in Kuwait. The result of the classification accuracy for the four techniques was relatively high (80.7%) for Logistic Regression (LR), 78.6% for K-Nearest Neighbors (KNN), 78.30% for Multi-factor Dimensionality Reduction (MDR), 81.3% for Support Vector Machines (SVM), and 82% represents the result for the performance of all techniques collaboratively. The used models show that ethnicity is a significant factor for predicting diabetes. In general, machine learning methods can provide great support for healthcare systems in various ways such as managing the hospital resources, recognizing high-risk patients, ranking the hospital, and improving patient care [54]. Healthcare organizations should leverage the advantage provided by machine learning tools to reduce the expenses of diabetes incidents by preventing the occurrence of the disease; thus, improving the public health and the population in general. However, one of the biggest challenges of machine learning in healthcare is that of data quality and consistency. Small dataset size, low quality of the data, incomplete data, and the lack of standardizations and interoperability may negatively affect the ability of building models that provide effective prediction."
2017,Development and Validation of a Deep Learning System for Diabetic Retinopathy and Related Eye Diseases Using Retinal Images From Multiethnic Populations With Diabetes,"Importance: A deep learning system (DLS) is a machine learning technology with potential for screening diabetic retinopathy and related eye diseases. Objective: To evaluate the performance of a DLS in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, possible glaucoma, and age-related macular degeneration (AMD) in community and clinic-based multiethnic populations with diabetes. Design, setting, and participants: Diagnostic performance of a DLS for diabetic retinopathy and related eye diseases was evaluated using 494 661 retinal images. A DLS was trained for detecting diabetic retinopathy (using 76 370 images), possible glaucoma (125 189 images), and AMD (72 610 images), and performance of DLS was evaluated for detecting diabetic retinopathy (using 112 648 images), possible glaucoma (71 896 images), and AMD (35 948 images). Training of the DLS was completed in May 2016, and validation of the DLS was completed in May 2017 for detection of referable diabetic retinopathy (moderate nonproliferative diabetic retinopathy or worse) and vision-threatening diabetic retinopathy (severe nonproliferative diabetic retinopathy or worse) using a primary validation data set in the Singapore National Diabetic Retinopathy Screening Program and 10 multiethnic cohorts with diabetes. Exposures: Use of a deep learning system. Main outcomes and measures: Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity of the DLS with professional graders (retinal specialists, general ophthalmologists, trained graders, or optometrists) as the reference standard. Results: In the primary validation dataset (n = 14 880 patients; 71 896 images; mean [SD] age, 60.2 [2.2] years; 54.6% men), the prevalence of referable diabetic retinopathy was 3.0%; vision-threatening diabetic retinopathy, 0.6%; possible glaucoma, 0.1%; and AMD, 2.5%. The AUC of the DLS for referable diabetic retinopathy was 0.936 (95% CI, 0.925-0.943), sensitivity was 90.5% (95% CI, 87.3%-93.0%), and specificity was 91.6% (95% CI, 91.0%-92.2%). For vision-threatening diabetic retinopathy, AUC was 0.958 (95% CI, 0.956-0.961), sensitivity was 100% (95% CI, 94.1%-100.0%), and specificity was 91.1% (95% CI, 90.7%-91.4%). For possible glaucoma, AUC was 0.942 (95% CI, 0.929-0.954), sensitivity was 96.4% (95% CI, 81.7%-99.9%), and specificity was 87.2% (95% CI, 86.8%-87.5%). For AMD, AUC was 0.931 (95% CI, 0.928-0.935), sensitivity was 93.2% (95% CI, 91.1%-99.8%), and specificity was 88.7% (95% CI, 88.3%-89.0%). For referable diabetic retinopathy in the 10 additional datasets, AUC range was 0.889 to 0.983 (n = 40 752 images). Conclusions and relevance: In this evaluation of retinal images from multiethnic cohorts of patients with diabetes, the DLS had high sensitivity and specificity for identifying diabetic retinopathy and related eye diseases. Further research is necessary to evaluate the applicability of the DLS in health care settings and the utility of the DLS to improve vision outcomes.","In this evaluation of nearly half a million of images from multiethnic community, population-based and clinical datasets, the DLS had high sensitivity and specificity for identifying referable diabetic retinopathy and vision-threatening diabetic retinopathy, as well as for identifying related eye diseases, including referable possible glaucoma and referable age-related macular degeneration. The performance of the DLS was comparable and clinically acceptable to the current model based on assessment of retinal images by trained professional graders and showed consistency in 10 external validation datasets of multiple ethnicities and settings, using diverse reference standards in assessment of diabetic retinopathy by professional graders, optometrists, or retinal specialists. This study also examined how the DLS could be deployed in 2 common diabetic retinopathy screening models: a “fully-automated” screening model that showed clinically acceptable performance to detect all 3 conditions, useful in communities without any existing diabetic retinopathy screening programs; and a “semi-automated” model in which diabetic retinopathy screening programs using trained professional graders already exist, and the DLS could be incorporated. There have been previous studies of automated software for diabetic retinopathy screening; most recent ones used a DLS. Gulshan et al reported a DLS with high sensitivity and specificity (>90%) and an AUC of 0.99 for referable diabetic retinopathy using approximately 10_000 images retrieved from 2 publicly available databases (EyePAC-1 and Messidor-2). Similarly, Gargeya and Leng showed optimal DLS diagnostic performance in detecting any diabetic retinopathy using 2 other public databases (Messidor-2 and E-Ophtha). To facilitate translation, it is important to develop and test the DLS in clinical scenarios using diverse retinal images of varying quality from different camera types and in representative diabetic retinopathy screening populations. The current study therefore substantially added to other current studies. First, the DLS was trained to also detect other related eye diseases including referable possible glaucoma and referable AMD in addition to diabetic retinopathy. Second, the training and validation data sets were substantially larger (nearly 500_000 images) and included images from patients of diverse racial and ethnic groups (ie, darker fundus pigmentation in African American and Indian individuals to lighter fundus in white individuals). The DLS showed consistent diagnostic performance across images of varying quality and different camera types, and across patients with varying systemic glycemic control level. Third, primary validation of the DLS was conducted in an ongoing diabetic retinopathy screening program in which there were poorer quality images, including ungradable ones. This results in somewhat lower performance of the DLS (AUC, 0.936) than the system by Gulshan et al that used higher-quality images. Fourth, this study also had fewer cases of severe disease (eg, vision-threatening diabetic retinopathy, referable possible glaucoma, and referable AMD), but this is more representative of populations for routine diabetic retinopathy screening. To ensure no degradation in health outcomes, a threshold was set to ensure false-negative rates were no worse than human assessment by trained professional graders. Although the results suggest that professional nonmedical graders may outperform the DLS (with high specificity of 99% for referable diabetic retinopathy and vision-threatening diabetic retinopathy), given the very low marginal cost of the DLS, the low prevalence rate of the conditions in the target screening population (<5%), and equality in health outcomes, the DLS could be used with a semiautomated model in which first-line screening with the DLS is followed by human assessment for patients who test positive. This will allow increasing screening episodes with lower cost and no degradation in health outcomes."
2016,Machine-Learning-Based Prediction of a Missed Scheduled Clinical Appointment by Patients With Diabetes,"Background: About 10% of patients with diabetes discontinue treatment, resulting in the progression of diabetes-related complications and reduced quality of life. Objective: The objective was to predict a missed clinical appointment (MA), which can lead to discontinued treatment for diabetes patients. Methods: A machine-learning algorithm was used to build a logistic regression model for MA predictions, with L2-norm regularization used to avoid over-fitting and 10-fold cross validation used to evaluate prediction performance. Data associated with patient MAs were extracted from electronic medical records and classified into two groups: one related to patients' clinical condition (X1) and the other related to previous findings (X2). The records used were those of the University of Tokyo Hospital, and they included the history of 16 026 clinical appointments scheduled by 879 patients whose initial clinical visit had been made after January 1, 2004, who had diagnostic codes indicating diabetes, and whose HbA1c had been tested within 3 months after their initial visit. Records between April 1, 2011, and June 30, 2014, were inspected for a history of MAs. Results: The best predictor of MAs proved to be X1 + X2 (AUC = 0.958); precision and recall rates were, respectively, 0.757 and 0.659. Among all the appointment data, the day of the week when an appointment was made was most strongly associated with MA predictions (weight = 2.22). Conclusions: Our findings may provide information to help clinicians make timely interventions to avoid MAs.","Ours is the first study to use machine learning to build a model that can predict MAs most likely to result in discontinuation of treatment for diabetes by using EHR, although some groups have used machine learning for various other aspects of diabetes research.8-10 The accuracy of prediction was validated. Prediction Model’s Performance and Future Our model performed well in predicting MAs, with an AUC at 0.958—an AUC value over 0.9 is considered to be an excellent prediction score.11 This promises to make the model a powerful tool for showing clinicians the suitable timing for intervening to keep patients continuing hospital visits. Of course, earlier prediction of MAs is required to prevent discontinuation of treatment. We will need to improve our current model by adding new features such as changes of diabetes treatment over time and progression of diabetes. Furthermore, the quality of interaction perceived by the patient may be another factor determining whether the patient returned; we plan to evaluate this in a future model. If we can predict MAs early enough for clinicians to encourage diabetic patients to continue treatment, the number of MAs will decrease significantly, and diabetes care will be also improved. One of our authors found that “DialBetics,” the telemedicine diabetes self-management system that can automatically give advice on the basis of a diabetic patient’s input and registry data, led patients to improve their dietary habits.12,13 We will combine DialBetics with our model and investigate whether coordination of clinical appointments with our model more effectively motivates patients to keep clinical appointments. General Applicability Our model was evaluated with outpatient EHR from one hospital in Japan. To assess its general applicability, we must evaluate the model with patients at other hospitals in several different countries that have different demographics and regional characteristics. We will also evaluate our model with patients who suffer from other diseases, like asthma and other chronic diseases, that require similarly continual outpatient treatment, and we will investigate the differences in features. Design of Features in the Model The features we deemed possibly relevant to MAs (X2 group) rendered a higher prediction accuracy compared with those related to patients’ clinical condition (X1 group). This suggests that features derived from knowledge about and experience with the diabetes treatment of clinicians is more effective for improving accuracy in predicting MAs. Nevertheless, X1 is also valuable since use of both X1 and X2 resulted in a higher prediction accuracy. Therefore, in a future study, we will identify the most contributive features in X1 to construct a simpler model with fewer features. Machine Learning of Features’ Weight The highest prediction accuracy was obtained by the model constructed by machine learning without maximum-likelihood estimation but with L2 regularization using only the X1 group or both X1 and X2 groups. Since the number of features in these groups exceeds that of the training data, it carries a high risk of overtraining a part of the training data. We confirmed that L2 regularization reduced over-fitting well. The accuracy of the model that learned with L2 regularization was almost the same as that of the model constructed with only the X2 group using maximum-likelihood estimation because overfitting was effectively suppressed by regularization reducing the number of features to under 1% of the whole training data. The appointment records we used were possibly uneven because of records obtained from patients who made many appointments. We will consider the relationship between prediction accuracy and the uniformity of appointment records. Machine learning is generally applied to “bigger” data than we used in this study (16 026).14 The prediction accuracy will be improved by using more data because machine-learning generalization increases as the number of training data increases.15 SS-MIX2, which is currently being developed to standardize medical data stored in the EHR systems of hospitals, will enable us to use “big data” and improve the prediction accuracy of our model in the near future.16,17 How Features Contribute to MA Predictions Tables 5 and _and66 show the top five qualitative and quantitative features, respectively. These features were given the largest absolute weights in our trained model and thus contributed strongly to MA prediction. We found that features related to when and how appointments were made, rather than to patients’ clinical condition, influenced the accuracy in predicting MAs. It would seem that irregularly scheduled appointments are more apt to be missed. We examined the largest qualitative/quantitative features in detail. The largest qualitative feature was “Appointment made on a Sunday.” In all, 164 (about 1%) of total appointments were made on Sundays; 73 (44.5%) of those appointments were MAs. The percentage of MAs in the appointments made on Sunday was much higher than that of the total appointments (5.75%). Physicians do not usually make appointments on Sundays, so consultations on Sunday are very unlikely except for visits to the emergency room. This means that those 164 Sunday appointments were made for the patients who needed to have a follow-up visit and be examined by the physicians who examined them in the emergency room. It seems that some patients came on a Sunday because they had used up their medications: the prescription for their latest medicine of 39 of the 73 MAs was expired. Another possibility is that appointments made on Sundays, and appointments made only 8 days after a previous one, suggest a sicker patient or more complex condition. The reason the rest of the appointments were missed is not clear. Further investigation is needed to clarify why the appointments made on Sundays are more likely to be missed. The qualitative feature “Appointment scheduled for a Friday” was second largest: 493 (17.4%) of 2831 appointments scheduled for a Friday were MAs. We examined the previous appointments of the KAs scheduled for a Friday and compared them with the previous appointments of MAs. Generally, the previous appointments of the KAs were likewise scheduled on Fridays, suggesting that KA patients incorporated visits to the hospital for diabetes treatment into their life as a matter of routine. In contrast, the previous appointments of MAs were less likely to have been scheduled on a Friday, suggesting that Friday was not their regular hospital-visit day. This suggests that the same day of the week as the patient’s previous hospital visits should be considered when making an appointment. Last, we examined appointment intervals, which is the fourth largest quantitative feature (the third largest involved diabetes history). The average interval in the case of KAs was 45 days, while that in the case of MAs was only 8 days. Next appointments in the case of KAs are usually made on the day of patients’ hospital visits. Of course, the interval between appointments is dictated by a patient’s health status; but, in practice, it generally falls between one and two months. As expected, most MAs were made on a day when a patient did not visit the hospital according to our examination. This suggests that appointments should be made on days when patients have a hospital visit. We will analyze other of the largest features related to clinical condition. For example, the feature, “Rilmazafone Hydrochloride Hydrate recently prescribed,” may indicate that those patients had a sleep disorder, which might suggest a useful hypothesis about why appointments are missed."
2017,Comparative approaches for classification of diabetes mellitus data: Machine learning paradigm,"Background and objective: Diabetes is a silent killer. The main cause of this disease is the presence of excessive amounts of metabolites such as glucose. There were about 387 million diabetic people all over the world in 2014. The financial burden of this disease has been calculated to be about $13,700 per year. According to the World Health Organization (WHO), these figures will more than double by the year 2030. This cost will be reduced dramatically if someone can predict diabetes statistically on the basis of some covariates. Although several classification techniques are available, it is very difficult to classify diabetes. The main objectives of this paper are as follows: (i) Gaussian process classification (GPC), (ii) comparative classifier for diabetes data classification, (iii) data analysis using the cross-validation approach, (iv) interpretation of the data analysis and (v) benchmarking our method against others. Methods: To classify diabetes, several classification techniques are used such as linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), and Naive Bayes (NB). However, most of the medical data show non-normality, non-linearity and inherent correlation structure. So in this paper we adapted Gaussian process (GP)-based classification technique using three kernels namely: linear, polynomial and radial basis kernel. We also investigate the performance of a GP-based classification technique in comparison to existing techniques such as LDA, QDA and NB. Performances are evaluated by using the accuracy (ACC), sensitivity (SE), specificity (SP), positive predictive value (PPV), negative predictive value (NPV) and receiver-operating characteristic (ROC) curves. Results: Pima Indian diabetes dataset is taken as part of the study. This consists of 768 patients, of which 268 patients are diabetic and 500 patients are controls. Our machine learning system shows the performance of GP-based model as: ACC 81.97%, SE 91.79%, SP 63.33%, PPV 84.91% and NPV 62.50% which are larger compared to other methods.","5.1. Our system In the last decade GP has become a powerful, non-parametric tool that is used mainly in regression and also in classification problems in order to handle various problems such as linearity of classical methods, complex data types, curse of dimension etc. GPC is an attractive tool for prediction problems. The prediction of GPC for binary class problem is very simple. It is a generalization of linear logistic regression, where the logistic function is used as activation function. In this paper we use three types of kernel function, linear, polynomial and radial basis kernel function. However, any positive definite function can be used as the kernel function. So, we should choose kernel on the basis of ongoing research goal. We can also simply choose kernel functions assuming prior information by knowing the properties of the kernel functions. For binary class problem we use sigmoid activation function. GPC is noise-free, and can be combined it with smooth activation functions, such as the logistic function. However, the likelihood function calculation for GPC using logistic activation function is intractable. Therefore, approximations algorithms must be needed, like the Laplace approximation or the Expectation Propagation (EP). In this study we have used the Laplace approximation for binary class problem of GPC. The focus of our study covered the following components: Comprehensive analysis between the three types of kernels for GPC-based paradigm using Laplace approximation framework for classification of diabetic (268) vs. control (500) in a 768 patient database, and further, comparing our 3 kernel-based GPC-classification against three other types of classifiers: LDA, QDA and NB, respectively. This thread leads to benchmarking our GPC system against three sets of other classifiers. Finally, performance evaluation of the machine learning system using the parameters such as: ACC, SE, SP, PPV, NPV, and ROC. Even though, the numbers of classifiers adapted in our study were only four, but theoretical benchmarking was accomplished against ten articles published in the literature Table 3 and [39], [40], [41]. The results are encouraging when compared against the four set of classifiers. An exhaustive research needs to be conducted to benchmark large data size and more number of classification techniques. 5.2. Factors affecting performance In this paper we have investigated the performance of three conventional classification techniques along with most recent technique, Gaussian process classification to classify diabetes status. Here, we divide the dataset into K5 and K10 folds and we have found the optimum results for K10 fold. In this case the accuracy for GPC with radial, linear and polynomial kernels are: 81.97%, 78.03% and 77.20%, respectively. GPC with radial basis kernel gives higher accuracy. Therefore, radial basis kernel function is selected for GP model. GPC with radial basis kernel gives ACC of 81.97%, SE of 91.79%, SP of 63.33%, PPV of 80.88% and NPV of 67.86% for the Pima Indian diabetes dataset and these values are larger compared to other three classification techniques LDA, QDA and NB. 5.3. Strengths, weakness and extensions The strength of Gaussian process framework is that it is a sophisticated classifier with computational tractability. GP can fit a wide variety of nonlinear and linear functions easily. It can also handle uncertainty in unknown functions by averaging. It can learn kernel parameters automatically from the data set. It provides full probabilistic prediction, whereas, SVM does not give any probability measure directly. One of the main difficulties of Gaussian process model is to choose a kernel which can represent the correct structure of the data. GP model may be extended or generalized by solving the above problems as well as difficulties."
2013,Machine learning approaches for discerning intercorrelation of hematological parameters and glucose level for identification of diabetes mellitus,"Background: The aim of this study is to explore the relationship between hematological parameters and glycemic status in the establishment of quantitative population-health relationship (QPHR) model for identifying individuals with or without diabetes mellitus (DM). Methods: A cross-sectional investigation of 190 participants residing in Nakhon Pathom, Thailand in January-March, 2013 was used in this study. Individuals were classified into 3 groups based on their blood glucose levels (normal, Pre-DM and DM). Hematological (white blood cell (WBC), red blood cell (RBC), hemoglobin (Hb) and hematocrite (Hct)) and glucose parameters were used as input variables while the glycemic status was used as output variable. Support vector machine (SVM) and artificial neural network (ANN) are machine learning approaches that were employed for identifying the glycemic status while association analysis (AA) was utilized in discovery of health parameters that frequently occur together. Results: Relationship amongst hematological parameters and glucose level indicated that the glycemic status (normal, Pre-DM and DM) was well correlated with WBC, RBC, Hb and Hct. SVM and ANN achieved accuracy of more than 98 % in classifying the glycemic status. Furthermore, AA analysis provided association rules for defining individuals with or without DM. Interestingly, rules for the Pre-DM group are associated with high levels of WBC, RBC, Hb and Hct. Conclusion This study presents the utilization of machine learning approaches for identification of DM status as well as in the discovery of frequently occurring parameters. Such predictive models provided high classification accuracy as well as pertinent rules in defining DM.","IR is a condition in which target cells are not responsive to insulin levels in circulation and this leads to the development of diseases such as MS, chronic inflammation, diabetes and cardiovascular diseases (Salsali and Nathan, 2006[15]; Alberti et al., 2009[2]). In considering hematological parameters, immune cells such as WBC may be involved in inflammatory response in which the adipose tissue is a target in IR. Subsequently, the adipose tissue secretes inflammatory factors such as cytokines to activate the increase of WBC (Bermann and Sypniewska, 2013[3]). Hct and Hb have been documented to increase the levels of parameters related to high blood viscosity, consequently leading to a decrease in blood flow (de Simone et al., 1990[6]) and an increase in blood pressure (Kutlu et al., 2009[11]) as found in DM and Pre-DM groups, respectively. Furthermore, RBC was also found to be correlated with glycemic condition (Chen et al., 2006[4]; Choi et al., 2003[5]; Jung et al., 2013[7]; Kawamoto et al., 2013[8]; Wang et al., 2004[17]) in which the mechanism of increasing RBC indices in the presence of IR is not completely understood, however, it may be deduced to be involved in the increase of erythropoiesis in peripheral blood or involved in reducing blood flow and rising viscosity thereby leading to elevated RBC count (Kawamoto et al., 2013[8]). Furthermore, hematological parameters were found to be correlated with glycemic conditions (Figure 2(Fig. 2)), which coincides with previous findings (Chen et al., 2006[4]; Choi et al., 2003[5]; Jung et al., 2013[7]; Kawamoto et al., 2013[8]; Wang et al., 2004[17]). Particularly, RBC, Hb and Hct were shown to exhibit significant association with glycemic status (i.e., normal, Pre-DM and DM) as shown in Figure 2(Fig. 2). Moreover, WBC was found to increase in both Pre-DM and DM groups (Table 1(Tab. 1)). Therefore, hematological parameters were used to classify individuals as having or not having DM. Herein, the QPHR approach had successfully been shown to afford robust classification of glycemic status (i.e., normal, Pre-DM and DM) as a function of health parameters. The approach enables the correlation of biomedical parameters with their respective DM status. QPHR is a data mining approach previously termed by us and had been successfully employed in classifying MS (Worachartcheewan et al., 2010[20], 2013[21]) while relevant effort had been shown to be useful in classifying DM (Quentin-Trautvetter et al., 2002[14]; Yu et al., 2010[22]). Previously, these methods have been shown by us to yield accuracies of 91 - 98 % in the classification of MS status (Worachartcheewan et al., 2013[21]). Interestingly, AA identified abnormalities in hematological parameters (i.e., WBC, RBC, Hb and Hct) in the Pre-DM group while abnormal level of glucose (i.e. glucose level 3) was found in the DM group. Previously, AA was used to analyze the comorbidity in patients with type 2 DM (Kim et al., 2012[9]) and MS (Worachartcheewan et al., 2013[21]) as to understand the correlation between biomedical parameters with diseases. Considering that the level of glucose was already used for labeling individuals as having DM or non-DM, it was therefore pertinent in the resulting DM identification. The inclusion of hematological parameters (i.e., WBC, RBC, Hb and Hct) in classifying DM status still led to an accuracy of more than 98 %. Therefore, it may be implied that hematological parameters are important variables together with glucose level for the identification of DM status. The QPHR study performed herein for the first time presents the utilization of complete blood cell count parameters (i.e., WBC, RBC, Hb and Hct) as descriptors in classification of DM status. Results support the fact that hematological parameters and glycemic condition are correlated, particularly, the strongest correlation was observed for the DM status group as corroborated by previous studies (Chen et al., 2006[4]; Choi et al., 2003[5]; Jung et al., 2013[7]; Kawamoto et al., 2013[8]; Wang et al., 2004[17]). Moreover, AA analysis suggests strong correlation between high levels of hematological parameters with the Pre-DM group (Table S2 in supplementary information). The machine learning approaches (i.e., SVM and ANN) employed in this study have been shown to be capable of correctly classifying the DM status affording accuracies of more than 98 %. In addition, rules obtained from AA analysis may be used as guidelines for the prevention of individuals at risk for the development of DM."